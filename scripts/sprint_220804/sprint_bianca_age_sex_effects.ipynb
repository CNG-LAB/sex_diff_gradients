{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc35224d-15b6-46d7-abae-b64d82575097",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lab Sprint: Multiscale organization of social brain networks\n",
    "\n",
    "# Age and Sex Effects\n",
    "\n",
    "2-4 August 2022\n",
    "\n",
    "Script author: Bianca Serio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acf8ea9-8176-4608-af49-25d524b6911a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "387b60a0-9b3d-429f-ad53-4e303845b351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# Computing\n",
    "import scipy.io  # loadmat\n",
    "import mat73  # loadmat \n",
    "import statistics\n",
    "from scipy import stats\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4507767-664b-4be8-b18a-f0cbb92842e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "011d09f1-a3e2-4d01-ab35-9ad6eae22f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "codedir = os.path.abspath('')  # obtain current direction from which script is runnning\n",
    "\n",
    "datadir = '/data/pt_02542/social_networks/data/'\n",
    "\n",
    "resdir = '/data/pt_02542/social_networks/results/'\n",
    "#os.makedirs(resdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e78f70-90c7-44ff-929c-1fb759d86999",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Descriptives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d72df15-7328-4275-8b2f-9fb81696cf7a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4db7b798-236a-432f-8aaa-b4d3ecb05c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics = pd.read_csv(datadir+'HCP_426unrelatedSub_phenotype.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7a0cc3c5-8513-468d-a8e4-d208b11d83fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 426\n",
      "225 females, 201 males\n",
      "Mean subject age: 28.60, SD: 3.67, range: 22.00 - 36.00\n",
      "Mean ICV: 1585739.06, SD: 184777.78, range: 831208.30 - 1998044.32\n"
     ]
    }
   ],
   "source": [
    "print(f\"N = {len(demographics)}\\n\"\n",
    "      f\"{np.sum(demographics.Gender == 'F')} females, {np.sum(demographics.Gender == 'M')} males\\n\"\n",
    "      f\"Mean subject age: {np.mean(demographics.Age_in_Yrs):.2f}, SD: {np.std(demographics.Age_in_Yrs):.2f}, range: {np.min(demographics.Age_in_Yrs):.2f} - {np.max(demographics.Age_in_Yrs):.2f}\\n\"\n",
    "      f\"Mean ICV: {np.mean(demographics.FS_IntraCranial_Vol):.2f}, SD: {np.std(demographics.FS_IntraCranial_Vol):.2f}, range: {np.min(demographics.FS_IntraCranial_Vol):.2f} - {np.max(demographics.FS_IntraCranial_Vol):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8fa5c3-631a-4cd1-a840-ad1f2e3f9c59",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing differences in age between the sexes (given that I will test sex and age effects without matching sex-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "dcf42c5d-9757-4cab-93c8-20c3ded65d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeveneResult(statistic=0.4557898237962922, pvalue=0.4999661929937028)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Levene's test for equality of variances -> non-significant differences means equality, can contiunue with parametric independent samples t-test\n",
    "stats.levene(demographics.Age_in_Yrs[demographics.Gender == 'M'], demographics.Age_in_Yrs[demographics.Gender == 'F'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "853eb56d-552e-4679-aff5-b37a8e73025e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-4.875214839068324, pvalue=1.5392502822237055e-06)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(demographics.Age_in_Yrs[demographics.Gender == 'M'], demographics.Age_in_Yrs[demographics.Gender == 'F'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e0cb360b-f445-41fe-a189-6db591efbb52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
    "\n",
    "fig.suptitle('Age distribution by sex', fontsize=16)\n",
    "\n",
    "axs[0].hist(demographics.Age_in_Yrs[demographics.Gender == 'M'], bins=15, color = 'lightblue')\n",
    "axs[0].set_title('Male')\n",
    "axs[0].set_xlabel('Age')\n",
    "axs[0].set_ylabel('Frequency')\n",
    "\n",
    "axs[1].hist(demographics.Age_in_Yrs[demographics.Gender == 'F'], bins=15, color = 'lightpink')\n",
    "axs[1].set_title('Female')\n",
    "axs[1].set_xlabel('Age')\n",
    "axs[1].set_ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cdff72-fe54-469d-b3c3-2cb2fa4eaf58",
   "metadata": {},
   "source": [
    "# Preparing brain data for linear regression (in R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf8b914-30f0-4cd0-9c7d-f865042f11b6",
   "metadata": {},
   "source": [
    "## SJH cluster mask\n",
    "\n",
    "i.e., in SJH parcellation (1010 parcels), parcels inside mask of interest (1), parcels outside (0)\n",
    "\n",
    "number of SJH parcels in mask: 462"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "9cf1a6e6-818d-4c05-b14f-b78b2a89c2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sjh_cluster_1010_mask = pd.read_csv('/data/pt_02542/social_networks/data/sjh_cluster_1010_mask.txt', sep=' ', header=None)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dadb9022-66ae-475b-931d-c2a8220d3679",
   "metadata": {},
   "source": [
    "# number of parcels included in mask (coded with 1)\n",
    "sjh_cluster_1010_mask[0].tolist().count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "665f231f-5cab-4abe-ac87-0acaa9647c28",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# index of values corresponding to the mask of interest -> will use this to cut the 1012x1012 matrices\n",
    "index_mask_462 = sjh_cluster_1010_mask.index[sjh_cluster_1010_mask[0] == 1].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62108f96-ec9b-404d-9bb2-237785c62bb0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MPC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7341744f-0d10-4e2a-9ec2-045f17c81968",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Raw data (i.e., MPC intensity profiles (averaged over 16 layers) in each parcel)\n",
    "**-> PROBLEM: Bin & Alex's data is individual level connectivity matrices - I would need the step just before no? raw data**\n",
    "\n",
    "**-> CONT.: raw data = Lina's data, BUT hers is in fsaverage vertices so I would need to project fsaverage -> sjh (and then apply mask)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f3a7e5-8e3b-48a5-b20f-cf0760077adb",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### MPC pairwise connectivity matrices (sjh parcellation, unmasked) computed by Bin & Alex\n",
    "\n",
    "each subject (out of 426) has: 1010 parcels x 1010 parcels "
   ]
  },
  {
   "cell_type": "raw",
   "id": "867b06c1-0731-4d0d-bd6d-58e3ac9f86bd",
   "metadata": {},
   "source": [
    "path_list_mpc_pairwise_matrices = os.listdir(resdir+'mpc/individual_pairwise_mpc/')\n",
    "path_list_mpc_pairwise_matrices.sort()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce1ad987-ab8d-4a96-947f-8bc2a7204e95",
   "metadata": {
    "tags": []
   },
   "source": [
    "# list that contains all the subject IDs of subjects with fc matrices - not planning on doing anything with this, but good to have as sanity check\n",
    "sub_list_mpc_pairwise_matrices = []\n",
    "\n",
    "# list that contains the mpc matrices of all subjects in the form of 1 np array per subject\n",
    "mpc_pairwise_matrices_1010 = []\n",
    "\n",
    "\n",
    "for e in path_list_mpc_pairwise_matrices:\n",
    "    if '.txt' in e:  # just in case so don't call on hidden ipynb_checkpoints in the path list matrices\n",
    "        \n",
    "        # add subject to the subjects' list\n",
    "        sub_list_mpc_pairwise_matrices.append(e.partition(\"_\")[0])  # this partitions the subID_mpc_sjh.txt into a 5-tuple containing ('subID', '_', 'mpc', '_', 'sjh.txt'), and I keep only the subID\n",
    "        \n",
    "        # reads txt file in the form of an array\n",
    "        sub_matrix = np.genfromtxt(resdir+'mpc/individual_pairwise_mpc/'+e, delimiter=' ')\n",
    "\n",
    "        # add subject's matrix to the mpc_pairwise_matrices_1010 list\n",
    "        mpc_pairwise_matrices_1010.append(sub_matrix)\n",
    "        \n",
    "print(f'number of MPC pairwise matrices (1010x1010), i.e., subjects: N = {len(sub_list_mpc_pairwise_matrices)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78a3260-62b6-40af-b5b3-eab3b0259743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ac50a1-5b10-473b-8273-c9dc01039fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c76ff3-db4f-493c-b2af-e4e404449eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a5390e3-d7ba-4c1e-b7b3-c19e47dcee30",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Lina's (Matlab) -example code for:\n",
    "- MPC data: in the format of layers x vertices/parcels x subjects\n",
    "- manipulating wholebrain fsaverage5 vertices\n",
    "- applying masks (activation-based meta-analytical map mask + midline wall mask)\n",
    "\n",
    "**last subsection in this section calculates the mean MPC for MPC sex and age lm analyses** (exports mean to txt file for analyses in R)\n",
    "\n",
    "**other than that, not used for project analyses because it's fsaverage parcellation (not SJH)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b78601-510d-4f08-883c-423381508104",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Wholebrain \n",
    "\n",
    "fsaverage5: 20484 vertices; first half of the array is left hemisphere and second half is right (fsaverage convention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e43d8de2-d6fb-4baf-b08a-f79d193c43af",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpc = mat73.loadmat('/data/pt_02542/social_networks/results/mpc/matlab_made_by_lina/intensity_profiles_wholebrain.mat')\n",
    "# 12 (layers) x 20484 (vertices) x 1101 (sub -> full sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d86bc1e-66ed-488d-b980-dc310fe467c2",
   "metadata": {},
   "source": [
    "Calculate the mean mpc (across 12 layers) value per vertex per subject (mpc is still in full sample N = 1101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8b9f4e8-0886-4f26-b530-95327ca22fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean mpc value per vertex per subject and store it in a list which will contain 1101 (sub) x 20484 (vertices)\n",
    "mpc_means = []\n",
    "\n",
    "for sub in mpc['BB_all'].T:\n",
    "    temp_sub = []\n",
    "    \n",
    "    for vertex in sub:\n",
    "        temp_mean_vertex = 0\n",
    "        temp_mean_vertex = statistics.mean(vertex)  # takes the mean of the 12 layers\n",
    "        temp_sub.append(temp_mean_vertex)\n",
    "    \n",
    "    mpc_means.append(temp_sub)    \n",
    "\n",
    "# dataframe containing 1101 rows (participants) x 20484 columns (vertices): content values are the mean mpc across 12 layers    \n",
    "df_mpc_means_wholebrain = pd.DataFrame(mpc_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ddb1673b-67f1-42b2-8e3c-e9d1d5b1d0f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20474</th>\n",
       "      <th>20475</th>\n",
       "      <th>20476</th>\n",
       "      <th>20477</th>\n",
       "      <th>20478</th>\n",
       "      <th>20479</th>\n",
       "      <th>20480</th>\n",
       "      <th>20481</th>\n",
       "      <th>20482</th>\n",
       "      <th>20483</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.000461</td>\n",
       "      <td>1.767805</td>\n",
       "      <td>1.626661</td>\n",
       "      <td>1.790237</td>\n",
       "      <td>1.893281</td>\n",
       "      <td>1.682160</td>\n",
       "      <td>1.801187</td>\n",
       "      <td>1.808154</td>\n",
       "      <td>1.848937</td>\n",
       "      <td>1.935242</td>\n",
       "      <td>...</td>\n",
       "      <td>1.608645</td>\n",
       "      <td>1.627179</td>\n",
       "      <td>1.593380</td>\n",
       "      <td>1.436093</td>\n",
       "      <td>1.707282</td>\n",
       "      <td>1.470818</td>\n",
       "      <td>1.515555</td>\n",
       "      <td>1.420999</td>\n",
       "      <td>1.605552</td>\n",
       "      <td>1.889388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.174153</td>\n",
       "      <td>1.736753</td>\n",
       "      <td>1.703559</td>\n",
       "      <td>1.644420</td>\n",
       "      <td>1.903188</td>\n",
       "      <td>1.621496</td>\n",
       "      <td>1.901350</td>\n",
       "      <td>1.866272</td>\n",
       "      <td>1.634727</td>\n",
       "      <td>1.753514</td>\n",
       "      <td>...</td>\n",
       "      <td>1.472344</td>\n",
       "      <td>1.601802</td>\n",
       "      <td>1.361401</td>\n",
       "      <td>1.450294</td>\n",
       "      <td>1.366128</td>\n",
       "      <td>1.419077</td>\n",
       "      <td>1.450180</td>\n",
       "      <td>1.584109</td>\n",
       "      <td>1.823018</td>\n",
       "      <td>1.986701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.257156</td>\n",
       "      <td>2.037592</td>\n",
       "      <td>1.810788</td>\n",
       "      <td>1.808471</td>\n",
       "      <td>1.797940</td>\n",
       "      <td>1.610294</td>\n",
       "      <td>1.793024</td>\n",
       "      <td>1.825155</td>\n",
       "      <td>1.804319</td>\n",
       "      <td>1.828903</td>\n",
       "      <td>...</td>\n",
       "      <td>1.639612</td>\n",
       "      <td>1.378683</td>\n",
       "      <td>1.620305</td>\n",
       "      <td>1.348348</td>\n",
       "      <td>1.504331</td>\n",
       "      <td>1.452196</td>\n",
       "      <td>1.529935</td>\n",
       "      <td>1.544274</td>\n",
       "      <td>1.453838</td>\n",
       "      <td>1.541041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.545038</td>\n",
       "      <td>1.714274</td>\n",
       "      <td>2.001156</td>\n",
       "      <td>2.204234</td>\n",
       "      <td>2.356803</td>\n",
       "      <td>1.916110</td>\n",
       "      <td>1.911009</td>\n",
       "      <td>2.006492</td>\n",
       "      <td>2.949324</td>\n",
       "      <td>2.563377</td>\n",
       "      <td>...</td>\n",
       "      <td>1.556775</td>\n",
       "      <td>1.572407</td>\n",
       "      <td>1.469532</td>\n",
       "      <td>1.538280</td>\n",
       "      <td>1.915211</td>\n",
       "      <td>1.484559</td>\n",
       "      <td>1.366107</td>\n",
       "      <td>1.742164</td>\n",
       "      <td>1.612746</td>\n",
       "      <td>1.859857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.231686</td>\n",
       "      <td>1.731238</td>\n",
       "      <td>1.907962</td>\n",
       "      <td>1.764206</td>\n",
       "      <td>1.978865</td>\n",
       "      <td>1.728274</td>\n",
       "      <td>1.954220</td>\n",
       "      <td>1.966234</td>\n",
       "      <td>0.414039</td>\n",
       "      <td>1.974718</td>\n",
       "      <td>...</td>\n",
       "      <td>1.800537</td>\n",
       "      <td>1.717592</td>\n",
       "      <td>2.065045</td>\n",
       "      <td>2.231532</td>\n",
       "      <td>1.753708</td>\n",
       "      <td>1.686569</td>\n",
       "      <td>1.622884</td>\n",
       "      <td>1.919786</td>\n",
       "      <td>2.077985</td>\n",
       "      <td>2.109041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>2.167738</td>\n",
       "      <td>1.711667</td>\n",
       "      <td>1.551511</td>\n",
       "      <td>1.662949</td>\n",
       "      <td>1.612842</td>\n",
       "      <td>1.616801</td>\n",
       "      <td>1.754872</td>\n",
       "      <td>1.462365</td>\n",
       "      <td>1.373346</td>\n",
       "      <td>1.623800</td>\n",
       "      <td>...</td>\n",
       "      <td>1.492997</td>\n",
       "      <td>1.634726</td>\n",
       "      <td>1.392594</td>\n",
       "      <td>1.391636</td>\n",
       "      <td>1.530879</td>\n",
       "      <td>1.469312</td>\n",
       "      <td>1.416831</td>\n",
       "      <td>1.579190</td>\n",
       "      <td>1.596682</td>\n",
       "      <td>1.614222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>2.286734</td>\n",
       "      <td>1.853452</td>\n",
       "      <td>1.926306</td>\n",
       "      <td>1.629814</td>\n",
       "      <td>1.974333</td>\n",
       "      <td>1.864594</td>\n",
       "      <td>1.987045</td>\n",
       "      <td>2.443951</td>\n",
       "      <td>1.998489</td>\n",
       "      <td>1.758896</td>\n",
       "      <td>...</td>\n",
       "      <td>1.668942</td>\n",
       "      <td>1.540204</td>\n",
       "      <td>1.697367</td>\n",
       "      <td>1.430471</td>\n",
       "      <td>1.526475</td>\n",
       "      <td>1.513034</td>\n",
       "      <td>1.716360</td>\n",
       "      <td>1.309412</td>\n",
       "      <td>1.471599</td>\n",
       "      <td>1.697034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>2.087103</td>\n",
       "      <td>1.832445</td>\n",
       "      <td>1.862363</td>\n",
       "      <td>1.783108</td>\n",
       "      <td>1.806915</td>\n",
       "      <td>1.681400</td>\n",
       "      <td>1.892178</td>\n",
       "      <td>1.892459</td>\n",
       "      <td>1.538533</td>\n",
       "      <td>1.693448</td>\n",
       "      <td>...</td>\n",
       "      <td>1.391550</td>\n",
       "      <td>1.409903</td>\n",
       "      <td>1.368373</td>\n",
       "      <td>1.785488</td>\n",
       "      <td>1.623389</td>\n",
       "      <td>1.490000</td>\n",
       "      <td>1.485327</td>\n",
       "      <td>1.745581</td>\n",
       "      <td>1.669378</td>\n",
       "      <td>1.723214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>2.576662</td>\n",
       "      <td>2.253352</td>\n",
       "      <td>2.554928</td>\n",
       "      <td>1.897771</td>\n",
       "      <td>1.909763</td>\n",
       "      <td>2.112520</td>\n",
       "      <td>2.103706</td>\n",
       "      <td>2.434849</td>\n",
       "      <td>1.978484</td>\n",
       "      <td>1.913547</td>\n",
       "      <td>...</td>\n",
       "      <td>1.655112</td>\n",
       "      <td>1.538816</td>\n",
       "      <td>1.673089</td>\n",
       "      <td>1.548260</td>\n",
       "      <td>1.406275</td>\n",
       "      <td>1.646929</td>\n",
       "      <td>1.546698</td>\n",
       "      <td>1.690821</td>\n",
       "      <td>1.655628</td>\n",
       "      <td>1.865741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>1.984598</td>\n",
       "      <td>1.672882</td>\n",
       "      <td>1.758679</td>\n",
       "      <td>1.717251</td>\n",
       "      <td>1.814188</td>\n",
       "      <td>1.412256</td>\n",
       "      <td>1.882280</td>\n",
       "      <td>1.878107</td>\n",
       "      <td>1.626960</td>\n",
       "      <td>1.634647</td>\n",
       "      <td>...</td>\n",
       "      <td>1.496337</td>\n",
       "      <td>1.283072</td>\n",
       "      <td>1.457492</td>\n",
       "      <td>1.456470</td>\n",
       "      <td>1.522869</td>\n",
       "      <td>1.443298</td>\n",
       "      <td>1.848533</td>\n",
       "      <td>1.523554</td>\n",
       "      <td>1.562484</td>\n",
       "      <td>1.500031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1101 rows × 20484 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6      \\\n",
       "0     2.000461  1.767805  1.626661  1.790237  1.893281  1.682160  1.801187   \n",
       "1     2.174153  1.736753  1.703559  1.644420  1.903188  1.621496  1.901350   \n",
       "2     2.257156  2.037592  1.810788  1.808471  1.797940  1.610294  1.793024   \n",
       "3     2.545038  1.714274  2.001156  2.204234  2.356803  1.916110  1.911009   \n",
       "4     2.231686  1.731238  1.907962  1.764206  1.978865  1.728274  1.954220   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1096  2.167738  1.711667  1.551511  1.662949  1.612842  1.616801  1.754872   \n",
       "1097  2.286734  1.853452  1.926306  1.629814  1.974333  1.864594  1.987045   \n",
       "1098  2.087103  1.832445  1.862363  1.783108  1.806915  1.681400  1.892178   \n",
       "1099  2.576662  2.253352  2.554928  1.897771  1.909763  2.112520  2.103706   \n",
       "1100  1.984598  1.672882  1.758679  1.717251  1.814188  1.412256  1.882280   \n",
       "\n",
       "         7         8         9      ...     20474     20475     20476  \\\n",
       "0     1.808154  1.848937  1.935242  ...  1.608645  1.627179  1.593380   \n",
       "1     1.866272  1.634727  1.753514  ...  1.472344  1.601802  1.361401   \n",
       "2     1.825155  1.804319  1.828903  ...  1.639612  1.378683  1.620305   \n",
       "3     2.006492  2.949324  2.563377  ...  1.556775  1.572407  1.469532   \n",
       "4     1.966234  0.414039  1.974718  ...  1.800537  1.717592  2.065045   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1096  1.462365  1.373346  1.623800  ...  1.492997  1.634726  1.392594   \n",
       "1097  2.443951  1.998489  1.758896  ...  1.668942  1.540204  1.697367   \n",
       "1098  1.892459  1.538533  1.693448  ...  1.391550  1.409903  1.368373   \n",
       "1099  2.434849  1.978484  1.913547  ...  1.655112  1.538816  1.673089   \n",
       "1100  1.878107  1.626960  1.634647  ...  1.496337  1.283072  1.457492   \n",
       "\n",
       "         20477     20478     20479     20480     20481     20482     20483  \n",
       "0     1.436093  1.707282  1.470818  1.515555  1.420999  1.605552  1.889388  \n",
       "1     1.450294  1.366128  1.419077  1.450180  1.584109  1.823018  1.986701  \n",
       "2     1.348348  1.504331  1.452196  1.529935  1.544274  1.453838  1.541041  \n",
       "3     1.538280  1.915211  1.484559  1.366107  1.742164  1.612746  1.859857  \n",
       "4     2.231532  1.753708  1.686569  1.622884  1.919786  2.077985  2.109041  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1096  1.391636  1.530879  1.469312  1.416831  1.579190  1.596682  1.614222  \n",
       "1097  1.430471  1.526475  1.513034  1.716360  1.309412  1.471599  1.697034  \n",
       "1098  1.785488  1.623389  1.490000  1.485327  1.745581  1.669378  1.723214  \n",
       "1099  1.548260  1.406275  1.646929  1.546698  1.690821  1.655628  1.865741  \n",
       "1100  1.456470  1.522869  1.443298  1.848533  1.523554  1.562484  1.500031  \n",
       "\n",
       "[1101 rows x 20484 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mpc_means_wholebrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a826a0-a03f-4719-add6-020880a8da34",
   "metadata": {},
   "source": [
    "Make a df_mpc_means_wholebrain that only contains unrelated subjects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f4d7efde-eb67-4c9d-a7bb-06162ccbdda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of full sample subject IDs (N = 1101) corresponding to subjects in Lina's matfile (in same order)\n",
    "full_sub_list = pd.read_csv('/data/pt_02542/social_networks/results/mpc/matlab_made_by_lina/fulllist.txt', sep=' ', header=None)\n",
    "\n",
    "# list of unrelated sample subject IDs (n = 426) from demographics dataframe (data loaded in descriptives section)\n",
    "unrel_sub_list = demographics['Subject'].tolist()\n",
    "\n",
    "# list of the indexes of unrelated subjects in the full sample dataframe \n",
    "index_unrel_sub = full_sub_list.index[full_sub_list[0].isin(unrel_sub_list)].tolist()\n",
    "\n",
    "# select (with index_unrel_sub) from df_mpc_means_wholebrain dataframe only rows corresponding to unrelated subjects \n",
    "df_mpc_means_wholebrain_unrel_sub = df_mpc_means_wholebrain.loc[index_unrel_sub]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "9f12a09d-4604-4986-a0e1-af43053b2850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20474</th>\n",
       "      <th>20475</th>\n",
       "      <th>20476</th>\n",
       "      <th>20477</th>\n",
       "      <th>20478</th>\n",
       "      <th>20479</th>\n",
       "      <th>20480</th>\n",
       "      <th>20481</th>\n",
       "      <th>20482</th>\n",
       "      <th>20483</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.000461</td>\n",
       "      <td>1.767805</td>\n",
       "      <td>1.626661</td>\n",
       "      <td>1.790237</td>\n",
       "      <td>1.893281</td>\n",
       "      <td>1.682160</td>\n",
       "      <td>1.801187</td>\n",
       "      <td>1.808154</td>\n",
       "      <td>1.848937</td>\n",
       "      <td>1.935242</td>\n",
       "      <td>...</td>\n",
       "      <td>1.608645</td>\n",
       "      <td>1.627179</td>\n",
       "      <td>1.593380</td>\n",
       "      <td>1.436093</td>\n",
       "      <td>1.707282</td>\n",
       "      <td>1.470818</td>\n",
       "      <td>1.515555</td>\n",
       "      <td>1.420999</td>\n",
       "      <td>1.605552</td>\n",
       "      <td>1.889388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.174153</td>\n",
       "      <td>1.736753</td>\n",
       "      <td>1.703559</td>\n",
       "      <td>1.644420</td>\n",
       "      <td>1.903188</td>\n",
       "      <td>1.621496</td>\n",
       "      <td>1.901350</td>\n",
       "      <td>1.866272</td>\n",
       "      <td>1.634727</td>\n",
       "      <td>1.753514</td>\n",
       "      <td>...</td>\n",
       "      <td>1.472344</td>\n",
       "      <td>1.601802</td>\n",
       "      <td>1.361401</td>\n",
       "      <td>1.450294</td>\n",
       "      <td>1.366128</td>\n",
       "      <td>1.419077</td>\n",
       "      <td>1.450180</td>\n",
       "      <td>1.584109</td>\n",
       "      <td>1.823018</td>\n",
       "      <td>1.986701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.257156</td>\n",
       "      <td>2.037592</td>\n",
       "      <td>1.810788</td>\n",
       "      <td>1.808471</td>\n",
       "      <td>1.797940</td>\n",
       "      <td>1.610294</td>\n",
       "      <td>1.793024</td>\n",
       "      <td>1.825155</td>\n",
       "      <td>1.804319</td>\n",
       "      <td>1.828903</td>\n",
       "      <td>...</td>\n",
       "      <td>1.639612</td>\n",
       "      <td>1.378683</td>\n",
       "      <td>1.620305</td>\n",
       "      <td>1.348348</td>\n",
       "      <td>1.504331</td>\n",
       "      <td>1.452196</td>\n",
       "      <td>1.529935</td>\n",
       "      <td>1.544274</td>\n",
       "      <td>1.453838</td>\n",
       "      <td>1.541041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.545038</td>\n",
       "      <td>1.714274</td>\n",
       "      <td>2.001156</td>\n",
       "      <td>2.204234</td>\n",
       "      <td>2.356803</td>\n",
       "      <td>1.916110</td>\n",
       "      <td>1.911009</td>\n",
       "      <td>2.006492</td>\n",
       "      <td>2.949324</td>\n",
       "      <td>2.563377</td>\n",
       "      <td>...</td>\n",
       "      <td>1.556775</td>\n",
       "      <td>1.572407</td>\n",
       "      <td>1.469532</td>\n",
       "      <td>1.538280</td>\n",
       "      <td>1.915211</td>\n",
       "      <td>1.484559</td>\n",
       "      <td>1.366107</td>\n",
       "      <td>1.742164</td>\n",
       "      <td>1.612746</td>\n",
       "      <td>1.859857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.231686</td>\n",
       "      <td>1.731238</td>\n",
       "      <td>1.907962</td>\n",
       "      <td>1.764206</td>\n",
       "      <td>1.978865</td>\n",
       "      <td>1.728274</td>\n",
       "      <td>1.954220</td>\n",
       "      <td>1.966234</td>\n",
       "      <td>0.414039</td>\n",
       "      <td>1.974718</td>\n",
       "      <td>...</td>\n",
       "      <td>1.800537</td>\n",
       "      <td>1.717592</td>\n",
       "      <td>2.065045</td>\n",
       "      <td>2.231532</td>\n",
       "      <td>1.753708</td>\n",
       "      <td>1.686569</td>\n",
       "      <td>1.622884</td>\n",
       "      <td>1.919786</td>\n",
       "      <td>2.077985</td>\n",
       "      <td>2.109041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>1.908414</td>\n",
       "      <td>1.781555</td>\n",
       "      <td>1.659760</td>\n",
       "      <td>1.828432</td>\n",
       "      <td>1.972391</td>\n",
       "      <td>1.683701</td>\n",
       "      <td>2.027914</td>\n",
       "      <td>1.778670</td>\n",
       "      <td>0.486577</td>\n",
       "      <td>1.914576</td>\n",
       "      <td>...</td>\n",
       "      <td>1.565383</td>\n",
       "      <td>1.492884</td>\n",
       "      <td>1.480382</td>\n",
       "      <td>1.293031</td>\n",
       "      <td>1.403323</td>\n",
       "      <td>1.239721</td>\n",
       "      <td>1.371714</td>\n",
       "      <td>1.569875</td>\n",
       "      <td>1.485799</td>\n",
       "      <td>1.728444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>2.454074</td>\n",
       "      <td>1.619065</td>\n",
       "      <td>2.067376</td>\n",
       "      <td>1.900855</td>\n",
       "      <td>1.856735</td>\n",
       "      <td>1.728323</td>\n",
       "      <td>1.666236</td>\n",
       "      <td>1.604520</td>\n",
       "      <td>2.071300</td>\n",
       "      <td>2.048840</td>\n",
       "      <td>...</td>\n",
       "      <td>1.624948</td>\n",
       "      <td>1.553646</td>\n",
       "      <td>1.553594</td>\n",
       "      <td>1.494731</td>\n",
       "      <td>1.791131</td>\n",
       "      <td>1.654571</td>\n",
       "      <td>1.687741</td>\n",
       "      <td>1.650664</td>\n",
       "      <td>1.573858</td>\n",
       "      <td>1.747165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>2.277170</td>\n",
       "      <td>2.033686</td>\n",
       "      <td>1.879270</td>\n",
       "      <td>2.181865</td>\n",
       "      <td>2.229678</td>\n",
       "      <td>1.680294</td>\n",
       "      <td>1.801140</td>\n",
       "      <td>2.111539</td>\n",
       "      <td>0.342290</td>\n",
       "      <td>2.038290</td>\n",
       "      <td>...</td>\n",
       "      <td>1.707393</td>\n",
       "      <td>1.694337</td>\n",
       "      <td>1.731360</td>\n",
       "      <td>1.581371</td>\n",
       "      <td>1.767588</td>\n",
       "      <td>1.495633</td>\n",
       "      <td>1.798281</td>\n",
       "      <td>1.757954</td>\n",
       "      <td>2.005455</td>\n",
       "      <td>1.769723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>1.949268</td>\n",
       "      <td>1.753848</td>\n",
       "      <td>2.037628</td>\n",
       "      <td>1.965520</td>\n",
       "      <td>2.106331</td>\n",
       "      <td>1.719512</td>\n",
       "      <td>1.565443</td>\n",
       "      <td>2.028048</td>\n",
       "      <td>2.937064</td>\n",
       "      <td>1.853679</td>\n",
       "      <td>...</td>\n",
       "      <td>1.559744</td>\n",
       "      <td>1.432147</td>\n",
       "      <td>1.476025</td>\n",
       "      <td>1.323513</td>\n",
       "      <td>1.382417</td>\n",
       "      <td>1.407095</td>\n",
       "      <td>1.383109</td>\n",
       "      <td>1.572093</td>\n",
       "      <td>1.490209</td>\n",
       "      <td>1.458300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>1.980550</td>\n",
       "      <td>1.743128</td>\n",
       "      <td>1.847090</td>\n",
       "      <td>1.613226</td>\n",
       "      <td>1.764619</td>\n",
       "      <td>1.591565</td>\n",
       "      <td>1.719271</td>\n",
       "      <td>1.821593</td>\n",
       "      <td>0.864354</td>\n",
       "      <td>1.658839</td>\n",
       "      <td>...</td>\n",
       "      <td>1.623366</td>\n",
       "      <td>1.680368</td>\n",
       "      <td>1.630235</td>\n",
       "      <td>1.525183</td>\n",
       "      <td>1.356100</td>\n",
       "      <td>1.482166</td>\n",
       "      <td>1.457619</td>\n",
       "      <td>1.389449</td>\n",
       "      <td>1.520281</td>\n",
       "      <td>1.752783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>426 rows × 20484 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6      \\\n",
       "0     2.000461  1.767805  1.626661  1.790237  1.893281  1.682160  1.801187   \n",
       "1     2.174153  1.736753  1.703559  1.644420  1.903188  1.621496  1.901350   \n",
       "2     2.257156  2.037592  1.810788  1.808471  1.797940  1.610294  1.793024   \n",
       "3     2.545038  1.714274  2.001156  2.204234  2.356803  1.916110  1.911009   \n",
       "4     2.231686  1.731238  1.907962  1.764206  1.978865  1.728274  1.954220   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1036  1.908414  1.781555  1.659760  1.828432  1.972391  1.683701  2.027914   \n",
       "1057  2.454074  1.619065  2.067376  1.900855  1.856735  1.728323  1.666236   \n",
       "1069  2.277170  2.033686  1.879270  2.181865  2.229678  1.680294  1.801140   \n",
       "1073  1.949268  1.753848  2.037628  1.965520  2.106331  1.719512  1.565443   \n",
       "1080  1.980550  1.743128  1.847090  1.613226  1.764619  1.591565  1.719271   \n",
       "\n",
       "         7         8         9      ...     20474     20475     20476  \\\n",
       "0     1.808154  1.848937  1.935242  ...  1.608645  1.627179  1.593380   \n",
       "1     1.866272  1.634727  1.753514  ...  1.472344  1.601802  1.361401   \n",
       "2     1.825155  1.804319  1.828903  ...  1.639612  1.378683  1.620305   \n",
       "3     2.006492  2.949324  2.563377  ...  1.556775  1.572407  1.469532   \n",
       "4     1.966234  0.414039  1.974718  ...  1.800537  1.717592  2.065045   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1036  1.778670  0.486577  1.914576  ...  1.565383  1.492884  1.480382   \n",
       "1057  1.604520  2.071300  2.048840  ...  1.624948  1.553646  1.553594   \n",
       "1069  2.111539  0.342290  2.038290  ...  1.707393  1.694337  1.731360   \n",
       "1073  2.028048  2.937064  1.853679  ...  1.559744  1.432147  1.476025   \n",
       "1080  1.821593  0.864354  1.658839  ...  1.623366  1.680368  1.630235   \n",
       "\n",
       "         20477     20478     20479     20480     20481     20482     20483  \n",
       "0     1.436093  1.707282  1.470818  1.515555  1.420999  1.605552  1.889388  \n",
       "1     1.450294  1.366128  1.419077  1.450180  1.584109  1.823018  1.986701  \n",
       "2     1.348348  1.504331  1.452196  1.529935  1.544274  1.453838  1.541041  \n",
       "3     1.538280  1.915211  1.484559  1.366107  1.742164  1.612746  1.859857  \n",
       "4     2.231532  1.753708  1.686569  1.622884  1.919786  2.077985  2.109041  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1036  1.293031  1.403323  1.239721  1.371714  1.569875  1.485799  1.728444  \n",
       "1057  1.494731  1.791131  1.654571  1.687741  1.650664  1.573858  1.747165  \n",
       "1069  1.581371  1.767588  1.495633  1.798281  1.757954  2.005455  1.769723  \n",
       "1073  1.323513  1.382417  1.407095  1.383109  1.572093  1.490209  1.458300  \n",
       "1080  1.525183  1.356100  1.482166  1.457619  1.389449  1.520281  1.752783  \n",
       "\n",
       "[426 rows x 20484 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mpc_means_wholebrain_unrel_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ed5bdd-21a8-4483-aa33-eb36b0a77c07",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Use thresholded maps to select (from wholebrain) only the vertices that belong to the mask of interest\n",
    "\n",
    "\n",
    "- Mask of interest: total size = 9197 vertices (without medial wall!)\n",
    "    - Full map yielded from Cl_all_thresh.10k_fsavg5.L.csv: 10146 vertices (including medial wall) \n",
    "    - Medial wall (is provided by fsa5_rh_mask.csv fsa5_rh_mask.csv): 949 -> to remove from full map\n",
    "    \n",
    "*Reason to remove medial wall: because when transforming from volume to surface, values from e.g. subcortical structures get projected to the medial wall, introducing inaccuracies. Thus, excluding it to focus on only the cortex is a standardization method*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "96017184-2f46-4a74-9036-dbc04c858eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the thresholded maps (by hemisphere)\n",
    "# size = 10242 vertices (fsaverage5) for each thresholded map, where vertices belonging to mask of interest != 0\n",
    "\n",
    "# left hemisphere thresholded map\n",
    "\n",
    "with open('/data/pt_02542/social_networks/data/MetaAnalysis_Maps/TransformedData_fsaverage5/Cl_all_thresh.10k_fsavg5.L.csv', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    data_all_cl_L = list(reader)\n",
    "\n",
    "# make thresholded maps into arrays (by first extracting every vertex value from the sublist it is in (as a result of csv.reader)\n",
    "all_cl_L = []\n",
    "for i in data_all_cl_L:\n",
    "    all_cl_L.append(i[0])\n",
    "\n",
    "all_cl_L = np.asarray(all_cl_L).astype('float64')  # .astype('float64') to change from scientific notation\n",
    "\n",
    "\n",
    "# right hemisphere thresholded map\n",
    "\n",
    "with open('/data/pt_02542/social_networks/data/MetaAnalysis_Maps/TransformedData_fsaverage5/Cl_all_thresh.10k_fsavg5.R.csv', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    data_all_cl_R = list(reader)\n",
    "\n",
    "# make thresholded maps into arrays (by first extracting every vertex value from the sublist it is in (as a result of csv.reader)\n",
    "all_cl_R = []\n",
    "for i in data_all_cl_R:\n",
    "    all_cl_R.append(i[0])\n",
    "\n",
    "all_cl_R = np.asarray(all_cl_R).astype('float64')  # .astype('float64') to change from scientific notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "17f28f3c-1e44-4729-8838-85fac2044ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the hemisphere thresholded maps with one another to make a wholebrain thresholded map (following the fsaverage convention: first left hemisphere, then right hemisphere)\n",
    "all_cl_wholebrain = np.concatenate((all_cl_L, all_cl_R), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d16d85-f7ef-465a-8ea3-10f37f44cd32",
   "metadata": {},
   "source": [
    "Remove the medial wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "09431e31-52b6-48a7-b39a-5613ec248db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medial wall masks, i.e., file encodes which parcels represent the medial wall in the hemispheres of fsa5\n",
    "# Every index is a parcel number, and the associated values signify if that parcel is part of the medial wall (0) or not (1)\n",
    "# You can thus use it to mask the medial wall in your fsavg5 arrays by substituting np.NaN in your array at the same location where the array from this file has a 0\n",
    "fsa5_lh_mask = pd.read_csv('/data/pt_02542/social_networks/sources/fsa5_lh_mask.csv', header = None)\n",
    "fsa5_rh_mask = pd.read_csv('/data/pt_02542/social_networks/sources/fsa5_rh_mask.csv', header = None)\n",
    "\n",
    "# concatenate the medial wall thresholded maps with one another to make a wholebrain medial wall thresholded map (following the fsaverage convention: first left hemisphere, then right hemisphere)\n",
    "fsa5_wholebrain_mask = np.concatenate((fsa5_lh_mask[0].tolist(), fsa5_rh_mask[0].tolist()), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "5907d383-de82-4c7f-be0f-fcbba6b53402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new list containing the thresholded map with removed medial wall from wholebrain (i.e. turning into 0 values that are part of the medial wall (0 in fsa5_wholebrain_mask)) \n",
    "\n",
    "all_cl_wholebrain_medialwall_removed = []\n",
    "\n",
    "# looping over all 20484 fsaverage vertices\n",
    "for i in range(len(all_cl_wholebrain)):\n",
    "    \n",
    "    # if the current vertex is part of the medial wall -> code it as 0 in all_cl_wholebrain_medialwall_removed \n",
    "    if fsa5_wholebrain_mask[i] == 0:\n",
    "        all_cl_wholebrain_medialwall_removed.append(0)\n",
    "    \n",
    "    # if the current vertex has a value other than zero in the mask -> code it with whatever value that vertex has in the thresholded map (mask)\n",
    "    else:\n",
    "        all_cl_wholebrain_medialwall_removed.append(all_cl_wholebrain[i])\n",
    "\n",
    "# this is final thresholded map array representing (with values != 0) vertices belonging to the mask of interest (without medial wall)\n",
    "all_cl_wholebrain_medialwall_removed = np.asarray(all_cl_wholebrain_medialwall_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "3d76953d-baea-4f81-9c06-b4b9376c1f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving the indexes of vertices belonging to the final mask of interest (without medial wall), i.e., where value != 0\n",
    "index_mask_wholebrain = np.where(all_cl_wholebrain_medialwall_removed != 0)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a42a78-45d9-468d-91fe-4e9dcbf8535f",
   "metadata": {},
   "source": [
    "**final dataframe mpc raw data (MPC intensity profiles - mean across 12 layers) - individual-subject level** - this format could be used for R analyses if I was doing them at vertex level\n",
    "\n",
    "**426 rows (subjects) x 9197 columns (vertices from mask) -> values represent average mpc across 12 layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "1a648c80-71e7-45c0-ba9c-cca2ef3b13fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>16</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>26</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>...</th>\n",
       "      <th>20465</th>\n",
       "      <th>20466</th>\n",
       "      <th>20467</th>\n",
       "      <th>20468</th>\n",
       "      <th>20469</th>\n",
       "      <th>20470</th>\n",
       "      <th>20471</th>\n",
       "      <th>20472</th>\n",
       "      <th>20473</th>\n",
       "      <th>20474</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.893281</td>\n",
       "      <td>1.935242</td>\n",
       "      <td>1.836077</td>\n",
       "      <td>1.996196</td>\n",
       "      <td>1.560392</td>\n",
       "      <td>1.686469</td>\n",
       "      <td>1.719342</td>\n",
       "      <td>1.836448</td>\n",
       "      <td>1.922759</td>\n",
       "      <td>1.689077</td>\n",
       "      <td>...</td>\n",
       "      <td>1.585138</td>\n",
       "      <td>1.605814</td>\n",
       "      <td>1.559319</td>\n",
       "      <td>1.570368</td>\n",
       "      <td>1.634970</td>\n",
       "      <td>1.644049</td>\n",
       "      <td>1.749788</td>\n",
       "      <td>1.670215</td>\n",
       "      <td>1.592911</td>\n",
       "      <td>1.608645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.903188</td>\n",
       "      <td>1.753514</td>\n",
       "      <td>1.596652</td>\n",
       "      <td>1.960138</td>\n",
       "      <td>1.788754</td>\n",
       "      <td>1.508702</td>\n",
       "      <td>1.525069</td>\n",
       "      <td>1.770393</td>\n",
       "      <td>1.732095</td>\n",
       "      <td>1.706800</td>\n",
       "      <td>...</td>\n",
       "      <td>1.420815</td>\n",
       "      <td>1.503979</td>\n",
       "      <td>1.589009</td>\n",
       "      <td>1.536603</td>\n",
       "      <td>1.531791</td>\n",
       "      <td>1.620041</td>\n",
       "      <td>1.654288</td>\n",
       "      <td>1.527478</td>\n",
       "      <td>1.596446</td>\n",
       "      <td>1.472344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.797940</td>\n",
       "      <td>1.828903</td>\n",
       "      <td>1.814869</td>\n",
       "      <td>1.924066</td>\n",
       "      <td>1.807365</td>\n",
       "      <td>1.690842</td>\n",
       "      <td>1.607376</td>\n",
       "      <td>1.786373</td>\n",
       "      <td>1.708823</td>\n",
       "      <td>1.721229</td>\n",
       "      <td>...</td>\n",
       "      <td>1.503931</td>\n",
       "      <td>1.356075</td>\n",
       "      <td>1.547114</td>\n",
       "      <td>1.551639</td>\n",
       "      <td>1.559163</td>\n",
       "      <td>1.610675</td>\n",
       "      <td>1.719584</td>\n",
       "      <td>1.685226</td>\n",
       "      <td>1.707401</td>\n",
       "      <td>1.639612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.356803</td>\n",
       "      <td>2.563377</td>\n",
       "      <td>2.003943</td>\n",
       "      <td>2.556389</td>\n",
       "      <td>1.883247</td>\n",
       "      <td>2.132923</td>\n",
       "      <td>2.628801</td>\n",
       "      <td>2.357618</td>\n",
       "      <td>2.136293</td>\n",
       "      <td>1.776450</td>\n",
       "      <td>...</td>\n",
       "      <td>1.659749</td>\n",
       "      <td>1.563872</td>\n",
       "      <td>1.629112</td>\n",
       "      <td>1.560361</td>\n",
       "      <td>1.614971</td>\n",
       "      <td>1.832248</td>\n",
       "      <td>1.734239</td>\n",
       "      <td>1.516639</td>\n",
       "      <td>1.604742</td>\n",
       "      <td>1.556775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.978865</td>\n",
       "      <td>1.974718</td>\n",
       "      <td>1.759196</td>\n",
       "      <td>2.146112</td>\n",
       "      <td>1.725259</td>\n",
       "      <td>1.649810</td>\n",
       "      <td>1.763318</td>\n",
       "      <td>1.876656</td>\n",
       "      <td>1.871773</td>\n",
       "      <td>1.571680</td>\n",
       "      <td>...</td>\n",
       "      <td>1.803422</td>\n",
       "      <td>1.778276</td>\n",
       "      <td>1.606708</td>\n",
       "      <td>1.669859</td>\n",
       "      <td>1.812810</td>\n",
       "      <td>1.814306</td>\n",
       "      <td>1.773683</td>\n",
       "      <td>1.787721</td>\n",
       "      <td>1.812351</td>\n",
       "      <td>1.800537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>1.972391</td>\n",
       "      <td>1.914576</td>\n",
       "      <td>1.930385</td>\n",
       "      <td>1.914466</td>\n",
       "      <td>1.842221</td>\n",
       "      <td>1.657078</td>\n",
       "      <td>1.899628</td>\n",
       "      <td>1.854850</td>\n",
       "      <td>1.850641</td>\n",
       "      <td>1.503924</td>\n",
       "      <td>...</td>\n",
       "      <td>1.724957</td>\n",
       "      <td>1.558331</td>\n",
       "      <td>1.603307</td>\n",
       "      <td>1.615151</td>\n",
       "      <td>1.587072</td>\n",
       "      <td>1.495125</td>\n",
       "      <td>1.669055</td>\n",
       "      <td>1.618040</td>\n",
       "      <td>1.703634</td>\n",
       "      <td>1.565383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>1.856735</td>\n",
       "      <td>2.048840</td>\n",
       "      <td>1.793901</td>\n",
       "      <td>2.142366</td>\n",
       "      <td>1.593719</td>\n",
       "      <td>1.672127</td>\n",
       "      <td>1.729530</td>\n",
       "      <td>1.943553</td>\n",
       "      <td>2.250063</td>\n",
       "      <td>1.599129</td>\n",
       "      <td>...</td>\n",
       "      <td>1.721427</td>\n",
       "      <td>1.634397</td>\n",
       "      <td>1.420103</td>\n",
       "      <td>1.589100</td>\n",
       "      <td>1.592187</td>\n",
       "      <td>1.731779</td>\n",
       "      <td>1.568706</td>\n",
       "      <td>1.614031</td>\n",
       "      <td>1.597686</td>\n",
       "      <td>1.624948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>2.229678</td>\n",
       "      <td>2.038290</td>\n",
       "      <td>2.029122</td>\n",
       "      <td>2.060589</td>\n",
       "      <td>2.123808</td>\n",
       "      <td>1.801695</td>\n",
       "      <td>1.593248</td>\n",
       "      <td>2.086979</td>\n",
       "      <td>2.039752</td>\n",
       "      <td>1.482456</td>\n",
       "      <td>...</td>\n",
       "      <td>1.714749</td>\n",
       "      <td>1.685091</td>\n",
       "      <td>1.352299</td>\n",
       "      <td>1.616908</td>\n",
       "      <td>1.674878</td>\n",
       "      <td>1.589018</td>\n",
       "      <td>1.376777</td>\n",
       "      <td>1.618642</td>\n",
       "      <td>1.736108</td>\n",
       "      <td>1.707393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>2.106331</td>\n",
       "      <td>1.853679</td>\n",
       "      <td>1.703474</td>\n",
       "      <td>2.020778</td>\n",
       "      <td>1.593446</td>\n",
       "      <td>1.719864</td>\n",
       "      <td>1.627489</td>\n",
       "      <td>1.752680</td>\n",
       "      <td>2.000380</td>\n",
       "      <td>1.542313</td>\n",
       "      <td>...</td>\n",
       "      <td>1.881615</td>\n",
       "      <td>1.571821</td>\n",
       "      <td>1.485398</td>\n",
       "      <td>1.570942</td>\n",
       "      <td>1.432158</td>\n",
       "      <td>1.545670</td>\n",
       "      <td>1.510698</td>\n",
       "      <td>1.453667</td>\n",
       "      <td>1.557517</td>\n",
       "      <td>1.559744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>1.764619</td>\n",
       "      <td>1.658839</td>\n",
       "      <td>1.712090</td>\n",
       "      <td>1.799886</td>\n",
       "      <td>1.516939</td>\n",
       "      <td>1.569211</td>\n",
       "      <td>1.479595</td>\n",
       "      <td>1.738302</td>\n",
       "      <td>1.773801</td>\n",
       "      <td>1.442167</td>\n",
       "      <td>...</td>\n",
       "      <td>1.579790</td>\n",
       "      <td>1.692526</td>\n",
       "      <td>1.436856</td>\n",
       "      <td>1.569103</td>\n",
       "      <td>1.553551</td>\n",
       "      <td>1.630402</td>\n",
       "      <td>1.607509</td>\n",
       "      <td>1.562196</td>\n",
       "      <td>1.518578</td>\n",
       "      <td>1.623366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>426 rows × 9197 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         4         9         10        12        16        21        22     \\\n",
       "0     1.893281  1.935242  1.836077  1.996196  1.560392  1.686469  1.719342   \n",
       "1     1.903188  1.753514  1.596652  1.960138  1.788754  1.508702  1.525069   \n",
       "2     1.797940  1.828903  1.814869  1.924066  1.807365  1.690842  1.607376   \n",
       "3     2.356803  2.563377  2.003943  2.556389  1.883247  2.132923  2.628801   \n",
       "4     1.978865  1.974718  1.759196  2.146112  1.725259  1.649810  1.763318   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1036  1.972391  1.914576  1.930385  1.914466  1.842221  1.657078  1.899628   \n",
       "1057  1.856735  2.048840  1.793901  2.142366  1.593719  1.672127  1.729530   \n",
       "1069  2.229678  2.038290  2.029122  2.060589  2.123808  1.801695  1.593248   \n",
       "1073  2.106331  1.853679  1.703474  2.020778  1.593446  1.719864  1.627489   \n",
       "1080  1.764619  1.658839  1.712090  1.799886  1.516939  1.569211  1.479595   \n",
       "\n",
       "         26        28        29     ...     20465     20466     20467  \\\n",
       "0     1.836448  1.922759  1.689077  ...  1.585138  1.605814  1.559319   \n",
       "1     1.770393  1.732095  1.706800  ...  1.420815  1.503979  1.589009   \n",
       "2     1.786373  1.708823  1.721229  ...  1.503931  1.356075  1.547114   \n",
       "3     2.357618  2.136293  1.776450  ...  1.659749  1.563872  1.629112   \n",
       "4     1.876656  1.871773  1.571680  ...  1.803422  1.778276  1.606708   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1036  1.854850  1.850641  1.503924  ...  1.724957  1.558331  1.603307   \n",
       "1057  1.943553  2.250063  1.599129  ...  1.721427  1.634397  1.420103   \n",
       "1069  2.086979  2.039752  1.482456  ...  1.714749  1.685091  1.352299   \n",
       "1073  1.752680  2.000380  1.542313  ...  1.881615  1.571821  1.485398   \n",
       "1080  1.738302  1.773801  1.442167  ...  1.579790  1.692526  1.436856   \n",
       "\n",
       "         20468     20469     20470     20471     20472     20473     20474  \n",
       "0     1.570368  1.634970  1.644049  1.749788  1.670215  1.592911  1.608645  \n",
       "1     1.536603  1.531791  1.620041  1.654288  1.527478  1.596446  1.472344  \n",
       "2     1.551639  1.559163  1.610675  1.719584  1.685226  1.707401  1.639612  \n",
       "3     1.560361  1.614971  1.832248  1.734239  1.516639  1.604742  1.556775  \n",
       "4     1.669859  1.812810  1.814306  1.773683  1.787721  1.812351  1.800537  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1036  1.615151  1.587072  1.495125  1.669055  1.618040  1.703634  1.565383  \n",
       "1057  1.589100  1.592187  1.731779  1.568706  1.614031  1.597686  1.624948  \n",
       "1069  1.616908  1.674878  1.589018  1.376777  1.618642  1.736108  1.707393  \n",
       "1073  1.570942  1.432158  1.545670  1.510698  1.453667  1.557517  1.559744  \n",
       "1080  1.569103  1.553551  1.630402  1.607509  1.562196  1.518578  1.623366  \n",
       "\n",
       "[426 rows x 9197 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a subset of the df_mpc_means_wholebrain which only contains the vertices belonging to the mask\n",
    "# ACHTUNG! to note that the column and row labels are not indexes 0-max but index before subselection, so careful when indexing -> maybe should just relabel them to avoid erros\n",
    "df_mpc_means_masked_9197v = df_mpc_means_wholebrain_unrel_sub[index_mask_wholebrain]\n",
    "df_mpc_means_masked_9197v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a375bd6c-8a88-4664-9924-7d770889508c",
   "metadata": {},
   "source": [
    "##### Calculate the **mean mpc across parcels** for each subject -> for mpc sex and age lm analyses (in R), i.e., to include in model as covariate\n",
    "Mean across all parcels/vertices (covariate) per subject -> because of parcel artifacts for each specific subject (intensity of t1/t2 could vary by subject)\n",
    "\n",
    "Potential problem with how I did this:\n",
    "- already check that this is the mean that Svenja meant, i.e. mean across layers, across vertices - per subject (ie one value per subject)\n",
    "- this was calculated at the masked vertex level - while it should technically be the same as if calculated a the masked sjh parcel level (because parcels are made of means over vertices), the fact that I went through the process of applying the mask over the vertices, removing the midline etc myself could make the vertex vs parcel solutions not match exactly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "a65687ed-0f3c-48b0-876e-46103a85901a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list will contain the mean of all mpc intensities (mean across vertices) per subjects (len = 426, ie number of subjects)\n",
    "means_mpc_9197v = []\n",
    "\n",
    "# iterate over rows (subjects) of dataframe\n",
    "for i in range(len(df_mpc_means_masked_9197v)):\n",
    "    means_mpc_9197v.append(np.mean(df_mpc_means_masked_9197v.iloc[i]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "45837bba-498b-41dd-80a6-9de8b503122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmt = decimals, header = 1 to 463 (without the first and last string letter because it's the [] of the list, comments = empty because otherwise gives a #\n",
    "\n",
    "np.savetxt(resdir+'age_sex/'+'means_mpc_9197v.csv', means_mpc_9197v, delimiter=',', header = 'mpc_means')#, fmt = '%.16g', header = str(list(range(1,463)))[1:-1], comments = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610a498b-7f87-4c8e-b762-d186016ae1e7",
   "metadata": {},
   "source": [
    "### Gradient eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0c1731-b1be-4366-9929-ce169081655b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### MPC gradients (mask on sjh parcellation) computed by Bin & Alex\n",
    "\n",
    "each subject (out of 426) has: 462 parcels x 10 gradients -> I am taking, from each subject, just G1 for all parcels\n",
    "\n",
    "this yields arrays of  426 subjects x 462 G1 eigenvalues (for mpc within and between separately)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "73e80e0d-4da6-41f7-a847-7683b32f2800",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list_mpc_pairwise_grad = os.listdir(resdir+'mpc/individual_pairwise_grad/')\n",
    "path_list_mpc_pairwise_grad.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "b61890d8-5ce4-400c-b561-08e63270c4f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of MPC pairwise within gradient arrays (462 parcels x 1 gradient (G1)), i.e., subjects: N = 426\n",
      "number of MPC pairwise rest gradient arrays (462 parcels x 1 gradients (G1)), i.e., subjects: N = 426\n"
     ]
    }
   ],
   "source": [
    "# list that contains all the subject IDs of subjects with fc matrices - not planning on doing anything with this, but good to have as sanity check\n",
    "sub_list_mpc_pairwise_within_grad = []\n",
    "sub_list_mpc_pairwise_rest_grad = []\n",
    "\n",
    "# lists that contains the mpc gradient matrices of all subjects in the form of 1 np array per subject\n",
    "#list \"within\" contains connectivity within mask of interest, list \"rest\" contains connectivity mask to rest of brain\n",
    "mpc_pairwise_within_grad_462 = []\n",
    "mpc_pairwise_rest_grad_462 = []\n",
    "\n",
    "\n",
    "for e in path_list_mpc_pairwise_grad:\n",
    "    if '.txt' in e:  # just in case so don't call on hidden ipynb_checkpoints in the path list matrices\n",
    "        \n",
    "        # identify if rest or within mpc in order to sort subject gradient data in the correct list\n",
    "        conn_type = e.split(\"_\")[2]  # this splits the string subID_all_within_sjh.txt into a list of 4 occurences containing ('subID', 'all', 'rest/within', 'sjh.txt'), and I keep only the rest/within\n",
    "        \n",
    "        # reads txt file in the form of an array, taking just the 1st value (G1) directly\n",
    "        sub_G1 = np.genfromtxt(resdir+'mpc/individual_pairwise_grad/'+e, delimiter=' ').T[0]\n",
    "        \n",
    "        if conn_type == 'within':\n",
    "            \n",
    "            # add subject to the subjects' list\n",
    "            sub_list_mpc_pairwise_within_grad.append(e.split(\"_\")[0])  # this partitions the subID_all_within_sjh.txt into a list of 4 occurences containing ('subID', 'all', 'rest/within', 'sjh.txt'), and I keep only the subID\n",
    "        \n",
    "            # add subject's matrix to the mpc_pairwise_within_grad_1010 list\n",
    "            mpc_pairwise_within_grad_462.append(sub_G1)\n",
    "            \n",
    "        elif conn_type == 'rest':\n",
    "            \n",
    "            # add subject to the subjects' list\n",
    "            sub_list_mpc_pairwise_rest_grad.append(e.split(\"_\")[0])  # this partitions the subID_all_within_sjh.txt into a list of 4 occurences containing ('subID', 'all', 'rest/within', 'sjh.txt'), and I keep only the subID\n",
    "        \n",
    "            # add subject's matrix to the mpc_pairwise_rest_grad_1010 list\n",
    "            mpc_pairwise_rest_grad_462.append(sub_G1)      \n",
    "\n",
    "            \n",
    "# make list into a numpy array - shape: 426 subjects x 462 parcels (containing each G1 eigenvalues)\n",
    "array_G1_mpc_pairwise_within = np.array(mpc_pairwise_within_grad_462) \n",
    "array_G1_mpc_pairwise_between = np.array(mpc_pairwise_rest_grad_462)  # between = rest, just to keep consistent with fc terminology\n",
    "            \n",
    "print(f'number of MPC pairwise within gradient arrays (462 parcels x 1 gradient (G1)), i.e., subjects: N = {len(sub_list_mpc_pairwise_within_grad)}')\n",
    "print(f'number of MPC pairwise rest gradient arrays (462 parcels x 1 gradients (G1)), i.e., subjects: N = {len(sub_list_mpc_pairwise_rest_grad)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca003fbd-cb0a-477e-8e93-b4058bbf62db",
   "metadata": {},
   "source": [
    "Exporting G1 arrays to csv for R analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "7ddf25b1-2fed-4647-a9e5-132f00f2429d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmt = decimals, header = 1 to 463 (without the first and last string letter because it's the [] of the list, comments = empty because otherwise gives a #\n",
    "\n",
    "np.savetxt(resdir+'age_sex/'+'array_G1_mpc_pairwise_within.csv', array_G1_mpc_pairwise_within, delimiter=',', fmt = '%.16g', header = str(list(range(1,463)))[1:-1], comments = '')\n",
    "np.savetxt(resdir+'age_sex/'+'array_G1_mpc_pairwise_between.csv', array_G1_mpc_pairwise_between, delimiter=',', fmt = '%.16g', header = str(list(range(1,463)))[1:-1], comments = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e34224e-2095-4b4d-9baa-d685c2cc470c",
   "metadata": {},
   "source": [
    "## Functional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99951be2-8e9e-445f-9f01-1303d8486604",
   "metadata": {},
   "source": [
    "### Raw data (i.e., mean activation across timeseries in each parcel)\n",
    "**->PROBLEM: I only have individual level connectivity matrices - I would need the step just before no? raw data**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "909e942a-ae1c-4b59-8f8e-9f20295fd2ed",
   "metadata": {},
   "source": [
    "fc_connectome = scipy.io.loadmat('/data/pt_02542/social_networks/results/FC/connectome/indiv_fc.mat')\n",
    "# 1012 sjh parcels x 1012 sjh parcels x 426 sub -> why 1012 and not 1010????!!!!! this is a problem because the mask that I have is for 1010 parcels"
   ]
  },
  {
   "cell_type": "raw",
   "id": "91a4333e-70ea-4d94-bd92-bd6111654cb5",
   "metadata": {},
   "source": [
    "len(fc_connectome['ind'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf67dc7a-8cb3-4beb-bcd0-fec13779c17b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecca1ca8-5791-48cf-9336-ef090434e188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4ee8cf-8ae6-4e55-b9d1-01d2a6b0153b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "581035b4-8608-4f46-9fd6-4927dba363a3",
   "metadata": {},
   "source": [
    "### Gradient eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "4baf96ad-dddf-4339-a677-8ac103bb9c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_grad_between_1010 = scipy.io.loadmat('/data/pt_02542/social_networks/results/FC/individual/between_1010_10_426.mat')\n",
    "# 1010 sjh parcels x 10 gradients x 426 sub\n",
    "\n",
    "fc_grad_within_1010 = scipy.io.loadmat('/data/pt_02542/social_networks/results/FC/individual/within_1010_10_426.mat')\n",
    "# 1010 sjh parcels x 10 gradients x 426 sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "4d977e28-a18a-4b0c-991e-cd9d48f5c55d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# selecting only the parcels in the mask: new size is 462 sjh parcels x 10 gradients x 426 subjects\n",
    "fc_grad_between_426 = fc_grad_between_1010['between_ind1010'][index_mask_462]\n",
    "fc_grad_within_426 = fc_grad_within_1010['within_ind1010'][index_mask_462]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "45f7ec67-ea94-4ed7-a287-ae0c7084a95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_G1_fc_between = []\n",
    "array_G1_fc_within = []\n",
    "\n",
    "for i in range(len(sjh_parcels_462.T)):  # iterating over subjects\n",
    "    \n",
    "    # append to list\n",
    "    array_G1_fc_between.append(fc_grad_between_426.T[i][0])  # gradient 1 for that subject\n",
    "    array_G1_fc_within.append(fc_grad_within_426.T[i][0])  # gradient 1 for that subject\n",
    "\n",
    "# make list into a numpy array - shape: 426 subjects x 462 parcels\n",
    "array_G1_fc_between = np.array(array_G1_fc_between)  \n",
    "array_G1_fc_within = np.array(array_G1_fc_within) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa739b0-83f4-4a68-8c3b-3f7f9e48ffc1",
   "metadata": {},
   "source": [
    "Exporting G1 arrays to csv for R analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "30817ea4-3e51-4807-90ee-ff6c99449783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmt = decimals, header = 1 to 463 (without the first and last string letter because it's the [] of the list, comments = empty because otherwise gives a #\n",
    "\n",
    "np.savetxt(resdir+'age_sex/'+'array_G1_fc_between.csv', array_G1_fc_between, delimiter=',', fmt = '%.16g', header = str(list(range(1,463)))[1:-1], comments = '')\n",
    "np.savetxt(resdir+'age_sex/'+'array_G1_fc_within.csv', array_G1_fc_within, delimiter=',', fmt = '%.16g', header = str(list(range(1,463)))[1:-1], comments = '')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
