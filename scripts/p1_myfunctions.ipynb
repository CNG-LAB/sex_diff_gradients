{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73bea96b-720c-4903-b477-e1282b9784ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_all_sub_conn_matrices(path_conn_matrices):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Function that fetches the connectivity matrices of all subjects from path and stores them in a variable \n",
    "    \n",
    "    Input:\n",
    "    - path containing all the subject connectivity matrices\n",
    "    \n",
    "    Output (dictionary containing):\n",
    "    - conn_matrices: np array contianing the connectivty matrices of all subjects (in the form of 1 np array per subject)\n",
    "    - sub_list: list containing all the subject IDs\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # list that contains all the subject IDs of subjects with fc matrices\n",
    "    sub_list = []\n",
    "\n",
    "    # list that contains the fc matrices of all subjects in the form of 1 np array per subject\n",
    "    conn_matrices = []\n",
    "\n",
    "    # reads (lists) the content of the path containing the list of fc_matrices and stores the sorted contents in as a list in the variable list_fc_matrices\n",
    "    list_conn_matrices = os.listdir(path_conn_matrices)\n",
    "    list_conn_matrices.sort()\n",
    "\n",
    "    for e in list_conn_matrices:\n",
    "        if '.csv' in e:  # need to do this because there is a hidden files in the path_list_fc_matrices\n",
    "\n",
    "            # add subject to the subjects' list\n",
    "            sub_list.append(e.partition(\".\")[0])  # this partitions the subID.csv into a 3-tuple containing ('subID', '.', 'csv'), and I keep only the subID\n",
    "\n",
    "            # reads csv file in the form of an array\n",
    "            sub_matrix = np.genfromtxt(path_conn_matrices + e, delimiter=',')\n",
    "\n",
    "            # add subject's matrix to the fc_matrices_400 list\n",
    "            conn_matrices.append(sub_matrix)\n",
    "\n",
    "    print(f'Connectivity matrices found in path {path_conn_matrices}: N = {len(sub_list)}')\n",
    "    \n",
    "    dict_output = {'conn_matrices': conn_matrices, 'sub_list': sub_list}\n",
    "    \n",
    "    return dict_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a341ca3-4eca-414b-a125-d5d3f9da7c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_gradients(mean_conn_matrix, display_output = True, data_reduction_algorithm = 'dm', save_screenshot = False, output_dir = None, sample_modality = None):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Function that computes the mean gradients from mean connectivity matrix (across subjects)\n",
    "    \n",
    "    Input:\n",
    "    - mean_conn_matrix: variable containing mean connectivity matrix across subjects\n",
    "    - display_output: True (default) or False - displays the plots specified below\n",
    "    - data_reduction_algorithm: used to compute the gradients. Options: 'dm' (diffusion map embedding; default), 'le' (laplacian eigenmaps), 'pca' (principal component analysis)\n",
    "    - save_screenshot: True or False - if you want to save screenshot in output_dir. If True, the plots do not get displayed - so if want to save, need to run with True and then False to leave the plots visible in notebook\n",
    "    - output_dir: path to output directory (e.g. resdir_fig, i.e. '/data/p_02667/sex_diff_gradients/HCP/results/')\n",
    "    - sample_modality: string, e.g. GSP_local_ct or HCP_fc (for name of figures saved in output_dir)\n",
    "    \n",
    "    Output (display):\n",
    "    - mean connectivity matrix + shape\n",
    "    - 3 first mean connectivity gradients\n",
    "    - scree plot of the variance explained by the 10 gradients + printed detail of variance explained and scaled varience explained\n",
    "    \n",
    "    Output:\n",
    "    - mean_grad: the mean gradients, computed from the mean connectivity matrix with default parameters (diffusion map embedding, 10 gradients, normalized angle, threshold (fit -> sparsity = 0.90)\n",
    "    \n",
    "    \n",
    "    '''  \n",
    "    \n",
    "    ## compute the mean gradients \n",
    "    \n",
    "    # GradientMaps function used to build the model parameters\n",
    "    mean_grad = GradientMaps(n_components = 10, random_state = 0, approach = data_reduction_algorithm, kernel = 'normalized_angle')\n",
    "\n",
    "    # fit function used to compute the gradients\n",
    "    mean_grad.fit(mean_conn_matrix)\n",
    "    \n",
    "    \n",
    "    if display_output:\n",
    "        \n",
    "        ## plot the mean connectivity matrix and shape\n",
    "        \n",
    "        plt.imshow(mean_conn_matrix)\n",
    "        plt.show()\n",
    "        print(mean_conn_matrix.shape)\n",
    "        \n",
    "        \n",
    "        ## plot the 3 first mean gradients\n",
    "        \n",
    "        # defining labeling scheme and mask\n",
    "        labeling = load_parcellation('schaefer', scale=400, join=True)\n",
    "        surf_lh, surf_rh = load_conte69()\n",
    "        mask = labeling != 0\n",
    "\n",
    "        # list containing placeholders (None) for the number of gradients I want to plot\n",
    "        grad = [None] * 3\n",
    "\n",
    "        for i in range(3):\n",
    "            # map the gradient to the parcels\n",
    "            grad[i] = map_to_labels((mean_grad.gradients_)[:, i], labeling, mask=mask, fill=np.nan)  # mean_grad contains 10 .gradients_ (1 gradient per column) - here I take all rows and individual select column based on gradient I want (first 3)\n",
    "\n",
    "        plot = plot_hemispheres(surf_lh, \n",
    "                                surf_rh, \n",
    "                                array_name=grad, \n",
    "                                embed_nb = True, \n",
    "                                size=(1200, 400),\n",
    "                                cmap='viridis_r', \n",
    "                                nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                color_bar=True, \n",
    "                                label_text=['Gradient 1', 'Gradient 2', 'Gradient 3'], \n",
    "                                zoom=1.55,\n",
    "                                screenshot = save_screenshot,\n",
    "                                filename = output_dir+sample_modality+'_plotted_hemispheres_mean_gradients.png')\n",
    "        \n",
    "        display(plot)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Gradient 1 to save with the correct parameters\n",
    "        mean_G1 = map_to_labels((mean_grad.gradients_)[:, 0], labeling, mask=mask, fill=np.nan)  # mean_grad contains 10 .gradients_ (1 gradient per column) - here I take all rows and individual select column based on gradient I want (first 3)\n",
    "\n",
    "        plot_mean_G1 = plot_hemispheres(surf_lh, \n",
    "                                surf_rh, \n",
    "                                array_name=mean_G1, \n",
    "                                embed_nb = True, \n",
    "                                size= (1400,200), \n",
    "                                cmap='viridis_r', \n",
    "                                color_bar=True, \n",
    "                                nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                label_text=['Mean G1'], \n",
    "                                zoom=1.45,\n",
    "                                screenshot = save_screenshot,\n",
    "                                filename = output_dir+sample_modality+'_plotted_hemispheres_mean_G1.png')\n",
    "        \n",
    "\n",
    "        ## plot the variance explained by the 10 gradients\n",
    "\n",
    "        fig, ax = plt.subplots(1, figsize=(5, 4))\n",
    "        ax.scatter(range(mean_grad.lambdas_.size), mean_grad.lambdas_)\n",
    "        ax.set_title(\"Variance explained by the 10 gradients\")\n",
    "        ax.set_xlabel('Component Nb')\n",
    "        ax.set_ylabel('Eigenvalue')\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"Total amount of variance explained by the {len(mean_grad.lambdas_)} gradients (uncorrected sum lambdas): {sum(mean_grad.lambdas_):.2f}\\n\")\n",
    "\n",
    "        # Scaled variance explained by individual gradients: lambda / total(i.e., sum lambdas) * 100 %\n",
    "        print(f\"Scaled variance explained by individual gradients:\\nG1: {mean_grad.lambdas_[0]/sum(mean_grad.lambdas_)*100:.2f}%\\nG2: {mean_grad.lambdas_[1]/sum(mean_grad.lambdas_)*100:.2f}%\\nG3: {mean_grad.lambdas_[2]/sum(mean_grad.lambdas_)*100:.2f}%\\n\")\n",
    "\n",
    "    \n",
    "    return mean_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5b80ad2-1162-4c48-b8ee-b82a54fe2519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_aligned_gradients(conn_matrices, mean_grad_for_alignment, data_reduction_algorithm = 'dm'):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Function that computes the alligned gradients from all subject connectivity matrices\n",
    "    \n",
    "    Input:\n",
    "    - variable containing all subject connectivity matrices\n",
    "    - array of the gradients to which the individual gradients should be aligned (the mean connectivity gradients)\n",
    "    - data_reduction_algorithm: used to compute the gradients. Options: 'dm' (diffusion map embedding; default), 'le' (laplacian eigenmaps), 'pca' (principal component analysis)\n",
    "    \n",
    "    Output (dictionary containing arrays):  \n",
    "    - array_aligned_gradients\n",
    "    - array_aligned_G1\n",
    "    - array_aligned_G2\n",
    "    - array_aligned_G3\n",
    "    \n",
    "    Gradients computed from the mean connectivity matrix with default parameters (diffusion map embedding, 10 gradients, normalized angle, threshold (fit -> sparsity = 0.90)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    list_aligned_gradients = []  # will contain all participants (1014), all parcels (400), all gradients (10)\n",
    "    list_aligned_G1 = []  # will contain all participants (1014), all parcels (400) -> values = loadings for GRADIENT 1\n",
    "    list_aligned_G2 = []  # will contain all participants (1014), all parcels (400) -> values = loadings for GRADIENT 2\n",
    "    list_aligned_G3 = []  # will contain all participants (1014), all parcels (400) -> values = loadings for GRADIENT 3\n",
    "\n",
    "    # loop over all the connectivity matrices\n",
    "    for i in range(len(conn_matrices)):\n",
    "        # setting model parameters for gradients to be computed across subjects - with procrustes alignment\n",
    "        grad_procr = GradientMaps(n_components=10, random_state=0, approach = data_reduction_algorithm, kernel='normalized_angle', alignment='procrustes')  # specify alignment method here (procrustes)\n",
    "\n",
    "        # computing\n",
    "        # note that by using an alignment method, .fit yields a variable (grad_procr) containing both types of gradients, callable with: .gradients_ (original) and .aligned_ \n",
    "          # use ._gradients for mean_grad_for_alignment (mean grad was not even calculated with a reference so doesn't have ._aligned) and use .aligned_ for grad_procr \n",
    "\n",
    "        grad_procr.fit(conn_matrices[i], reference=mean_grad_for_alignment)  # align to the gradients of the gradients produced by the mean matrix (reference) \n",
    "\n",
    "        # append array to lists results (.T is necessary in order to be able to first access the gradients layer (10) so that can index the desired gradient, which will then contain all the parcels (400)\n",
    "        list_aligned_gradients.append(grad_procr.aligned_)\n",
    "        list_aligned_G1.append(grad_procr.aligned_.T[0])\n",
    "        list_aligned_G2.append(grad_procr.aligned_.T[1])\n",
    "        list_aligned_G3.append(grad_procr.aligned_.T[2])\n",
    "\n",
    "    # make gradient lists into arrays (for analyses)    \n",
    "    array_aligned_gradients = np.array(list_aligned_gradients)\n",
    "    array_aligned_G1 = np.array(list_aligned_G1)\n",
    "    array_aligned_G2 = np.array(list_aligned_G2)\n",
    "    array_aligned_G3 = np.array(list_aligned_G3)\n",
    "        \n",
    "        \n",
    "    ### dictionary to output\n",
    "    \n",
    "    dict_output = {'array_aligned_gradients': array_aligned_gradients, 'array_aligned_G1': array_aligned_G1, 'array_aligned_G2': array_aligned_G2, 'array_aligned_G3': array_aligned_G3}\n",
    "    \n",
    "    \n",
    "    return dict_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef128b14-2ab9-479b-b196-8b0593a98df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RainCloudPlot_YeoNetworks_SexComparison(array_grad, sex_comp = None):\n",
    "    \n",
    "    ''' \n",
    "    \n",
    "    Function that produced RainCloud Plots of gradient loadings (mean across subjects for each parcel), color coded by Yeo network, compared across sexes\n",
    "    \n",
    "    The distribuitions by network (as displayed in different colors) show the differences between parcels belonging to the same network (because each point is 1 parcel; the mean is calculated across subjects for that parcel)\n",
    "    -> emphasis is on displaying the gradient loadings of parcels belonging to the same network (spread of distribution -integration/segregation- of parcels belonging to the same network)\n",
    "    \n",
    "    \n",
    "    Input:\n",
    "    - array_grad: gradient array\n",
    "    - sex_comp: variable used for sex comparison in list or series format\n",
    "    \n",
    "    Output (display):  \n",
    "    - RainCloudPlot of mean gradient loadings across subjects per parcel, color coded by Yeo network, compard by sex\n",
    "\n",
    "   \n",
    "    '''\n",
    "    \n",
    "        \n",
    "    ## format gradient array for plotting\n",
    "    # for the RainCloud plots, we need dataframe to have all values to be plotted in 1 column (y), and labels to be plotted in other columns (max 2: x (sex) and hue (coloring by Yeo network))\n",
    "\n",
    "    # dataframe of gradient loadings (shape: sub (vertical) x parcels (horizontal))\n",
    "    df_grad = pd.DataFrame(array_grad)\n",
    "\n",
    "    # adding a column containing the labels for the sex comparison\n",
    "    df_grad[\"sex\"] = sex_comp.tolist()\n",
    "\n",
    "    # separatating the dataframe into two dataframes containing only subjects of the given sex (because need to calculate mean across subjects for each parcel)\n",
    "    df_grad_cat_M = df_grad[df_grad[\"sex\"] == 'M']\n",
    "    df_grad_cat_F = df_grad[df_grad[\"sex\"] == 'F']\n",
    "\n",
    "    # removing the label of sex for the moment because need to have only the parcels in the same column\n",
    "    df_grad_cat_M = df_grad_cat_M.drop('sex', axis=1)\n",
    "    df_grad_cat_F = df_grad_cat_F.drop('sex', axis=1)\n",
    "\n",
    "    # transposing because we want the 400 parcels to be vertical in the dataframe in order to calculate mean by parcel\n",
    "    df_grad_cat_M = df_grad_cat_M.T\n",
    "    df_grad_cat_F = df_grad_cat_F.T\n",
    "\n",
    "    # adding a column containing the mean gradient loading across subjects per parcel\n",
    "    df_grad_cat_M['mean gradient loadings across subjects per parcel'] = df_grad_cat_M.mean(axis=1)\n",
    "    df_grad_cat_F['mean gradient loadings across subjects per parcel'] = df_grad_cat_F.mean(axis=1)\n",
    "\n",
    "    # adding a column containing the Yeo network labels\n",
    "    df_grad_cat_M['yeo network'] = yeo7_networks_array_labels\n",
    "    df_grad_cat_F['yeo network'] = yeo7_networks_array_labels\n",
    "\n",
    "    # take a subset of the dataframes (only keep mean gradient loadings across subjects per parcels and yeo network labels, remove the individual subject values per parcel)\n",
    "    df_grad_cat_M = df_grad_cat_M[[\"mean gradient loadings across subjects per parcel\", \"yeo network\"]]\n",
    "    df_grad_cat_F = df_grad_cat_F[[\"mean gradient loadings across subjects per parcel\", \"yeo network\"]]\n",
    "\n",
    "    # add label of sex for each dataframe before merging them in order to make males and females identifiable for plotting\n",
    "    df_grad_cat_M['sex'] = 'M'\n",
    "    df_grad_cat_F['sex'] = 'F'\n",
    "\n",
    "    # concatenate the two datasets (by index in order to have rows = parcels from both datasets)\n",
    "    df_to_plot = pd.concat([df_grad_cat_M, df_grad_cat_F], axis = 'index')\n",
    "\n",
    "\n",
    "\n",
    "    ## plot \n",
    "    \n",
    "    f,ax=plt.subplots(figsize=(20,15))\n",
    "\n",
    "    ax=pt.RainCloud(x=\"sex\",\n",
    "                    y=\"mean gradient loadings across subjects per parcel\",\n",
    "                    hue=\"yeo network\",\n",
    "                    data=df_to_plot,\n",
    "                    palette=palette_labeled_networks,\n",
    "                    bw=.2,\n",
    "                    width_viol=.6,\n",
    "                    orient=\"h\",\n",
    "                    move=.2,\n",
    "                    alpha=.65,\n",
    "                    pointplot=True, \n",
    "                    dodge = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc26ec4e-7512-4d0e-87c4-bb4ce01f74c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RainCloudPlot_YeoNetworks_SexComparison_IndDiff(array_grad, sex_comp = None, plot_type = ['across sexes overlayed', 'across sexes separate', 'by sex overlayed', 'by sex separate']):\n",
    "    \n",
    "    ''' \n",
    "\n",
    "     --- don't use this function, only keeping it for reference for individual differences, but what I am using to understand results is function RainCloudPlot_YeoNetworks_SexComparison ---\n",
    "     \n",
    "     \n",
    "    Function that produced Rain Cloud Plots of gradient loadings by Yeo network and optionally by sex \n",
    "    OLD function: the distribution by network shows the differences between subjects (because each point is 1 subject; the mean is calculated across parcels belonging to that same network) -> emphasis is on individual differences\n",
    "     \n",
    "    \n",
    "    Input:\n",
    "    - array_grad: gradient array\n",
    "    - sex_comp: variable used for sex comparison in list or series format\n",
    "    - plot_type: plot type display - should be one of the following 'across sexes overlayed', 'across sexes separate', 'by sex overlayed', 'by sex separate'\n",
    "    \n",
    "    Output (display):  \n",
    "    - RainCloudPlot - display according to specified plot_type\n",
    "\n",
    "   \n",
    "    '''\n",
    "    \n",
    "    # defining conflicting inputted parameters - error messages\n",
    "    if sex_comp is not None and plot_type == 'across sexes overlayed' or sex_comp is not None and plot_type == 'across sexes separate':\n",
    "        print('ERROR: Conflicting inputted parameters - if you want across sexes, you must input sex_comp = None')\n",
    "    \n",
    "    elif sex_comp is None and plot_type == 'by sex overlayed' or sex_comp is None and plot_type == 'by sex separate':\n",
    "         print('ERROR: Conflicting inputted parameters - if you want by sex, you must provide a variable for sex_comp')\n",
    "            \n",
    "    # if no conflicting parameters, can procede with formatting gradient array for plotting and plotting \n",
    "    else:\n",
    "        \n",
    "        ## format gradient array for plotting\n",
    "        \n",
    "        # dataframe of the G1 loadings (transposing the original array because we need the 400 parcels to be vertical in the dataframe in order to be labeled with their corresponding Yeo network)\n",
    "        df_grad = pd.DataFrame(array_grad.T)\n",
    "\n",
    "        # adding a column containing the Yeo network labels\n",
    "        df_grad['yeo network'] = yeo7_networks_array_labels\n",
    "\n",
    "        # obtaining the mean of the parcels with the same Yeo network label, then transposing because we need all subjects to be vertical (1 subject per row) in the dataframe in order to be labeled with their corresponding sex for comparison \n",
    "        df_grad = df_grad.groupby(\"yeo network\", as_index=True).mean().T\n",
    "\n",
    "        \n",
    "        if sex_comp is None:\n",
    "            df_grad[\"categorical comparison\"] = [1] * len(df_grad)  # making a column of just 1s so that there is no categorical comparison to display (all subject belong in same group)\n",
    "            \n",
    "        else:    \n",
    "            # adding a column containing the labels for the categorical comparison (according to inputted categorical variable\n",
    "            df_grad[\"categorical comparison\"] = sex_comp.tolist()\n",
    "\n",
    "        # naming the index and resetting it as an index in order to make it callable in the following melt function\n",
    "        df_grad.index.name = \"sub\"\n",
    "        df_grad = df_grad.reset_index()\n",
    "\n",
    "        # for the RainCloud plots, we need dataframe to have all values to be plotted in 1 column, and labels to be plotted in other columns (max 2)\n",
    "        # using melt() to make dataframe long so that mean loadings per network are in one column, whilst preserving the sub number and sex as ID variables\n",
    "        df_grad=pd.melt(df_grad, id_vars=[\"sub\", 'categorical comparison'], var_name='yeo network', value_name='mean gradient loadings across parcels per subject')\n",
    "\n",
    "\n",
    "\n",
    "        ## plot depending on requested plot type\n",
    "\n",
    "        if plot_type == 'across sexes overlayed':\n",
    "            f,ax=plt.subplots(figsize=(20,15))\n",
    "\n",
    "            ax=pt.RainCloud(x=\"categorical comparison\",\n",
    "                            y=\"mean gradient loadings across parcels per subject\",\n",
    "                            hue=\"yeo network\",\n",
    "                            data=df_grad,\n",
    "                            palette=palette_labeled_networks,\n",
    "                            bw=.2,\n",
    "                            width_viol=.6,\n",
    "                            orient=\"h\",\n",
    "                            move=.2,\n",
    "                            alpha=.65,\n",
    "                            pointplot=False, \n",
    "                            dodge = True)\n",
    "\n",
    "        elif plot_type == 'across sexes separate':    \n",
    "            f,ax=plt.subplots(figsize=(20,15))\n",
    "\n",
    "            ax=pt.RainCloud(x=\"yeo network\",\n",
    "                            y=\"mean gradient loadings across parcels per subject\",\n",
    "                            #hue=\"yeo network\",\n",
    "                            data=df_grad,\n",
    "                            palette=palette_labeled_networks,\n",
    "                            bw=.2,\n",
    "                            width_viol=.6,\n",
    "                            orient=\"h\",\n",
    "                            move=.2,\n",
    "                            alpha=.65,\n",
    "                            pointplot=False, \n",
    "                            dodge = True)\n",
    "\n",
    "\n",
    "        elif plot_type == 'by sex overlayed':\n",
    "            f,ax=plt.subplots(figsize=(20,15))\n",
    "\n",
    "            ax=pt.RainCloud(x=\"categorical comparison\",\n",
    "                            y=\"mean gradient loadings across parcels per subject\",\n",
    "                            hue=\"yeo network\",\n",
    "                            data=df_grad,\n",
    "                            palette=palette_labeled_networks,\n",
    "                            bw=.2,\n",
    "                            width_viol=.6,\n",
    "                            orient=\"h\",\n",
    "                            move=.2,\n",
    "                            alpha=.65,\n",
    "                            pointplot=True, \n",
    "                            dodge = True)\n",
    "\n",
    "\n",
    "        elif plot_type == 'by sex separate':\n",
    "\n",
    "            f,ax=plt.subplots(figsize=(20,15))\n",
    "\n",
    "            ax=pt.RainCloud(x=\"yeo network\",\n",
    "                            y=\"mean gradient loadings across parcels per subject\",\n",
    "                            hue=\"categorical comparison\",\n",
    "                            data=df_grad,\n",
    "                            palette=sns.color_palette(n_colors=2),\n",
    "                            bw=.2,\n",
    "                            width_viol=.6,\n",
    "                            #figsize=(7,5),  # DELETE THIS\n",
    "                            orient=\"h\",\n",
    "                            move=.2,\n",
    "                            alpha=.65, \n",
    "                            dodge=True)\n",
    "\n",
    "        else:\n",
    "            print(\"ERROR: mis-specified plot_type. Please choose from: 'across sexes overlayed', 'across sexes separate', 'by sex overlayed', 'by sex separate'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86b84223-e8da-4a8f-864a-4b580ca96163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_reg_results_R(reg_res, contrast_type, save_screenshot = False, output_dir = None, res_statistic = 'beta_val', sample_modality = None, categorical_contrast = True):\n",
    "    \n",
    "    '''\n",
    "    Function that plots regression results coming from R script (t-values, p-values, FDR corrected q-values, and t-values corresponding to sig FDR corrected q values)\n",
    "    \n",
    "    Input: \n",
    "    - reg_res: slm results dataframe containing vales with the following names: t_val, p_val, q_val, beta_val\n",
    "    - contrast type: string indicating the contrast that is being studied, e.g., 'sex' (for figure name and plot titles)\n",
    "    - save_screenshot: True or False - if you want to save screenshot in output_dir. If True, the plots do not get displayed - so if want to save, need to run with True and then False to leave the plots visible in notebook\n",
    "    - output_dir: path to output directory (e.g. resdir_fig, i.e. '/data/p_02667/sex_diff_gradients/results/figures/')\n",
    "    - res_statistic: what test statistic you want to be displayed as result, i.e., 't_val' or 'beta_val'. Default is beta_val\n",
    "    - sample_modality: string, e.g. GSP_local_ct or HCP_fc_G1 (for name of figures saved in output_dir)\n",
    "    - categorical_contrast: whether the contrast that is being plotted is categorical (e.g., sex) as opposed to continuous (e.g., geodesic distance). Default is True \n",
    "    \n",
    "    Specific to plotting on surf_lh, surf_rh from conte69; for data coming from Schaefer 400 parcellation\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # defining the colormaps for plotting on hemispheres of t-values depending on whether the contrast we're looking at is categorical (e.g., male vs female) or continuous (e.g., geodesic distance)\n",
    "    if categorical_contrast:\n",
    "        cmap_tval = \"bwr_r\"  # bwr, _r stands for reversed; using it to match male-blue female-red \n",
    "    else:\n",
    "        cmap_tval = \"PRGn\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    # defining \n",
    "    chosen_statistic = reg_res.loc[:, res_statistic]\n",
    "    p_val = reg_res.loc[:, 'p_val']\n",
    "    q_val = reg_res.loc[:, 'q_val']\n",
    "    \n",
    "    \n",
    "    # defining labeling scheme and mask\n",
    "    labeling = load_parcellation('schaefer', scale=400, join=True)\n",
    "    surf_lh, surf_rh = load_conte69()\n",
    "    mask = labeling != 0\n",
    "    \n",
    "    \n",
    "    # will contain the different plots\n",
    "    handles = []\n",
    "    \n",
    "    \n",
    "    ### beta- or t-values\n",
    "    tvals_mapped_to_labels = map_to_labels(np.asarray(chosen_statistic), labeling, mask=mask, fill=np.nan)  # t[0] because there is a double bracket for the t-values array, need [0] to access the values themselves\n",
    "    \n",
    "    tvals_plotted_hemispheres = plot_hemispheres(\n",
    "        surf_lh, \n",
    "        surf_rh, \n",
    "        array_name = tvals_mapped_to_labels, \n",
    "        embed_nb = True, \n",
    "        size = (1400,200), \n",
    "        cmap = cmap_tval,  \n",
    "        color_bar = True, \n",
    "        color_range='sym',\n",
    "        nan_color = (0.7, 0.7, 0.7, 1),\n",
    "        label_text = [res_statistic],\n",
    "        zoom = 1.45, \n",
    "        screenshot = save_screenshot,\n",
    "        filename = output_dir+sample_modality+'_plotted_hemispheres_'+contrast_type+'_contrast_'+res_statistic+'.png')\n",
    "    \n",
    "    # plot\n",
    "    handles.append(tvals_plotted_hemispheres)\n",
    "       \n",
    "        \n",
    "    \n",
    "    ### p-values (uncorrected)\n",
    "    \n",
    "    #assigning to new variable using copy() so that changes made in copy will not affect the original array\n",
    "    pvals = np.asarray(p_val.copy())\n",
    "\n",
    "    # only keep Q-values that are significant (replacing values > 0.05 with nan)\n",
    "    np.place(pvals, pvals > 0.05, np.nan) \n",
    "    \n",
    "    # this maps shape (400,) turning it inot shape (64984,)\n",
    "    pvals_mapped_to_labels = map_to_labels(pvals, labeling, mask=mask, fill=np.nan)\n",
    "    \n",
    "    # plot\n",
    "    pvals_plotted_hemispheres =  plot_hemispheres(\n",
    "        surf_lh, \n",
    "        surf_rh, \n",
    "        array_name = pvals_mapped_to_labels, \n",
    "        embed_nb = True, \n",
    "        size = (1400,200), \n",
    "        cmap = \"plasma_r\", \n",
    "        color_bar = True, \n",
    "        #color_range = color_range_Q,\n",
    "        nan_color = (0.7, 0.7, 0.7, 1),\n",
    "        label_text = [\"p-values (uncorr.)\"],\n",
    "        zoom = 1.45,\n",
    "        screenshot = save_screenshot,\n",
    "        filename = output_dir+sample_modality+'_plotted_hemispheres_'+contrast_type+'_contrast_p_val.png')\n",
    "    \n",
    "    handles.append(pvals_plotted_hemispheres)    \n",
    "        \n",
    "        \n",
    "                   \n",
    "    ### Q-values\n",
    "    \n",
    "    #assigning to new variable using copy() so that changes made in copy will not affect the original array\n",
    "    Qvals = np.asarray(q_val.copy())\n",
    "\n",
    "    # only keep Q-values that are significant (replacing values > 0.05 with nan)\n",
    "    np.place(Qvals, Qvals > 0.05, np.nan) \n",
    "    \n",
    "    # this maps shape (400,) turning it inot shape (64984,)\n",
    "    Qvals_mapped_to_labels = map_to_labels(Qvals, labeling, mask=mask, fill=np.nan)\n",
    "    \n",
    "    # plot\n",
    "    Qvals_plotted_hemispheres =  plot_hemispheres(\n",
    "        surf_lh, \n",
    "        surf_rh, \n",
    "        array_name = Qvals_mapped_to_labels, \n",
    "        embed_nb = True, \n",
    "        size = (1400,200), \n",
    "        cmap = \"plasma_r\", \n",
    "        color_bar = True, \n",
    "        #color_range = color_range_Q,\n",
    "        nan_color = (0.7, 0.7, 0.7, 1),\n",
    "        label_text = [\"Q-values\"],\n",
    "        zoom = 1.45,\n",
    "        screenshot = save_screenshot,\n",
    "        filename = output_dir+sample_modality+'_plotted_hemispheres_'+contrast_type+'_contrast_q_val.png')\n",
    "    \n",
    "    handles.append(Qvals_plotted_hemispheres)\n",
    "    \n",
    "    \n",
    "    ### beta- or t-values (only FDR-corrected) showing sex differences\n",
    "    \n",
    "    ## find t-values\n",
    "    fdr_corrected_tvals = []\n",
    "    \n",
    "    for i in range(len(q_val)):\n",
    "        if q_val[i] <= 0.05:\n",
    "            fdr_corrected_tvals.append(chosen_statistic[i])\n",
    "        else:\n",
    "            fdr_corrected_tvals.append(float('nan'))\n",
    "    \n",
    "    fdr_corr_tvals_mapped_to_labels = map_to_labels(np.asarray(fdr_corrected_tvals), labeling, mask=mask, fill=np.nan)\n",
    "    \n",
    "    fdr_corr_tvals_plotted_hemispheres = plot_hemispheres(\n",
    "        surf_lh, \n",
    "        surf_rh, \n",
    "        array_name = fdr_corr_tvals_mapped_to_labels, \n",
    "        embed_nb = True, \n",
    "        size = (1400,200), \n",
    "        cmap = cmap_tval,\n",
    "        color_bar = True, \n",
    "        color_range='sym',\n",
    "        nan_color = (0.7, 0.7, 0.7, 1),\n",
    "        label_text = [res_statistic+'\\nFDR-corrected'],\n",
    "        zoom = 1.45,\n",
    "        screenshot = save_screenshot,\n",
    "        filename = output_dir+sample_modality+'_plotted_hemispheres_'+contrast_type+'_contrast_'+res_statistic+'_fdr_corr.png')\n",
    "    \n",
    "    # plot\n",
    "    handles.append(res_statistic+' FDR-corrected q < 0.05: (male: blue, female: red)')  # title\n",
    "    handles.append(fdr_corr_tvals_plotted_hemispheres)\n",
    "    \n",
    "                                           \n",
    "    return handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef648a5c-344b-4736-bc7b-d80c9d9d39cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_contrast_results_breakdown_by_network(reg_res, contrast_type, scatterplot = True, scatter_x = None, scatter_y = None, scatter_x_label = None, scatter_y_label = None, sample_modality = None, output_dir = None, categorical_contrast = True):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Function that outputs the breakdown of regression contrast results by network\n",
    "    \n",
    "    !!! TO DO to improve function output (and code labels): this is not only used for sex contrast, so could change the \"M and F\" labels to \"plus and minus\" here in code but also in output (when I say \"by sex\" or Males vs Females)\n",
    "    # -> except M and F labels in inner ring of nested pie chart -> makes no sense to have the labels be \"plus\" and \"minus\" - for now I am leaving it; I am not using those figures anyway\n",
    "    \n",
    "    \n",
    "    Input:\n",
    "    - reg_res: regression results (in fomrat: DataFrame, containing columns 'q_val' and 't_val', len = 400 parcels (Schaeffer400))\n",
    "    - contrast type: string indicating the contrast that is being studied, e.g., 'sex' (for figure name and plot titles)\n",
    "    - scatter_x: x-axis of the scatterplot G1 vs G2 -> so G1 or G2 from mean gradient (in array format)\n",
    "    - scatter_y: y-axis of the scatterplot G1 vs G2 -> so G1 or G2 from mean gradient (in array format)\n",
    "    - scatter_x_label, scatter_y_label\n",
    "    - output_dir: path to output directory (e.g. resdir_fig, i.e. '/data/p_02667/sex_diff_gradients/results/figures/')\n",
    "    - sample_modality: string, e.g. GSP_local_ct or HCP_fc_G1 (for name of figures saved in output_dir)\n",
    "    - categorical_contrast: whether the contrast that is being plotted is categorical (e.g., sex) as opposed to continuous (e.g., geodesic distance). Default is True \n",
    "    \n",
    "    Output (display):\n",
    "    - written breakdown (number and proportion of significant parcels by network (relative proportion (i.e., out of all the parcels belonging to a given network) and absolute proportion (i.e., out of the total significant results)\n",
    "    - plotted breakdown (pie chart) - proportion of significant parcels by network (absolute proportion)\n",
    "    - plotted breakdown by sex (nested pie chart) - proportion of significant parcels by network (absolute proportion) by sex <- !!! HARDCODED M vs F labels !!! - color coding with original Yeo network colors\n",
    "    - plotted breadown by sex (nested pie chart) - same as above, WITHOUT LABELS\n",
    "    - scatter plot showing of G1 vs G2, displaying parcels showing a significant contrast in dark\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ### required variables\n",
    "    \n",
    "    ## yeo network numbered labels (hardcoded path)\n",
    "    # labels: 1=visual, 2=sensory motor, 3=dorsal attention, 4=ventral attention, 5=limbic, 6=fronto parietal, 7= DMN\n",
    "    #yeo7_networks_array = np.genfromtxt(datadir+'yeo_7.csv', delimiter=',', skip_header=0)\n",
    "    \n",
    "    \n",
    "    # making an array with yeo network labels (names instead of numbers)\n",
    "    yeo7_networks_array_labels = []\n",
    "\n",
    "    for i in yeo7_networks_array:\n",
    "        if i == 1:\n",
    "            yeo7_networks_array_labels.append('visual')\n",
    "        elif i == 2:\n",
    "            yeo7_networks_array_labels.append('sensory motor')\n",
    "        elif i == 3:\n",
    "            yeo7_networks_array_labels.append('dorsal attention')\n",
    "        elif i == 4:\n",
    "            yeo7_networks_array_labels.append('ventral attention')\n",
    "        elif i == 5:\n",
    "            yeo7_networks_array_labels.append('limbic')\n",
    "        elif i == 6:\n",
    "            yeo7_networks_array_labels.append('fronto parietal')\n",
    "        elif i == 7:\n",
    "            yeo7_networks_array_labels.append('DMN')\n",
    "\n",
    "    yeo7_networks_array_labels = np.asarray(yeo7_networks_array_labels)\n",
    "    \n",
    "    \n",
    "    network_names = [\"visual\", \"sensory motor\", \"DMN\", \"dorsal attention\", \"ventral attention\", \"limbic\", \"fronto parietal\"]\n",
    "    network_names_abbreviated = [\"V\", \"SM\", \"DMN\", \"DA\", \"VA\", \"L\", \"FP\"]\n",
    "\n",
    "    \n",
    "    \n",
    "    ### written breakdown\n",
    "    \n",
    "    # counting number of significant parcels\n",
    "    # storing the Q values in a list (where non significant Q values are marked as 1 -> for later potential scatterplot visualization)\n",
    "    # making a dictionary that counts the number of significant parcels per yeo network\n",
    "    # making dictionaries that count the number of significant parcels per yeo network by sex\n",
    "    \n",
    "    sig_Q_vals_slm = []\n",
    "    count_sig = 0\n",
    "    count_sig_M = 0\n",
    "    count_sig_F = 0\n",
    "    count_sig_per_network = {\"visual\": 0, \"sensory motor\": 0, \"DMN\": 0, \"dorsal attention\": 0, \"ventral attention\": 0, \"limbic\": 0, \"fronto parietal\": 0}\n",
    "    count_sig_per_network_bysex = {\"visual\": [0,0], \"sensory motor\": [0,0], \"DMN\": [0,0], \"dorsal attention\": [0,0], \"ventral attention\": [0,0], \"limbic\": [0,0], \"fronto parietal\": [0,0]} # M: [0], F: [1]\n",
    "    \n",
    "    for i in range(len(reg_res.q_val)):\n",
    "    \n",
    "        if reg_res.q_val[i] < 0.05:\n",
    "            count_sig += 1\n",
    "            count_sig_per_network[yeo7_networks_array_labels[i]] += 1\n",
    "            sig_Q_vals_slm.append(1)\n",
    "    \n",
    "            # positive t-values mean male > female: increment the first item of the list fort given label\n",
    "            if reg_res.t_val[i] > 0:\n",
    "                count_sig_M += 1\n",
    "                count_sig_per_network_bysex[yeo7_networks_array_labels[i]][0] += 1\n",
    "            \n",
    "            # negative t-values mean female > male: increment the second item of the list for the given label\n",
    "            else:\n",
    "                count_sig_F += 1\n",
    "                count_sig_per_network_bysex[yeo7_networks_array_labels[i]][1] += 1\n",
    "        \n",
    "        else:\n",
    "            sig_Q_vals_slm.append(0)\n",
    "    \n",
    "    print(f\"Number of significant parcels: {count_sig}\\n\")\n",
    "    print(f\"Number of significant parcels for males: {count_sig_M}\")\n",
    "    print(f\"Number of significant parcels for females: {count_sig_F}\\n\")\n",
    "    print(\"Number of significant parcels in each Yeo network (across sexes):\")\n",
    "    \n",
    "    # using ANSI escape sequences to underline -> bold: \\033[1m ; underline: \\033[4m ; end: \\033[0m\n",
    "    for i in range(len(count_sig_per_network)):\n",
    "        print(f\"- {list(count_sig_per_network.keys())[i]}: \\033[4m{count_sig_per_network[list(count_sig_per_network.keys())[i]]}\\033[0m out of {yeo7_networks_array_labels.tolist().count(network_names[i])} ({round(count_sig_per_network[list(count_sig_per_network.keys())[i]] / yeo7_networks_array_labels.tolist().count(network_names[i]) * 100, 2)}%) -> \\033[1m{round(count_sig_per_network[list(count_sig_per_network.keys())[i]]*100/count_sig,2)}%\\033[0m of overall significance\")\n",
    "    \n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    \n",
    "    ### Nested pie chart\n",
    "    \n",
    "    ## make data plottable\n",
    "    list_count_sig_per_network_bysex = []\n",
    "    \n",
    "    for label in count_sig_per_network_bysex:\n",
    "        list_count_sig_per_network_bysex.append(count_sig_per_network_bysex[label])\n",
    "    \n",
    "    vals = np.array(list_count_sig_per_network_bysex)\n",
    "    \n",
    "    outer_colors = [\"darkorchid\",  # visual\n",
    "                    \"steelblue\",  # sensorimotor\n",
    "                    \"indianred\",  # dmn\n",
    "                    \"forestgreen\",  # dorsal attention\n",
    "                    \"orchid\",  # ventral attention\n",
    "                    \"lemonchiffon\",  # limbic\n",
    "                    \"orange\"]  # frontoparietal\n",
    "    \n",
    "    \n",
    "    if categorical_contrast: \n",
    "        inner_color_plus = 'lightblue'\n",
    "        inner_color_minus = 'lightcoral'\n",
    "    else:\n",
    "        inner_color_plus = 'darkseagreen'\n",
    "        inner_color_minus =  'plum'\n",
    "    \n",
    "    \n",
    "    inner_colors = [inner_color_plus, inner_color_minus,  # visual\n",
    "                    inner_color_plus, inner_color_minus,  # sensorimotor\n",
    "                    inner_color_plus, inner_color_minus,  # dmn\n",
    "                    inner_color_plus, inner_color_minus,  # dorsal attention\n",
    "                    inner_color_plus, inner_color_minus,  # ventral attention\n",
    "                    inner_color_plus, inner_color_minus,  # limbic\n",
    "                    inner_color_plus, inner_color_minus]  #frontoparietal\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    \n",
    "    size = 0.3\n",
    "    \n",
    "    ## plot outer pie\n",
    "    ax.pie(vals.sum(axis=1), radius=1, labels=count_sig_per_network_bysex.keys(), colors=outer_colors, autopct='%.0f%%', pctdistance=0.85,\n",
    "           wedgeprops=dict(width=size, edgecolor='white'),  textprops={'fontsize': 20})\n",
    "    \n",
    "    ## plot inner pie\n",
    "    \n",
    "    # make a list (in order) containing the labels (sex - hardcoded) only for sections that have more than 1 count (otherwise label is placeholder: blank)\n",
    "    \n",
    "    labels_only_show_non_null = []\n",
    "    \n",
    "    for network in list_count_sig_per_network_bysex:\n",
    "    \n",
    "        # males\n",
    "        if network[0] > 0:\n",
    "            labels_only_show_non_null.append('M')\n",
    "        else:\n",
    "            labels_only_show_non_null.append('')\n",
    "        \n",
    "        # females\n",
    "        if network[1] > 0:\n",
    "            labels_only_show_non_null.append('F')\n",
    "        else:\n",
    "            labels_only_show_non_null.append('')\n",
    "    \n",
    "    ax.pie(vals.flatten(), radius=1-size, labels=labels_only_show_non_null, colors=inner_colors,\n",
    "           wedgeprops=dict(width=size, edgecolor='white'),  textprops={'fontsize': 15},  labeldistance=0.78)\n",
    "    \n",
    "    ax.set(aspect=\"equal\")\n",
    "    ax.set_title(f'Breakdown of parcels by network showing a statistically significant {contrast_type} difference in gradient loadings, by {contrast_type}', y=1.03, fontsize=20)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print('Number of significant parcels by sex:')\n",
    "    for network in count_sig_per_network_bysex:\n",
    "        print(f\"{network} - Male: {count_sig_per_network_bysex[network][0]}, Female: {count_sig_per_network_bysex[network][1]}\")\n",
    "    \n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### plot outer and inner pie (with abbreviated network labels) -> manuscript figure\n",
    "    \n",
    "    fig, disp = plt.subplots(figsize=(15, 10))\n",
    "    size = 0.3\n",
    "    \n",
    "    disp.pie(vals.sum(axis=1), radius=1, labels=network_names_abbreviated, colors=outer_colors, pctdistance=0.85,\n",
    "           wedgeprops=dict(width=size, edgecolor='black'),  textprops={'fontsize': 30})\n",
    "    \n",
    "    disp.pie(vals.flatten(), radius=1-size, colors=inner_colors,\n",
    "           wedgeprops=dict(width=size, edgecolor='black'),  textprops={'fontsize': 15},  labeldistance=0.78)\n",
    "    \n",
    "    disp.set(aspect=\"equal\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    ## save figure in directory \n",
    "    fig.savefig(output_dir+sample_modality+'_pie_chart_'+contrast_type+'_diff_netw.png', dpi=300)\n",
    "    \n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### plot outer and inner pie (without labels)\n",
    "    \n",
    "    fig, disp = plt.subplots(figsize=(15, 10))\n",
    "    size = 0.3\n",
    "    \n",
    "    disp.pie(vals.sum(axis=1), radius=1, colors=outer_colors, pctdistance=0.85,\n",
    "           wedgeprops=dict(width=size, edgecolor='black'),  textprops={'fontsize': 20})\n",
    "    \n",
    "    disp.pie(vals.flatten(), radius=1-size, colors=inner_colors,\n",
    "           wedgeprops=dict(width=size, edgecolor='blacK'),  textprops={'fontsize': 15},  labeldistance=0.78)\n",
    "    \n",
    "    disp.set(aspect=\"equal\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    ## save figure in directory \n",
    "    #fig.savefig(output_dir+sample_modality+'_pie_chart_'+contrast_type+'_diff_netw.png', dpi=300)\n",
    "    \n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### plot of significant parcels on G1 vs G2 visualization\n",
    "    \n",
    "    # problems with this plot\n",
    "        # hard-coded axes labels and title (G1 vs G2)\n",
    "        # legend of colors: showing 0 vs 1\n",
    "    \n",
    "    if scatterplot:\n",
    "    \n",
    "        fig, ax = plt.subplots(figsize = (6,5));\n",
    "        \n",
    "        ax = sns.scatterplot(x = scatter_x,\n",
    "                             y = scatter_y,\n",
    "                             hue = sig_Q_vals_slm,  # gives color coding based on Q value of sex contrast (main model including age, sex, icv) -> dark color: significance\n",
    "                             palette = sns.color_palette([\"lavender\", \"navy\"]),\n",
    "                             legend = True, ax = ax);\n",
    "        \n",
    "        ax.set_xlabel(scatter_x_label, fontsize=20);\n",
    "        ax.set_ylabel(scatter_y_label, fontsize=20);\n",
    "        ax.set_title(f'Scatter plot of G1 vs G2, showing significant {contrast_type} contrast in dark', y=1.05, fontsize=20)\n",
    "        ax.spines['right'].set_visible(False);\n",
    "        ax.spines['top'].set_visible(False);\n",
    "        #plt.legend(title='1 = FDR-corr significance')\n",
    "        \n",
    "        plt.show(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dae2cfcf-09ee-4273-a0af-19464744ae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_plot_corr_networks(x, y, x_label, y_label):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    Output:\n",
    "    - correlations between 2 variables, both overall and per network\n",
    "    - scatterplots colorcoded by yeo network, with regression lines per network\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ### creating a dataframe in order to have the data in the correct format to be plotted\n",
    "    temp_dict = {x_label: x, y_label: y, 'yeo_network': yeo7_networks_array_labels}  \n",
    "    dataframe = pd.DataFrame(data = temp_dict)\n",
    "    \n",
    "\n",
    "    ### print overall correlation\n",
    "    print('Note that the correlation p-values below have not undergone permutation testing! so here the correlations (r coefficients) are only indicative of effect sizes\\n\\n')\n",
    "    \n",
    "    print(f\"Overall Pearson correlation between {x_label} and {y_label}: r = {round(stats.pearsonr(dataframe[x_label], dataframe[y_label])[0], 2)}; p = {round(stats.pearsonr(dataframe[x_label], dataframe[y_label])[1], 3)}\\n\")\n",
    "    \n",
    "    network_labels = ['visual', 'sensory motor', 'dorsal attention', 'ventral attention', 'limbic', 'fronto parietal', 'DMN']\n",
    "\n",
    "    for i in range(len(network_labels)):\n",
    "        \n",
    "        corr_coef = stats.pearsonr(dataframe.loc[dataframe['yeo_network'] == network_labels[i]][x_label], dataframe.loc[dataframe['yeo_network'] == network_labels[i]][y_label])[0]\n",
    "        p_val = stats.pearsonr(dataframe.loc[dataframe['yeo_network'] == network_labels[i]][x_label], dataframe.loc[dataframe['yeo_network'] == network_labels[i]][y_label])[1]\n",
    "        \n",
    "        print(f\"{network_labels[i]}: r = {round(corr_coef, 2)}, p = {round(p_val, 3)}\")\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    \n",
    "    ### scatter plot color-coded by network, with regression lines \n",
    "        \n",
    "    # original Yeo network colors\n",
    "    palette_labeled_networks = {'DMN': 'indianred',  \n",
    "                                'dorsal attention' : 'forestgreen',  \n",
    "                                'fronto parietal' : 'orange',  \n",
    "                                'limbic' : 'lemonchiffon',  \n",
    "                                'sensory motor' : 'steelblue',\n",
    "                                'ventral attention' : 'orchid', \n",
    "                                'visual' : 'darkorchid'} \n",
    "\n",
    "    # plot\n",
    "    \n",
    "    sns.lmplot(x = x_label, y = y_label, \n",
    "           hue = 'yeo_network',\n",
    "           data = dataframe,\n",
    "           palette = palette_labeled_networks, \n",
    "           height=10, aspect=1.2,  # aspect gives you the height-width ratio\n",
    "           legend=False)\n",
    "\n",
    "    sns.despine()\n",
    "\n",
    "    plt.title(f\"Correlation between {x_label} and {y_label}\", y=1.05, fontsize=25)\n",
    "    plt.xlabel(x_label, fontsize=25)\n",
    "    plt.ylabel(y_label, fontsize=25)\n",
    "    plt.tick_params(labelsize=25)\n",
    "    plt.legend(fontsize=25, bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bc5d4c8-1251-449e-9c7d-02715e1e27b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SpinPermutationTest_PearsonCorr_Schaefer400(x, y):\n",
    "    \n",
    "    '''\n",
    "    OUTDATED: I MADE A NEW FUNCTION THAT ALLOWS TO SPECFIY WHAT KIND OF CORRELATION (INCLUDING SPEARMAN AS OPTION) - the reason why I don't want to delete already is that I don't want it to directly throw an error in previous scripts\n",
    "    \n",
    "    Function that conducts spin permutation testing (for pearson correlation) specifically for data in Schaefer400 parcellation (len = 400) using enigmatoolbox.permutation_testing package\n",
    "    \n",
    "    Input:\n",
    "    - x: data to correlate (len = 400) \n",
    "    - y: data to correlate (len = 400) \n",
    "    \n",
    "    Output (display):  \n",
    "    - spin permutation p-value\n",
    "    - plotted null distribution of generated correlations\n",
    "\n",
    "   \n",
    "    '''\n",
    "    \n",
    "    from enigmatoolbox.permutation_testing import spin_test, shuf_test\n",
    "    \n",
    "    print(\"there is an updated function -> SpinPermutationTest_Schaefer400 with specification of correlation type. Use that one and go to p1_myfunctions.ipynb to delete SpinPermutationTest_PearsonCorr_Schaefer400\")\n",
    "    \n",
    "    ### Project gradient loadings (from Schaefer 400 parcellation) to fsaverage5's 20484 vertices\n",
    "    \n",
    "    sample_1_fs5_grad_loadings = []\n",
    "    sample_2_fs5_grad_loadings = []\n",
    "\n",
    "    # iterate over the 20484 vertices in fsaverage5\n",
    "    for i in range(len(schaefer_400_fs5)):\n",
    "\n",
    "        if schaefer_400_fs5[i] == 0:  # corresponds to the midline\n",
    "            # append to the lists of fs5_tvals: 0\n",
    "            sample_1_fs5_grad_loadings.append(0)\n",
    "            sample_2_fs5_grad_loadings.append(0)\n",
    "\n",
    "        else:\n",
    "            # append to the lists of fs5_tvals: the unimodal-heteromodal gradient eigenvalue of the corresponding Schaefer parcel (here parcel value [i] - 1 because parcel numbers go from 1-400 instead of 0-399 as required for indexing)\n",
    "            sample_1_fs5_grad_loadings.append(x[schaefer_400_fs5[i]-1])\n",
    "            sample_2_fs5_grad_loadings.append(y[schaefer_400_fs5[i]-1])\n",
    "\n",
    "    # change the zeros into nan (couldn't nan directly because then it made the array content strings\n",
    "    sample_1_fs5_grad_loadings[sample_1_fs5_grad_loadings == 0] = np.nan\n",
    "    sample_2_fs5_grad_loadings[sample_2_fs5_grad_loadings == 0] = np.nan\n",
    "\n",
    "    # transform list into array\n",
    "    sample_1_fs5_grad_loadings = np.asarray(sample_1_fs5_grad_loadings)\n",
    "    sample_2_fs5_grad_loadings = np.asarray(sample_2_fs5_grad_loadings)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### Spin permutation testing \n",
    "    \n",
    "    # spin permutation testing for two cortical maps (output of spin_test is the p-value and the null distribution)\n",
    "    spin_test_p, spin_test_d = spin_test(sample_1_fs5_grad_loadings, sample_2_fs5_grad_loadings, surface_name='fsa5', parcellation_name='aparc', type='pearson', n_rot=1000, null_dist=True)\n",
    "    \n",
    "    \n",
    "    # print spin permutation test\n",
    "    print(f\"Spin permutation test p-value: {spin_test_p}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### Plot null distribution of generated correlations\n",
    "    \n",
    "    # To better interpret statistical significance, we can plot the null distribution of generated correlations (i.e., “spun” or “shuffled” correlations) and overlay the correlation coefficient obtained from the empirical (i.e., real) brain maps.\n",
    "    \n",
    "    fig, ax = plt.subplots(1, figsize=(15, 3))\n",
    "\n",
    "    ax.hist(spin_test_d, bins=50, density=True, color=\"blue\", edgecolor='white', lw=0.5)\n",
    "    ax.set_xlabel('Null correlations')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title('Null distribution of generated correlations')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "960282b5-6b39-42d4-93a1-2e9d941db64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SpinPermutationTest_Schaefer400(x, y, correlation_type = 'pearson'):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Function that conducts spin permutation testing (for pearson correlation) specifically for data in Schaefer400 parcellation (len = 400) using enigmatoolbox.permutation_testing package\n",
    "    \n",
    "    Input:\n",
    "    - x: data to correlate (len = 400) \n",
    "    - y: data to correlate (len = 400) \n",
    "    - correlation_type: 'pearson' or 'spearman'\n",
    "    \n",
    "    Output (display):  \n",
    "    - spin permutation p-value\n",
    "    - plotted null distribution of generated correlations\n",
    "\n",
    "   \n",
    "    '''\n",
    "    \n",
    "    from enigmatoolbox.permutation_testing import spin_test, shuf_test\n",
    "    \n",
    "    ### Project gradient loadings (from Schaefer 400 parcellation) to fsaverage5's 20484 vertices (required for enigmatoolbox.permutation_testing package)\n",
    "    \n",
    "    sample_1_fs5_grad_loadings = []\n",
    "    sample_2_fs5_grad_loadings = []\n",
    "\n",
    "    # iterate over the 20484 vertices in fsaverage5\n",
    "    for i in range(len(schaefer_400_fs5)):\n",
    "\n",
    "        if schaefer_400_fs5[i] == 0:  # corresponds to the midline\n",
    "            # append to the lists of fs5_tvals: 0\n",
    "            sample_1_fs5_grad_loadings.append(0)\n",
    "            sample_2_fs5_grad_loadings.append(0)\n",
    "\n",
    "        else:\n",
    "            # append to the lists of fs5_tvals: the unimodal-heteromodal gradient eigenvalue of the corresponding Schaefer parcel (here parcel value [i] - 1 because parcel numbers go from 1-400 instead of 0-399 as required for indexing)\n",
    "            sample_1_fs5_grad_loadings.append(x[schaefer_400_fs5[i]-1])\n",
    "            sample_2_fs5_grad_loadings.append(y[schaefer_400_fs5[i]-1])\n",
    "\n",
    "    # change the zeros into nan (couldn't nan directly because then it made the array content strings\n",
    "    sample_1_fs5_grad_loadings[sample_1_fs5_grad_loadings == 0] = np.nan\n",
    "    sample_2_fs5_grad_loadings[sample_2_fs5_grad_loadings == 0] = np.nan\n",
    "\n",
    "    # transform list into array\n",
    "    sample_1_fs5_grad_loadings = np.asarray(sample_1_fs5_grad_loadings)\n",
    "    sample_2_fs5_grad_loadings = np.asarray(sample_2_fs5_grad_loadings)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### Spin permutation testing \n",
    "    \n",
    "    # spin permutation testing for two cortical maps (output of spin_test is the p-value and the null distribution)\n",
    "    spin_test_p, spin_test_d = spin_test(sample_1_fs5_grad_loadings, sample_2_fs5_grad_loadings, surface_name='fsa5', parcellation_name='aparc', type=correlation_type, n_rot=1000, null_dist=True)\n",
    "    \n",
    "    \n",
    "    # print spin permutation test\n",
    "    print(f\"Spin permutation test p-value: {spin_test_p}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### Plot null distribution of generated correlations\n",
    "    \n",
    "    # To better interpret statistical significance, we can plot the null distribution of generated correlations (i.e., “spun” or “shuffled” correlations) and overlay the correlation coefficient obtained from the empirical (i.e., real) brain maps.\n",
    "    \n",
    "    fig, ax = plt.subplots(1, figsize=(15, 3))\n",
    "\n",
    "    ax.hist(spin_test_d, bins=50, density=True, color=\"blue\", edgecolor='white', lw=0.5)\n",
    "    ax.set_xlabel('Null correlations')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title('Null distribution of generated correlations')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    # return the spin test p value and null distribution of r values in a dictionary format\n",
    "    return {'spin_test_p': spin_test_p, 'spin_test_d': spin_test_d}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98a7ddf0-e1e3-48cc-9fbd-662db11ba4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RainCloudPlot_YeoNetworks_SampleComparison_Grad(array_grad_sample_1, array_grad_sample_2, sample_1_label, sample_2_label):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "        \n",
    "    Function that produces RainCloud Plots of gradient loadings (mean across subjects for each parcel), color coded by Yeo network, compared across sample\n",
    "    \n",
    "    The distribuitions by network (as displayed in different colors) show the differences between parcels belonging to the same network (because each point is 1 parcel; the mean is calculated across subjects for that parcel)\n",
    "    -> emphasis is on displaying the gradient loadings of parcels belonging to the same network (spread of distribution -integration/segregation- of parcels belonging to the same network)\n",
    "    \n",
    "    Input:\n",
    "    - array_grad_sample_1: gradient array for sample 1 \n",
    "    - array_grad_sample_2: gradient array for sample 2\n",
    "    - sample_1_label: in string format, e.g., \"GSP G2\"\n",
    "    - sample_2_label: in string format, e.g., \"HCP G1\"\n",
    "    \n",
    "    Output (display):  \n",
    "    - RainCloudPlot displaying sample 1 and 2 specified gradients, i.e., mean gradient loadings across subjects per parcel, color coded by Yeo network, compared across samples \n",
    "   \n",
    "    '''\n",
    "    \n",
    "    ## format gradient array for plotting\n",
    "    # for the RainCloud plots, we need dataframe to have all values to be plotted in 1 column (y), and labels to be plotted in other columns (max 2: x (sex) and hue (coloring by Yeo network))\n",
    "\n",
    "    # dataframes of gradient loadings - transposing because we want the 400 parcels to be vertical in the dataframe in order to calculate mean by parcel\n",
    "    array_grad_sample_1 = pd.DataFrame(array_grad_sample_1.T)\n",
    "    array_grad_sample_2 = pd.DataFrame(array_grad_sample_2.T)\n",
    "    \n",
    "    # adding a column containing the mean gradient loading across subjects per parcel\n",
    "    array_grad_sample_1['mean gradient loadings across subjects per parcel'] = array_grad_sample_1.mean(axis=1)\n",
    "    array_grad_sample_2['mean gradient loadings across subjects per parcel'] = array_grad_sample_2.mean(axis=1)\n",
    "\n",
    "    # adding a column containing the Yeo network labels\n",
    "    array_grad_sample_1['yeo network'] = yeo7_networks_array_labels\n",
    "    array_grad_sample_2['yeo network'] = yeo7_networks_array_labels\n",
    "\n",
    "    # take a subset of the dataframes (only keep mean gradient loadings across subjects per parcels and yeo network labels, remove the individual subject values per parcel)\n",
    "    array_grad_sample_1 = array_grad_sample_1[[\"mean gradient loadings across subjects per parcel\", \"yeo network\"]]\n",
    "    array_grad_sample_2 = array_grad_sample_2[[\"mean gradient loadings across subjects per parcel\", \"yeo network\"]]\n",
    "\n",
    "    # adding a column containing the label of the respective dataset (for all rows) before merging them in order to make samples identifiable for plotting\n",
    "    array_grad_sample_1[\"sample\"] = sample_1_label\n",
    "    array_grad_sample_2[\"sample\"] = sample_2_label\n",
    "\n",
    "    # concatenate the two datasets (by index in order to have rows = parcels from both datasets)\n",
    "    df_to_plot = pd.concat([array_grad_sample_1, array_grad_sample_2], axis = 'index')\n",
    "    \n",
    "    \n",
    "    ### RainCloud plot\n",
    "    \n",
    "    # color palette matching the RainCloud plot colors - specifying otherwise switches colors visual-DMN in the oder direction\n",
    "    # (rgb found via mac's digital color meter, then /255 to obtain 0-1 values as required by plt)\n",
    "\n",
    "    color_palette =[(227/255, 174/255, 211/255),  # visual\n",
    "                    (185/255, 163/255, 204/255),  # sensory motor\n",
    "                    (236/255, 170/255, 119/255),  # dorsal attention\n",
    "                    (174/255, 147/255, 143/255),  # ventral attention\n",
    "                    (216/255, 128/255, 129/255),  # limbic\n",
    "                    (128/255, 183/255, 126/255),  # fronto parietal\n",
    "                    (120/255, 162/255, 189/255)]  # DMN\n",
    "    \n",
    "    f,ax=plt.subplots(figsize=(20,15))\n",
    "\n",
    "    ax=pt.RainCloud(x=\"sample\",\n",
    "                    y=\"mean gradient loadings across subjects per parcel\",\n",
    "                    hue=\"yeo network\",\n",
    "                    data=df_to_plot,\n",
    "                    palette=color_palette,\n",
    "                    bw=.2,\n",
    "                    width_viol=.6,\n",
    "                    orient=\"h\",\n",
    "                    move=.2,\n",
    "                    alpha=1,\n",
    "                    pointplot=True, \n",
    "                    dodge = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9576114-3ca3-496d-abcb-4e3bfa4fc1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RainCloudPlot_YeoNetworks_SampleComparison_Grad_IndDiff(array_grad_sample_1, array_grad_sample_2, sample_1_label, sample_2_label):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "     --- don't use this function, only keeping it for reference for individual differences, but what I am using to understand results is function RainCloudPlot_YeoNetworks_SexComparison ---\n",
    "     \n",
    "     \n",
    "    Function that produced Rain Cloud Plots of gradient loadings by Yeo network by sample\n",
    "    OLD function: the distribution by network shows the differences between subjects (because each point is 1 subject; the mean is calculated across parcels belonging to that same network) -> emphasis is on individual differences\n",
    "\n",
    "    \n",
    "    Input:\n",
    "    - array_grad_sample_1: gradient array for sample 1 \n",
    "    - array_grad_sample_2: gradient array for sample 2\n",
    "    - sample_1_label: in string format, e.g., \"GSP G2\"\n",
    "    - sample_2_label: in string format, e.g., \"HCP G1\"\n",
    "    \n",
    "    Output (display):  \n",
    "    - RainCloudPlot displaying sample 1 and 2 specified gradients \n",
    "\n",
    "   \n",
    "    '''\n",
    "    \n",
    "    ### Reshaping the data in order to make it plottable\n",
    "    \n",
    "    # dataframe of the gradient loadings (transposing the original array because we need the 400 parcels to be vertical in the dataframe in order to be labeled with their corresponding Yeo network)\n",
    "    array_grad_sample_1 = pd.DataFrame(array_grad_sample_1.T)\n",
    "    array_grad_sample_2 = pd.DataFrame(array_grad_sample_2.T)\n",
    "\n",
    "    # adding a column containing the Yeo network labels\n",
    "    array_grad_sample_1['yeo network'] = yeo7_networks_array_labels\n",
    "    array_grad_sample_2['yeo network'] = yeo7_networks_array_labels\n",
    "\n",
    "    # obtaining the mean of the parcels with the same Yeo network label, then transposing because we need the all subjects to be vertical in the dataframe in order to be labeled with their corresponding sample \n",
    "    array_grad_sample_1 = array_grad_sample_1.groupby(\"yeo network\", as_index=True).mean().T\n",
    "    array_grad_sample_2 = array_grad_sample_2.groupby(\"yeo network\", as_index=True).mean().T\n",
    "\n",
    "    # adding a column containing the label of the respective dataset (for all rows)\n",
    "    array_grad_sample_1[\"sample\"] = sample_1_label\n",
    "    array_grad_sample_2[\"sample\"] = sample_2_label\n",
    "\n",
    "    # naming the index and resetting it as an index in order to make it callable in the following melt function\n",
    "    array_grad_sample_1.index.name = \"sub\"\n",
    "    array_grad_sample_1 = array_grad_sample_1.reset_index()\n",
    "\n",
    "    array_grad_sample_2.index.name = \"sub\"\n",
    "    array_grad_sample_2 = array_grad_sample_2.reset_index()\n",
    "\n",
    "    # concatenate the two datasets (by index in order to have rows = subjects from both datasets)\n",
    "    df_to_plot = pd.concat([array_grad_sample_1, array_grad_sample_2], axis = 'index')\n",
    "\n",
    "    # for the RainCloud plots, we need dataframe to have all values to be plotted in 1 column, and labels to be plotted in other columns (max 2)\n",
    "    # using melt() to make dataframe long so that mean loadings per network are in one column, whilst preserving the sub number and sample lable as ID variables\n",
    "    df_to_plot = pd.melt(df_to_plot, id_vars=[\"sub\", 'sample'], var_name='yeo network', value_name='mean grad loadings per yeo network')\n",
    "\n",
    "    \n",
    "    ### RainCloud plot\n",
    "    \n",
    "    f,ax=plt.subplots(figsize=(20,15))\n",
    "\n",
    "    ax=pt.RainCloud(x=\"sample\",\n",
    "                    y=\"mean grad loadings per yeo network\",\n",
    "                    hue=\"yeo network\",\n",
    "                    data=df_to_plot,\n",
    "                    palette=sns.color_palette(n_colors=7),\n",
    "                    bw=.2,\n",
    "                    width_viol=.6,\n",
    "                    orient=\"h\",\n",
    "                    move=.2,\n",
    "                    alpha=.65,\n",
    "                    pointplot=True, \n",
    "                    dodge = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22a5bab3-dd16-4d8e-9d9b-d03d328d4ef8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_sig_overlap(reg_res_sample_1, reg_res_sample_2, sample_1_label, sample_2_label, save_screenshot = False, output_dir = None, modality = None):\n",
    "    \n",
    "    '''\n",
    "    Function that displays the overlap of signficant sex differences\n",
    "    Specific to plotting on surf_lh, surf_rh from conte69; for data coming from Schaefer 400 parcellation\n",
    "    \n",
    "    Input required: \n",
    "    - reg_res_sample_1: regression results sample 1 (in fomrat: DataFrame, containing columns 'q_val_sel' and 't_val_sex', len = 400 parcels (Schaeffer400))\n",
    "    - reg_res_sample_2: regression results sample 1 (in fomrat: DataFrame, containing columns 'q_val_sel' and 't_val_sex', len = 400 parcels (Schaeffer400))\n",
    "    - sample_1_label: e.g., \"GSP G2\"\n",
    "    - sample_2_label: e.g., \"HCP G1\"\n",
    "    - save_screenshot: True or False - if you want to save screenshot in output_dir. If True, the plots do not get displayed - so if want to save, need to run with True and then False to leave the plots visible in notebook\n",
    "    - output_dir: path to output directory (e.g. resdir_fig, i.e. '/data/p_02667/sex_diff_gradients/results/figures/')\n",
    "    - sample_modality: string, e.g. GSP_local_ct or HCP_fc_grad (for name of figures saved in output_dir)\n",
    "    \n",
    "    Output display:\n",
    "    - printed text \"Number of parcels that show statistically significant sex differences\"\n",
    "    - plotted hemispheres: overlap of significant sex differences across samples: 2 (dark green): significant in both samples, 1 (light green): significant in one sample, 0: not significant\n",
    "    - plotted hemispheres: which dataset shows significant sex difference\n",
    "    - plotted hemispheres: parcels showing sex differences in opposite directions (if any)\n",
    "    - plotted hemispheres: mean t-values for parcels showing an overlap of significant FDR-corrected statistical difference across samples (showing the same directionality of effects - opposite effects (different signs) are marked as nan) \n",
    "    \n",
    "    plotted hemispheres displayed via handles -> need to display(*handles)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    ### mormat data to plot\n",
    "    \n",
    "    q_vals_sig_overlap = []  # significant sex differences (per parcel): 2 = in both datasets, 1 = in one dataset only, 0 = not significant in any dataset\n",
    "    sample1_v_sample2_sig = []  # which dataset shows significant sex difference (per parcel): +1 = sample 1, -1 = sample 2, 0 = both datasets, nan = not significant in any dataset\n",
    "    fdr_corrected_tvals_sample_1 = []  # FDR corrected t-values for sample 1 (non significant are labeled as nan)\n",
    "    fdr_corrected_tvals_sample_2 = []  # FDR corrected t-values for sample 1 (non significant are labeled as nan)\n",
    "    \n",
    "    for i in range(len(reg_res_sample_1.q_val_sex)):\n",
    "\n",
    "        count_sig = 0\n",
    "        sample1_v_sample2 = 0\n",
    "        not_sig_at_all = True\n",
    "\n",
    "        # sample 1\n",
    "        \n",
    "        if reg_res_sample_1.q_val_sex[i] <= 0.05:\n",
    "            count_sig += 1\n",
    "            sample1_v_sample2 += 1\n",
    "            not_sig_at_all = False\n",
    "            \n",
    "            # appending FDR-corrected t-value\n",
    "            fdr_corrected_tvals_sample_1.append(reg_res_sample_1.t_val_sex[i])\n",
    "        \n",
    "        else:\n",
    "             # appending nan for FDR-corrected t-value\n",
    "            fdr_corrected_tvals_sample_1.append(float('nan'))\n",
    "            \n",
    "        \n",
    "        # sample 2\n",
    "        \n",
    "        if reg_res_sample_2.q_val_sex[i] <= 0.05:\n",
    "            count_sig += 1\n",
    "            sample1_v_sample2 -= 1\n",
    "            not_sig_at_all = False\n",
    "            \n",
    "             # appending FDR-corrected t-value\n",
    "            fdr_corrected_tvals_sample_2.append(reg_res_sample_2.t_val_sex[i])\n",
    "        \n",
    "        else:\n",
    "             # appending nan for FDR-corrected t-value\n",
    "            fdr_corrected_tvals_sample_2.append(float('nan'))\n",
    "            \n",
    "        \n",
    "        # non significance\n",
    "        \n",
    "        if not_sig_at_all:\n",
    "            q_vals_sig_overlap.append(float(count_sig))  # if no significant we want to save as 0\n",
    "            sample1_v_sample2_sig.append(float('nan'))  # if no significant we want to save as nan (will be grey in plot hemispheres display)\n",
    "\n",
    "        else:\n",
    "            q_vals_sig_overlap.append(float(count_sig))  # append the sig counts in sig overlap\n",
    "            sample1_v_sample2_sig.append(float(sample1_v_sample2))  # append which sample showd significance (final interpretation: +1 = sample 1, -1 = sample 2, 0 = both samples\n",
    "    \n",
    "    \n",
    "    # check whether the directionality of sex differences is the same in the regions that overlap -> append to \"flags\" variable\n",
    "    \n",
    "    flags = []\n",
    "\n",
    "    for i in range(len(q_vals_sig_overlap)):\n",
    "\n",
    "        if q_vals_sig_overlap[i] == 2:\n",
    "\n",
    "            # if the sign of the t value is the same in GSP and HCP (either (+ and +) or (- and -), then append nan for no problem\n",
    "            if (reg_res_sample_1.t_val_sex[i] > 0 and reg_res_sample_2.t_val_sex[i] > 0) or (reg_res_sample_1.t_val_sex[i] < 0 and reg_res_sample_2.t_val_sex[i] < 0):\n",
    "                flags.append(float('nan'))\n",
    "\n",
    "            # else flag the problem with 1\n",
    "            else:\n",
    "                flags.append(float(1))\n",
    "\n",
    "        else:\n",
    "            flags.append(float('nan'))\n",
    "            \n",
    "            \n",
    "            \n",
    "    # mean t-values for overlapping significant parcels (FDR-corrected) across samples\n",
    "\n",
    "    fdr_corrected_tvals_overlap = []  \n",
    "    \n",
    "    for i in range(len(fdr_corrected_tvals_sample_1)):\n",
    "        \n",
    "        # if either (or both) samples is nan, append nan to overlap\n",
    "        if np.isnan(fdr_corrected_tvals_sample_1[i]) or np.isnan(fdr_corrected_tvals_sample_2[i]):\n",
    "            fdr_corrected_tvals_overlap.append(float('nan'))\n",
    "        \n",
    "        # if there is a recorded t-value for both (not nan)\n",
    "        else:\n",
    "            # if the t values have the same sign (ie same direction of effects): take the mean t value\n",
    "            if np.sign(fdr_corrected_tvals_sample_1[i]) == np.sign(fdr_corrected_tvals_sample_2[i]):\n",
    "                fdr_corrected_tvals_overlap.append(statistics.mean((fdr_corrected_tvals_sample_1[i], fdr_corrected_tvals_sample_2[i])))\n",
    "            \n",
    "            # if different signs (ie different direction of effects): append nan\n",
    "            else:\n",
    "                fdr_corrected_tvals_overlap.append(float('nan'))\n",
    "\n",
    "                \n",
    "    \n",
    "    \n",
    "    ### Plotting\n",
    "    \n",
    "    # defining labeling scheme and mask\n",
    "    labeling = load_parcellation('schaefer', scale=400, join=True)  #len(labeling) = 64984 (i.e., conte69? at least matches as works with conte69 hemispheres)\n",
    "    surf_lh, surf_rh = load_conte69()\n",
    "    mask = labeling != 0  # do not consider 0 labels which correspond to the midline\n",
    "    \n",
    "    # to be displayed\n",
    "    handles = []\n",
    "    \n",
    "    \n",
    "    ## sig q vals correspondance\n",
    "    q_vals_sig_mapped_to_labels = map_to_labels(np.array(q_vals_sig_overlap), labeling, mask=mask, fill=np.nan) \n",
    "    \n",
    "    q_vals_plotted_hemispheres = plot_hemispheres(\n",
    "        surf_lh, \n",
    "        surf_rh, \n",
    "        array_name = q_vals_sig_mapped_to_labels, \n",
    "        embed_nb = True, \n",
    "        size = (1400,200), \n",
    "        cmap = 'Greens', \n",
    "        color_bar = True, \n",
    "        #color_range = color_range_t,\n",
    "        nan_color = (0.7, 0.7, 0.7, 1),\n",
    "        #label_text = [\"overlap of significant sex differences\"],\n",
    "        zoom = 1.45,\n",
    "        screenshot = save_screenshot,\n",
    "        filename = output_dir+'overlap_'+modality+'_plotted_hemispheres_sex_contrast_sig_fdr_corr.png')\n",
    "    \n",
    "    # append to what will be displayed\n",
    "    handles.append('Overlap of significant sex differences: 2 (dark green): significant in both samples, 1 (light green): significant in one sample, 0: not significant')  # title\n",
    "    handles.append(q_vals_plotted_hemispheres)  # plot\n",
    "\n",
    "\n",
    "    \n",
    "    ## sample 1 or sample 2 significance \n",
    "    sample1_v_sample2_sig_mapped_to_labels = map_to_labels(np.array(sample1_v_sample2_sig), labeling, mask=mask, fill=np.nan) \n",
    "    \n",
    "    sample1_v_sample2_sig_plotted_hemispheres = plot_hemispheres(\n",
    "        surf_lh, \n",
    "        surf_rh, \n",
    "        array_name = sample1_v_sample2_sig_mapped_to_labels, \n",
    "        embed_nb = True, \n",
    "        size = (1400,200), \n",
    "        cmap = 'RdYlGn_r', \n",
    "        color_bar = True, \n",
    "        #color_range = color_range_t,\n",
    "        nan_color = (0.7, 0.7, 0.7, 1),\n",
    "        #label_text = [\"overlap of significant sex differences\"],\n",
    "        zoom = 1.45,\n",
    "        screenshot = save_screenshot,\n",
    "        filename = output_dir+'overlap_'+modality+'_plotted_hemispheres_sex_contrast_sample_showing_sex_diff.png')\n",
    "    \n",
    "    # append to what will be displayed\n",
    "    handles.append(f'Which dataset shows significant sex difference: +1 (red) {sample_1_label}, -1 (green) = {sample_2_label}, 0 (yellow) = both datasets, nan (grey) = not significant in any dataset')  # title\n",
    "    handles.append(sample1_v_sample2_sig_plotted_hemispheres)  # plot\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## Plot the location of the flagged parcels where the directionality of the overalpping sex differences significant across samples isnßt the same (if there are any)\n",
    "\n",
    "    if flags.count(1) > 0:\n",
    "\n",
    "        # defining labeling scheme and mask\n",
    "        # ! if doesn't work anymore for some reason, take this out of the definition (put it before it) !\n",
    "        labeling = load_parcellation('schaefer', scale=400, join=True)\n",
    "        surf_lh, surf_rh = load_conte69()\n",
    "        mask = labeling != 0\n",
    "\n",
    "\n",
    "        ### flagged parcels\n",
    "        flagged_mapped_to_labels = map_to_labels(np.array(flags), labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "        flagged_plotted_hemispheres = plot_hemispheres(\n",
    "            surf_lh, \n",
    "            surf_rh, \n",
    "            array_name = flagged_mapped_to_labels, \n",
    "            embed_nb = True, \n",
    "            size = (1400,200), \n",
    "            cmap = 'Reds_r', \n",
    "            color_bar = True, \n",
    "            #color_range = color_range_t,\n",
    "            nan_color = (0.7, 0.7, 0.7, 1),\n",
    "            #label_text = [\"overlap of significant sex differences\"],\n",
    "            zoom = 1.45,\n",
    "            screenshot = save_screenshot,\n",
    "            filename = output_dir+'overlap_'+modality+'_plotted_hemispheres_sex_contrast_sig_opposing_directions.png')\n",
    "\n",
    "        # append to what will be displayed\n",
    "        handles.append('Parcels showing sex differences in opposite directions')  # title\n",
    "        handles.append(flagged_plotted_hemispheres)  # plot\n",
    "        \n",
    "        \n",
    "        \n",
    "    ## mean t-values for overlapping significant parcels (FDR-corrected) across samples\n",
    "    \n",
    "    fdr_corr_tvals_overlap_mapped_to_labels = map_to_labels(np.asarray(fdr_corrected_tvals_overlap), labeling, mask=mask, fill=np.nan)\n",
    "    \n",
    "    fdr_corr_tvals_plotted_hemispheres = plot_hemispheres(\n",
    "        surf_lh, \n",
    "        surf_rh, \n",
    "        array_name = fdr_corr_tvals_overlap_mapped_to_labels, \n",
    "        embed_nb = True, \n",
    "        size = (1400,200), \n",
    "        cmap = \"bwr_r\",  # bwr, _r stands for reversed; using it to match male-blue female-red \n",
    "        color_bar = True, \n",
    "        color_range='sym',\n",
    "        nan_color = (0.7, 0.7, 0.7, 1),\n",
    "        #label_text = [\"t-values\"],\n",
    "        zoom = 1.45,\n",
    "        screenshot = save_screenshot,\n",
    "        filename = output_dir+'overlap_'+modality+'_plotted_hemispheres_sex_contrast_mean_t_val.png')\n",
    "\n",
    "    \n",
    "    # append to what will be displayed\n",
    "    handles.append(f'mean t-values for overlapping significant parcels (FDR-corrected, q < 0.05) across samples (male: blue, female: red)')  # title\n",
    "    handles.append(fdr_corr_tvals_plotted_hemispheres)  # plot\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    ### Print significant overlap results\n",
    "    \n",
    "    print(f\"Number of parcels that show statistically significant sex differences across datasets: {q_vals_sig_overlap.count(2)}\")\n",
    "    print(f\"Number of parcels that show statistically significant sex differences in {sample_1_label} only: {sample1_v_sample2_sig.count(1)}\")\n",
    "    print(f\"Number of parcels that show statistically significant sex differences in {sample_2_label} only: {sample1_v_sample2_sig.count(-1)}\")\n",
    "    print(f\"Number of parcels (out of the {q_vals_sig_overlap.count(2)} parcels that show sig sex differences in both datasets) which show sex differences in opposite directions: {flags.count(1)}\\n\")\n",
    "\n",
    "                                           \n",
    "    return handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "312b19aa-9381-44bb-8966-77a41dbb05a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RainCloudPlot_YeoNetworks_SampleComparison_tval(reg_res_sample_1, reg_res_sample_2, sample_1_label, sample_2_label, save_violin_plot = False, output_dir = None, title = None):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Function that produces Rain Cloud and violin plots of t-values (regression results) by Yeo network by sample\n",
    "    \n",
    "    Input:\n",
    "    - reg_res_sample_1: regression results sample 1 (in fomrat: DataFrame, containing columns 'q_val_sel' and 't_val_sex', len = 400 parcels (Schaeffer400)\n",
    "    - reg_res_sample_2: regression results sample 1 (in fomrat: DataFrame, containing columns 'q_val_sel' and 't_val_sex', len = 400 parcels (Schaeffer400)\n",
    "    - sample_1_label: in string format, e.g., \"GSP G2\"\n",
    "    - sample_2_label: in string format, e.g., \"HCP G1\"\n",
    "    - save_violin_plot: True or False to save violin plot in output_dir\n",
    "    - output_dir: path to output directory (e.g. resdir_fig, i.e. '/data/p_02667/sex_diff_gradients/results/figures/')\n",
    "    - modality: string e.g., local_ct or fc_grad\n",
    "    \n",
    "    Output (display):  \n",
    "    - printed specification of min/max t-values for signficance, as well as number of significant parcels per network\n",
    "    - RainCloudPlot displaying sample 1 and 2 t-values \n",
    "    - Violin plot displaying sample 1 and 2 t-values\n",
    "\n",
    "   \n",
    "    '''\n",
    "    \n",
    "    ### Printed specification of min/max t-values for signficance, as well as number of significant parcels per network\n",
    "\n",
    "    list_samples = [reg_res_sample_1, reg_res_sample_2]\n",
    "    list_sample_labels = [sample_1_label, sample_2_label]\n",
    "\n",
    "    for e in range(len(list_samples)):\n",
    "    \n",
    "        # to record significant t-values (by sex)\n",
    "        tvals_sig_pos = []  # positive t-values == higher eignevalues in M\n",
    "        tvals_sig_neg = []  # negative t-values == heigher eivenvalues in F\n",
    "\n",
    "        # to record the number of significant t-values per network (by sex)\n",
    "        dict_networks_sig_pos = {'visual' : 0, 'sensory motor' : 0, 'dorsal attention' : 0, 'ventral attention' : 0, 'limbic' : 0, 'fronto parietal' : 0, 'DMN' : 0}  # positive t-values == higher eignevalues in M\n",
    "        dict_networks_sig_neg = {'visual' : 0, 'sensory motor' : 0, 'dorsal attention' : 0, 'ventral attention' : 0, 'limbic' : 0, 'fronto parietal' : 0, 'DMN' : 0}  # negative t-values == heigher eivenvalues in F\n",
    "\n",
    "        for i in range(len(list_samples[e])):\n",
    "            if list_samples[e].iloc[i].q_val_sex < 0.05:\n",
    "                if list_samples[e].iloc[i].t_val_sex > 0:\n",
    "                    tvals_sig_pos.append(list_samples[e].iloc[i].t_val_sex)\n",
    "                    dict_networks_sig_pos[yeo7_networks_array_labels[i]] += 1\n",
    "                else:\n",
    "                    tvals_sig_neg.append(list_samples[e].iloc[i].t_val_sex)\n",
    "                    dict_networks_sig_neg[yeo7_networks_array_labels[i]] += 1\n",
    "\n",
    "        print(f\"Minimum positive significant t-value in {list_sample_labels[e]}: {round(min(tvals_sig_pos), 2)}\\nMinimum negative significant t-value in {list_sample_labels[e]}: {round(max(tvals_sig_neg), 2)}\\n\")\n",
    "        print(f\"Number of positive significant t-values (M > F (gradient loadings)) in {list_sample_labels[e]}: {len(tvals_sig_pos)} -> by network: {dict_networks_sig_pos}\\nNumber of negative significant t-values (F > M (gradient loadings)) in {list_sample_labels[e]}: {len(tvals_sig_neg)} -> by network: {dict_networks_sig_neg}\\n\\n\")\n",
    "\n",
    "        \n",
    "    \n",
    "    ### Reshaping the data in order to make it plottable\n",
    "\n",
    "    # dataframe of the t-values \n",
    "    sample_1_tval = pd.DataFrame(reg_res_sample_1.t_val_sex)\n",
    "    sample_2_tval = pd.DataFrame(reg_res_sample_2.t_val_sex)\n",
    "\n",
    "    # adding a column containing the Yeo network labels\n",
    "    sample_1_tval['yeo network'] = yeo7_networks_array_labels\n",
    "    sample_2_tval['yeo network'] = yeo7_networks_array_labels\n",
    "\n",
    "    # adding a column containing the label of the respective dataset (for all rows)\n",
    "    sample_1_tval[\"sample\"] = sample_1_label\n",
    "    sample_2_tval[\"sample\"] = sample_2_label\n",
    "\n",
    "    # naming the index and resetting it as an index in order to make it callable in the following melt function\n",
    "    sample_1_tval.index.name = \"parcel\"\n",
    "    sample_1_tval = sample_1_tval.reset_index()\n",
    "\n",
    "    sample_2_tval.index.name = \"parcel\"\n",
    "    sample_2_tval = sample_2_tval.reset_index()\n",
    "\n",
    "    # for the RainCloud plots, we need dataframe to have all values to be plotted in 1 column, and labels to be plotted in other columns (max 2)\n",
    "    # concatenate the two datasets (by index in order to have rows = subjects from both datasets) -> already in the correct shape for the Raincloudplot\n",
    "    df_all_tval = pd.concat([sample_1_tval, sample_2_tval], axis = 'index')\n",
    "\n",
    "\n",
    "    \n",
    "    ### Rain Cloud plot of t-values (regression results) by Yeo network by sample\n",
    "    \n",
    "    print(\"Rain Cloud plot of t-values (regression results) by Yeo network by sample\")\n",
    "\n",
    "    f,ax=plt.subplots(figsize=(20,15))\n",
    "\n",
    "    ax=pt.RainCloud(x=\"sample\",\n",
    "                    y=\"t_val_sex\",\n",
    "                    hue=\"yeo network\",\n",
    "                    data=df_all_tval,\n",
    "                    palette=palette_labeled_networks,\n",
    "                    bw=.2,\n",
    "                    width_viol=.6,\n",
    "                    orient=\"h\",\n",
    "                    move=.2,\n",
    "                    alpha=.65,\n",
    "                    pointplot=True, \n",
    "                    dodge = True)\n",
    "    \n",
    "    #ax.legend(fontsize=20, bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "    \n",
    "    \n",
    "    ### Violin plot of t-values (regression results) by Yeo network by sample\n",
    "    \n",
    "    fig, eg = plt.subplots(figsize = (15,5))\n",
    "    eg = sns.violinplot(data=df_all_tval, \n",
    "                        x=\"yeo network\", \n",
    "                        y=\"t_val_sex\",\n",
    "                        hue=\"sample\",\n",
    "                        palette = ['firebrick', 'darkolivegreen'],\n",
    "                        split = True)       \n",
    "    \n",
    "    eg.axes.set_title(\"Violin plot of t-values (sex contrast) by Yeo network\", y=1.05, fontsize=20)\n",
    "    eg.set_xlabel(\"Yeo network\",fontsize=25)\n",
    "    eg.set_ylabel(\"t-value sex contrast\",fontsize=25)\n",
    "    eg.tick_params(labelsize=25)\n",
    "    eg.set_xticklabels(eg.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "    eg.legend(fontsize=20, bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "    \n",
    "    if save_violin_plot:\n",
    "         ## save figure in directory \n",
    "        fig.savefig(output_dir+title+'_violin_sex_contrast_tval_netw.png', dpi=300, bbox_inches=\"tight\")  # bbox_inches is so that the figure doesn't get cut off when saving\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15867ed4-aa43-49f2-88ad-c8616381023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_surface_to_parcel_for_all_subjects(surface_level_across_subs, surface_atlas_to_parcellation = ['schaefer_400_fsa5', 'schaefer_400_fsa5', 'schaefer_400_conte69']):\n",
    "            \n",
    "    '''\n",
    "    \n",
    "    Function that reshapes data from surface-level to parcel-level\n",
    "    \n",
    "    Input:\n",
    "    - surface_level_across_subs: surface level data (i.e., vertices) across subjects in format: N x vertices\n",
    "    - surface_atlas_to_parcellation: what surface atlas (e.g., fsa5 (20484 vertices), conte69 (64984 vertices)) needs to be converted into what parcellation scheme (e.g., Schaefer 400)\n",
    "        - possible string options: 'schaefer_400_fsa5', 'schaefer_400_fsa5', 'schaefer_400_conte69'\n",
    "        - Note: ONLY USE ON CONVERSION TO SCHAEFER 400 (hardcoded removal of first element yielded by the enigmatoolbox surface_to_parcel function, corresponding to midline (1st out of 401 parcels)\n",
    "                 Need to see manually what comes out of function for other pacellation schemes\n",
    "    \n",
    "    Output:\n",
    "    - dictionary containing: \n",
    "        - parcel_level_all_subs: data in parcellated format\n",
    "        - mean_across_parcels: mean value (of whatever is being manipulated here, e.g., CT) across surface/parcels\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # import enigma toolbox function surface_to_parcel\n",
    "    from enigmatoolbox.utils.parcellation import surface_to_parcel \n",
    "    \n",
    "    \n",
    "    # define list that will contain the data in new parcellated format\n",
    "    parcel_level_all_subs = []\n",
    "    \n",
    "    # define list that will contain the mean value (of whatever is being computed here) across surface/parcels\n",
    "    mean_across_parcels = []\n",
    "    \n",
    "\n",
    "    ### get the CT data in Schaefer 400 format for all subjects\n",
    "    \n",
    "    # iterate over the number of subjects (surface_level_across_subs is in N x vertices format)\n",
    "    for i in range(len(surface_level_across_subs)):\n",
    "\n",
    "        # transform surface data to parcellated data using enigma toolbox function, according to specified surface_atlas_to_parcellation schemes\n",
    "        sub_parcel_level = surface_to_parcel(surface_level_across_subs[i], surface_atlas_to_parcellation)  # enigmatoolbox function transforming to Schaefer 400 yields array len = 401 (including midline as first array element)\n",
    "\n",
    "        # deleting first element (index = 0) of the array corresponding to midline in order to yield Schaefer 400 (len = 400) parcellated data\n",
    "        sub_parcel_level = np.delete(sub_parcel_level, 0) \n",
    "\n",
    "        # appending current subject's values for all parcels to list of parcel-level values for all subjects \n",
    "        parcel_level_all_subs.append(sub_parcel_level)\n",
    "\n",
    "        # appending current subject's mean value (across parcels) to corresponding list\n",
    "        mean_across_parcels.append(statistics.mean(sub_parcel_level))\n",
    "\n",
    "\n",
    "    # make the variable containing newly parcellated data of all subjects into array    \n",
    "    parcel_level_all_subs = np.array(parcel_level_all_subs)  \n",
    "\n",
    "\n",
    "    #  store \n",
    "    dict_output = {'parcel_level_all_subs': parcel_level_all_subs, 'mean_across_parcels': mean_across_parcels}\n",
    "\n",
    "    \n",
    "    return dict_output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "184aed26-59f9-4438-9f37-282f78508cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_structural_covariance_matrix_with_covariates(array_ct_subjects_parcels, covar = []):\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    Function that computes the structural covariance matrix across subjects using partial correlation (i.e., controlling for covariates)\n",
    "    - structural covariance matrix (parcels*parcels) can only be computed at the group-level\n",
    "    - needs to be across subjects otherwise cannot compute correlation because each parcel has 1 CT value per subject\n",
    "    \n",
    "    Note: VERY SLOW FUNCTION (13 min for 1570 subjects) because it calculates every single one of the parcel*parcel covariance matrix pairwise partial correlation coefficients \n",
    "    (only half of that (e.g., upper triangle) would be necessary) -> takes double the time\n",
    "    \n",
    "    Input:\n",
    "    - array_ct_subjects_parcels: array containing CT data of all subjects per parcel -> shape N x parcels\n",
    "    - covar: list/series containing covariate variables for the structural covariance matrix (to control for during partial correlation), e.g., 3 covariates: [demographics_df.global_ct, demographics_df.age, demographics_df.sex]\n",
    "        - note: dummy variables need to be coded numerically (not with string labels)\n",
    "        - note: make sure that the length of the covariate variables are as long as the length of array containing CT data (i.e., N = number of subjects)\n",
    "    \n",
    "    Output:\n",
    "    - structural covariance matrix across subjects (parcels*parcels) in array format\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # import pingouin package which includes partial_corr -> function to compute partial correlation\n",
    "    import pingouin as pg\n",
    "    \n",
    "       \n",
    "\n",
    "\n",
    "    ### Format data to make it analyzable compute partial correlation: dataframe requirey by pingouin (pg) partial_corr function\n",
    "\n",
    "    # change shape from N x parcels to parcels x N, and turn array into a list in order to add covariates (lists of length = N) \n",
    "    df_ct_cov_matrix = (array_ct_subjects_parcels.T).tolist()\n",
    "\n",
    "    # add specified covariates\n",
    "    for i in range(len(covar)):\n",
    "        df_ct_cov_matrix.append(covar[i])\n",
    "\n",
    "    # make into dataframe (reverting back to shape N x parcels)\n",
    "     # columns = parcels + covariates, which can be called upon to compute pairwise partial correlations between parcels (x and y), whilst taking into account covariates (covar_indices)\n",
    "     # rows = subjects\n",
    "     # in this way, a the pairwise partial correlations are computed between 2 parcels, across all subject CT values for those parcel (e.g. Parcel 1 (CT values for N subjects) correlated with Parcel 2 (CT values for N subjects)\n",
    "    df_ct_cov_matrix = pd.DataFrame(np.array(df_ct_cov_matrix).T) \n",
    "    \n",
    "    \n",
    "    ### Compute structural covariance matrix across subjects using partial correlation (i.e., controling for covariates)\n",
    "    \n",
    "    # list of indices of covariates in dataframe (in descending order but doesn't matter, they are included all at once in partial correlation calculation) \n",
    "    covar_indices = []\n",
    "    \n",
    "    for i in range(len(covar)):\n",
    "        covar_indices.append(len(df_ct_cov_matrix.columns) - 1 - i)  # -1 in order to account for the fact that index starts at 0\n",
    "    \n",
    "\n",
    "    # list containing the structural covariance matrix\n",
    "    ct_cov_matrix_list = []\n",
    "\n",
    "    \n",
    "    # iteration across the parcels: to obtain the number of parcels, calculate length columns minus length covariates\n",
    "    for n in range(len(df_ct_cov_matrix.columns) - len(covar)):\n",
    "\n",
    "        # list for one line of the structural covariance matrix\n",
    "        line_partial_corr_coef = []\n",
    "        \n",
    "        # again iteration across the parcels to obtain a second iteration of parcel numbers, in order to correlate parcel(n) with parcel(i)\n",
    "        for i in range(len(df_ct_cov_matrix.columns) - len(covar)):\n",
    "\n",
    "            # if parcel number n and i are NOT the same, compute partial correlation coefficient\n",
    "            if i != n:\n",
    "                \n",
    "                # define x and y variables to correlate for this iteration (pairwise partial correlation)\n",
    "                x = df_ct_cov_matrix.columns[n]  # x variable to correlate (CT across all subjects for that given parcel): df column name (parcel number)\n",
    "                y = df_ct_cov_matrix.columns[i]  # y variable to correlate (CT across all subjects for that given parcel): df column name (parcel number)\n",
    "                \n",
    "                # compute the pairwise partial correlation (specifying the x and y variables to be correlated, as well as covariate variables <- what is specified is the dataframe, and the column names)\n",
    "                # directly storing the correlation coefficient (as a float)\n",
    "                partial_corr_coef = float(pg.partial_corr(data = df_ct_cov_matrix, x = x, y = y, covar = covar_indices, x_covar = None, y_covar = None, alternative=\"two-sided\", method = \"pearson\").r)\n",
    "                \n",
    "                # append the partial correlation coefficient to the list for the current line (iteration) of the structural covariance matrix\n",
    "                line_partial_corr_coef.append(partial_corr_coef)\n",
    "\n",
    "\n",
    "            # if i == n: correlation of the parcel with itself, so r = 1 (append this value manually)\n",
    "            else:\n",
    "                line_partial_corr_coef.append(1)\n",
    "\n",
    "            # if last iteration of the line (the line is already at its full length (i.e., len(line_partial_corr_coef) == number of parcels), append line of correlation coefficients to the full matrix list\n",
    "            if len(line_partial_corr_coef) == (len(df_ct_cov_matrix.columns) - len(covar)):  \n",
    "                ct_cov_matrix_list.append(line_partial_corr_coef)\n",
    "\n",
    "\n",
    "    # saving the structural covariance matrix in array format\n",
    "    ct_cov_matrix = np.array(ct_cov_matrix_list)\n",
    "    \n",
    "    \n",
    "    return ct_cov_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87080f56-e31f-4dd5-a8cf-338de85a3454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_wise_correlation_matrices(x, y, label_x, label_y):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Function that displays the row-wise correlation between structurak and functional 400x400 correlation matrices\n",
    "    Specific to plotting on surf_lh, surf_rh from conte69; for data coming from Schaefer 400 parcellation\n",
    "    \n",
    "    Input required: \n",
    "    - x: 400x400 mean matrix to correlate (1)\n",
    "    - y: 400x400 mean matrix to correlate (2)\n",
    "    \n",
    "    Output display:\n",
    "    - plotted hemispheres: correlation coefficients of row-by-row correlations of two matrices (e.g., structural matrix and functional matrix, but can also use this to compare datasets): \n",
    "        Interpretation: I get for each of the 400 parcels an r-value of the association/correlation between how that parcel correlates with the other 399 parcels (structure) and how thtat parcels correlates with the other 399 parcels (function)\n",
    "    - plotted hemispheres: p-values of row-by-row correlations of two matrices (e.g., structural matrix and functional matrix, but can also use this to compare datasets): \n",
    "    - plotted hemispheres: correlation coefficients of row-by-row correlations of two matrices that pass bonferonni significance threshold (e.g., structural matrix and functional matrix, but can also use this to compare datasets): \n",
    "    \n",
    "    plotted hemispheres displayed via handles -> need to display(*handles)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    count_sig = 0\n",
    "    count_sig_bonferroni = 0\n",
    "\n",
    "    list_p_val = []\n",
    "    list_corr_coef = []\n",
    "    list_corr_coef_bonferroni = []\n",
    "    list_corr_coef_bonferroni_nan = []\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        corr_coef = stats.pearsonr(x[i], y[i])[0]\n",
    "        p_val = stats.pearsonr(x[i], y[i])[1]\n",
    "\n",
    "        list_corr_coef.append(corr_coef)\n",
    "        list_p_val.append(p_val)\n",
    "\n",
    "        if p_val < (0.05):\n",
    "            count_sig += 1\n",
    "\n",
    "            if p_val < (0.05/400):\n",
    "                count_sig_bonferroni += 1\n",
    "                list_corr_coef_bonferroni.append(corr_coef)\n",
    "                list_corr_coef_bonferroni_nan.append(corr_coef)\n",
    "\n",
    "            else:\n",
    "                list_corr_coef_bonferroni_nan.append(float('nan'))  # if no significant we want to save as nan (will be grey in plot hemispheres display)\n",
    "       \n",
    "        else:\n",
    "            list_corr_coef_bonferroni_nan.append(float('nan'))  # if no significant we want to save as nan (will be grey in plot hemispheres display)\n",
    " \n",
    "    \n",
    "    print(f\"Significant row-wise correlations between {label_x} and {label_y} matrices: {count_sig}\")\n",
    "    print(f\"Significant row-wise correlations between {label_x} and {label_y} matrices: (Bonferroni corrected; alpha = 0.05/400 = 0.000125): {count_sig_bonferroni}\")\n",
    "\n",
    "\n",
    "    \n",
    "    ### Plots\n",
    "    \n",
    "    # defining labeling scheme and mask\n",
    "    labeling = load_parcellation('schaefer', scale=400, join=True)\n",
    "    surf_lh, surf_rh = load_conte69()\n",
    "    mask = labeling != 0\n",
    "    \n",
    "    \n",
    "    # will contain the different plots\n",
    "    handles = []\n",
    "    \n",
    "    \n",
    "    ## correlation coefficents\n",
    "    corrcoef_mapped_to_labels = map_to_labels(np.asarray(list_corr_coef), labeling, mask=mask, fill=np.nan)  \n",
    "    \n",
    "    corrcoef_plotted_hemispheres = plot_hemispheres(\n",
    "        surf_lh, \n",
    "        surf_rh, \n",
    "        array_name = corrcoef_mapped_to_labels, \n",
    "        embed_nb = True, \n",
    "        size = (1400,200), \n",
    "        cmap = \"PiYG\",\n",
    "        color_bar = True, \n",
    "        nan_color = (0.7, 0.7, 0.7, 1),\n",
    "        label_text = [\"corr coef (r)\"],\n",
    "        zoom = 1.45)\n",
    "    \n",
    "    # plot\n",
    "    handles.append(corrcoef_plotted_hemispheres)\n",
    "       \n",
    "        \n",
    "    \n",
    "    ## p-values\n",
    "    pvals_mapped_to_labels = map_to_labels(np.asarray(list_p_val), labeling, mask=mask, fill=np.nan)      \n",
    "    \n",
    "    # plot\n",
    "    pvals_plotted_hemispheres =  plot_hemispheres(\n",
    "        surf_lh, \n",
    "        surf_rh, \n",
    "        array_name = pvals_mapped_to_labels, \n",
    "        embed_nb = True, \n",
    "        size = (1400,200), \n",
    "        cmap = \"plasma_r\", \n",
    "        color_bar = True, \n",
    "        nan_color = (0.7, 0.7, 0.7, 1),\n",
    "        label_text = [\"p-values\"],\n",
    "        zoom = 1.45)\n",
    "    \n",
    "    handles.append(pvals_plotted_hemispheres)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## correlation coefficients (only the one passing Bonferroni corrected significance)   \n",
    "    corrcoef_bonf_mapped_to_labels = map_to_labels(np.asarray(list_corr_coef_bonferroni_nan), labeling, mask=mask, fill=np.nan)\n",
    "    \n",
    "    # decision of the color coding scheme\n",
    "    if sum(1 for number in list_corr_coef_bonferroni if number < 0) == 0:  # of there are no negative correlation coefficients (passing bonferroni corrected significance level)\n",
    "        color_decision = \"YlGn\"  # use color map that goes gradual from small to high\n",
    "    else:\n",
    "        color_decision = \"PiYG\"  # use color map that goes (-) to 0 to (+)\n",
    "    \n",
    "    corrcoef_bonf_plotted_hemispheres = plot_hemispheres(\n",
    "        surf_lh, \n",
    "        surf_rh, \n",
    "        array_name = corrcoef_bonf_mapped_to_labels, \n",
    "        embed_nb = True, \n",
    "        size = (1400,200), \n",
    "        cmap = color_decision,  \n",
    "        color_bar = True, \n",
    "        nan_color = (0.7, 0.7, 0.7, 1),\n",
    "        label_text = [\"corr coef (r) Bonf\"],\n",
    "        zoom = 1.45)\n",
    "    \n",
    "    handles.append(corrcoef_bonf_plotted_hemispheres)\n",
    "        \n",
    "        \n",
    "    return handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a39bfceb-7bbb-4714-80c9-088a0a9acdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ct_similarity_matrices_for_all_subjects(array_ct_subjects_parcels):\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    Function that computes cortical thickness similarity matrices for all subjects (individual level)\n",
    "\n",
    "    Note: VERY SLOW FUNCTION (15 min for 1570 subjects) because it calculates every single one of the parcel*parcel similarity coefficient\n",
    "    (only half of that (e.g., upper triangle) would be necessary) -> takes double the time\n",
    "    \n",
    "    Input:\n",
    "    - array_ct_subjects_parcels: array containing CT data of all subjects per parcel -> shape N x parcels\n",
    "      \n",
    "    Output:\n",
    "    - CT similarity matrices for each subject (shape: N x parcels x parcels) in array format\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ### list of standard deviation of CT values for each parcel (across subjects) -> required for formula calculating similarity coefficients\n",
    "\n",
    "    list_std_parcels = []\n",
    "\n",
    "    # iterate over parcels (by taking transposed ct_schaefer400 variable) \n",
    "    for i in range(len(array_ct_subjects_parcels.T)):\n",
    "\n",
    "        # calculate standard deviation of CT values for that parcel (across subjects)\n",
    "        std_parcel = np.std(array_ct_subjects_parcels.T[i])\n",
    "\n",
    "        # add standard deviation for current parcel to list\n",
    "        list_std_parcels.append(std_parcel)\n",
    "\n",
    "\n",
    "    ### compute similarity matrices (containing all subjects)\n",
    "\n",
    "    similarity_ct_matrices = []\n",
    "\n",
    "    # loop over subjects\n",
    "    for sub in range(len(array_ct_subjects_parcels)):\n",
    "\n",
    "        # list containing a subject's similarity matrix (400x400)\n",
    "        sub_similarity_ct_matrix = []\n",
    "\n",
    "        # iteration across parcels\n",
    "        for i in range(len(array_ct_subjects_parcels[sub])):        \n",
    "\n",
    "            # list containing one line (row) of the similarity matrix\n",
    "            line_similarity_ct_matrix_list = []\n",
    "\n",
    "            # again iteration across the parcels to obtain a second iteration of parcel numbers, in order to compute the similarity between parcel(n) with parcel(i)\n",
    "            for j in range(len(array_ct_subjects_parcels[sub])):\n",
    "\n",
    "                # compute similarity coefficient (according to: Wee et al (2013) https://onlinelibrary.wiley.com/doi/epdf/10.1002/hbm.22156) -> it works, proof: when i=j, yields similarity of 1.0\n",
    "\n",
    "                dissimilarity = (array_ct_subjects_parcels[sub][i] - array_ct_subjects_parcels[sub][j])**2\n",
    "\n",
    "                sigma = math.sqrt(list_std_parcels[i] + list_std_parcels[j])\n",
    "\n",
    "                # similarity coefficient\n",
    "                similarity = math.exp(- dissimilarity / (2 * (sigma)**2))\n",
    "\n",
    "                # append similarity coefficient for current parcel interaction to the line of similarity ct matrix (list)\n",
    "                line_similarity_ct_matrix_list.append(similarity)\n",
    "\n",
    "\n",
    "                # if last iteration (parcel) of the line (the line is already at its full length (i.e., len(line_similarity_ct_matrix_list) == number of parcels), append line of correlation coefficients to the subject's similarity matrix\n",
    "                if len(line_similarity_ct_matrix_list) == len(array_ct_subjects_parcels[sub]):  \n",
    "                    sub_similarity_ct_matrix.append(line_similarity_ct_matrix_list)\n",
    "\n",
    "        # if last iteration (line) of the matrix (the matrix is already at its full length (i.e., len(sub_similarity_ct_matrix) == number of parcels), append the subject's similarity matrix to the list of similarity ct matrices (all subjects)  \n",
    "        if len(sub_similarity_ct_matrix) == len(array_ct_subjects_parcels[sub]):\n",
    "            similarity_ct_matrices.append(sub_similarity_ct_matrix)\n",
    "\n",
    "    # saving the similarity matrix in array format\n",
    "    similarity_ct_matrices = np.array(similarity_ct_matrices)\n",
    "\n",
    "    return similarity_ct_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cade7a03-970f-465a-89f6-d9552bd631e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_parcel_values_scatter_bysex(male_data, female_data, title = None):\n",
    "    \n",
    "    '''\n",
    "    Function that males a scatterplot comparing mean male vs female parcel values (e.g. mean function gradient loading per parcel) color coded per Yeo network for Schaeffer 400\n",
    "    \n",
    "    Input: mean male and female values (format: array len = 400, i.e. number of Schafer parcels)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # make a dataframe containing the male and female data (to make it plottable)\n",
    "    dataframe = pd.DataFrame({'M': male_data, 'F': female_data})\n",
    "    \n",
    "    \n",
    "    # plot figure\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "    sns.scatterplot(data = dataframe, x = 'M', y = 'F', \n",
    "                    hue=yeo7_networks_array_labels,  # gives color coding based on yeo networks\n",
    "                    palette=palette_labeled_networks, \n",
    "                    s=70, \n",
    "                    edgecolor='black',\n",
    "                    linewidth=1)\n",
    "\n",
    "    # plot line x = y through getting the x and y limits\n",
    "    x0, x1 = ax.get_xlim()\n",
    "    y0, y1 = ax.get_ylim()\n",
    "    lims = [max(x0, y0), min(x1, y1)]\n",
    "    ax.plot(lims, lims, 'black', linewidth=2)\n",
    "\n",
    "    ax.axes.set_title(f\"Male vs Female {title}\", y=1.05, fontsize=25)\n",
    "    ax.set_xlabel(\"Males\",fontsize=25)\n",
    "    ax.set_ylabel(\"Females\",fontsize=25)\n",
    "    ax.tick_params(labelsize=25)\n",
    "    ax.legend(fontsize=25, bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "    \n",
    "    # Remove the top and right spines\n",
    "    sns.despine(top=True, right=True)\n",
    "\n",
    "    # Adjust the tick lines (optional)\n",
    "    plt.tick_params(axis='both', which='both', length=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb70650-4f4a-41eb-9109-675a884b7104",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a2ea4ec-b6df-4f94-9b56-cdf3d97f6058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variability_wholebrain_corr_to_mean(mean_grad, mean_grad_M, mean_grad_F, subject_grad, subject_ages, subject_sexes):\n",
    "    \n",
    "    '''\n",
    "    Function computing variability at the wholebrain level by correlating individual subject gradient loadings with mean gradient loadings (-> computing deviations from the mean as quantified by correlation coefficient) shown in plots\n",
    "    Ordering HCP subjects by age only for plotting purposes (although it could also include information on variability (i.e., if there seems to be an age effect))\n",
    "    \n",
    "    Input variables: \n",
    "    - mean_grad: mean gradient loadings (e.g. only gradient 1 loadings) - shape array: number of parcels\n",
    "    - mean_grad_M: mean gradient loadings for male subsample (e.g. only gradient 1 loadings) - shape array: number of parcels\n",
    "    - mean_grad_F: mean gradient loadings for female subsample (e.g. only gradient 1 loadings) - shape array: number of parcels\n",
    "    - subject_grad: aligned gradient loadings of all subjects - shape array: number of subjects x number of parcels\n",
    "    - subject_ages: list of subject ages\n",
    "    - subject_sexes: list of subject sexes\n",
    "    \n",
    "    Output:\n",
    "    - scatter and box plots comparing individual gradients to overall mean (ordered by age) -> To study variability as a function of age\n",
    "    - scatter and box plots comparing individual gradients to overall mean (color coded by sex) -> To study variability as a function of sex\n",
    "    - mean correlation coefficients by sex -> to indicate greater male or female variability\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ### Ordering subjects by age only for plotting purposes (although it could also include information on variability (i.e., if there seems to be an age effect)\n",
    "    \n",
    "    # getting the ages in their original order from demographics dataframe\n",
    "    subject_ages_rawoder = subject_ages\n",
    "\n",
    "    # np.argsort outputs the indices by which the list would be sorted (ascending order)\n",
    "    subject_indices_age_sorting = np.argsort(subject_ages_rawoder)\n",
    "\n",
    "    # sort the ages list\n",
    "    subject_ages_sorted = subject_ages_rawoder.copy()\n",
    "    subject_ages_sorted.sort()\n",
    "\n",
    "    # sort the subject gradient loadings by age (using the indices used to sort subject age list)\n",
    "    array_aligned_grad_age_sorted = np.array([subject_grad[i] for i in subject_indices_age_sorting])\n",
    "\n",
    "\n",
    "    # sort the subject sex variable by age (using the indices used to sort subject age list)\n",
    "    subject_sex_sorted = np.array([subject_sexes[i] for i in subject_indices_age_sorting])\n",
    "\n",
    "    # need to numberise the sex labels for plotting\n",
    "    subject_sex_sorted_num = []\n",
    "\n",
    "    for letter in subject_sex_sorted:\n",
    "        if letter == 'M':\n",
    "            subject_sex_sorted_num.append(0)\n",
    "        else:\n",
    "            subject_sex_sorted_num.append(1)\n",
    "\n",
    "    subject_sex_sorted_num = np.array(subject_sex_sorted_num)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ### computing differences between individual subject gradient loadings and mean sample gradient loadings (correlation coefficient) -> deviations from the mean\n",
    "\n",
    "    # computing the differences between the each HCP G1 and HCP mean G1 using correlation coefficient\n",
    "    list_corr_coeff_ind_mean_grad = []\n",
    "\n",
    "    # for every subject in the aligned gradient array, correlate that subject's gradient loadings with the mean gradient loadings\n",
    "    for sub in array_aligned_grad_age_sorted:\n",
    "\n",
    "        # appending correlation coefficient to the list\n",
    "        list_corr_coeff_ind_mean_grad.append(stats.pearsonr(mean_grad, sub)[0])\n",
    "\n",
    "\n",
    "    ### making a dictionary with correlation data to format it for making boxplots using sns\n",
    "    dict_ind_var = {'ages': subject_ages_sorted, 'sex': subject_sex_sorted, 'r_ind_mean': list_corr_coeff_ind_mean_grad}\n",
    "\n",
    "\n",
    "\n",
    "    ### computing differences between individual gradient loadings and mean gradient loadings FOR GIVEN SEX (correlation coefficient)\n",
    "    # THIS SHOULD BE USED WHEN COMPARING MALE TO FEMALE VARIABILITY IN GRADIENT LOADINGS given that there are more female subjects in sample, which would skew results towards better correlations (less variability) for females\n",
    "\n",
    "    # computing the differences between the each subject's gradient loadings and mean gradient loadings using correlation coefficient\n",
    "    list_corr_coeff_ind_mean_grad_bysex = []\n",
    "\n",
    "    # for every subject in the aligned G1 array, correlate that subject's gradient loadings with the mean HCP G1 loadings\n",
    "    for i in range(len(array_aligned_grad_age_sorted)):\n",
    "\n",
    "        # appending correlation coefficient to the list (correlation with mean male or mean female gradient values depending on sex of current subject iterated over\n",
    "        if subject_sex_sorted[i] == 'M':\n",
    "            list_corr_coeff_ind_mean_grad_bysex.append(stats.pearsonr(mean_grad_M, array_aligned_grad_age_sorted[i])[0])\n",
    "\n",
    "        else:\n",
    "            list_corr_coeff_ind_mean_grad_bysex.append(stats.pearsonr(mean_grad_F, array_aligned_grad_age_sorted[i])[0])\n",
    "\n",
    "    # appending correlation coefficient by sex to dictionary\n",
    "    dict_ind_var['r_ind_mean_bysex'] = list_corr_coeff_ind_mean_grad_bysex\n",
    "\n",
    "\n",
    "    # turning the dictionary into a dataframe\n",
    "    df_ind_var = pd.DataFrame(dict_ind_var)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### Plots\n",
    "\n",
    "    ## Comparing individual gradients to overall mean (ordered by age)\n",
    "    # To study variability as a function of age\n",
    "    \n",
    "    print(\"Correlation of individual gradient loadings to mean gradient loadings (age ordered)\")\n",
    "    \n",
    "    plt.scatter(subject_ages_sorted, list_corr_coeff_ind_mean_grad)\n",
    "    plt.show()\n",
    "    \n",
    "    sns.boxplot(data=dict_ind_var, x='ages', y='r_ind_mean') \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    ## Comparing individual gradients to mean of given sex\n",
    "    # To study wholebrain variability as a function of sex\n",
    "    \n",
    "    print(\"Correlation of individual gradient loadings to mean gradient loadings of given sex (color-coded by sex)\")\n",
    "    \n",
    "    colors = {'F':'firebrick', 'M':'royalblue'}\n",
    "\n",
    "    plt.scatter(subject_ages_sorted, list_corr_coeff_ind_mean_grad_bysex, c=df_ind_var['sex'].map(colors))\n",
    "    plt.show()\n",
    "    \n",
    "    sns.boxplot(data=dict_ind_var, x='sex', y='r_ind_mean_bysex', palette=colors, fliersize = 2) \n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Mean correlation coefficient of male individual gradients and mean male gradient: M = {round(df_ind_var.loc[df_ind_var['sex'] == 'M', 'r_ind_mean_bysex'].mean(), 2)}; SD = {round(df_ind_var.loc[df_ind_var['sex'] == 'M', 'r_ind_mean_bysex'].std(), 3)}\\n\"\n",
    "      f\"Mean correlation coefficient of female individual gradients and mean female gradient: M = {round(df_ind_var.loc[df_ind_var['sex'] == 'F', 'r_ind_mean_bysex'].mean(), 2)}; SD = {round(df_ind_var.loc[df_ind_var['sex'] == 'F', 'r_ind_mean_bysex'].std(), 3)}\\n\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de4e0dc-2755-445c-bc48-7b21e591fe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variability_parcel_std(subject_grad, subject_grad_M, subject_grad_F, sample_modality, save_plots = False, output_dir = None):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Function that computes variability at the parcel level: Visualizing standard deviation by parcels in both sexes separately in order to visualize which sex and parcels have most variability\n",
    "    - computing the 'difference score' of std (male std - female std) as quantification\n",
    "    - testing the significance of the sex difference using Levene's test for homogeneity of variance (+ FDR-correction)\n",
    "    - computing a network breakdown of significant differences (pie charts)\n",
    "    \n",
    "    Input variables:\n",
    "    - subject_grad: aligned gradient loadings of all subjects - shape array: number of subjects x number of parcels\n",
    "    - subject_grad_M: aligned gradient loadings of male subjects - shape array: number of subjects x number of parcels\n",
    "    - subject_grad_F: aligned gradient loadings of female subjects - shape array: number of subjects x number of parcels\n",
    "    - save_plots: True/False if want to save screenshots of plotted hemispheres and network breakdown of significant differences\n",
    "    - output_dir: path to output directory (e.g. resdir_fig, i.e. '/data/p_02667/sex_diff_gradients/results/figures/')\n",
    "    - sample_modality: will be included in label of saved plot names (e.g., 'HCP_fc_G1')\n",
    "    \n",
    "    Output:\n",
    "    - Number of parcels for which there males have a statistically significant larger variance than females; and for which females have a statistically significant larger variance than males (before and after FDR correction)\n",
    "    - plotted hemispheres: *STD across all subjects, STD males, STD females, difference STD M - F, p-values Levene's test, q-values Levene's test (FDR), difference STD for p sig, *difference STD for q sig\n",
    "    - nested pie chart: breakdown of statistically significant sex differences by network\n",
    "    - saves in output_dir: *STD_plotted_hemispheres_across_sexes, *STD_plotted_hemispheres_sex_differences_fdr_corr, and STD_pie_chart_sex_diff_netw\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ### Compute std per parcel, across all subjects, and for males and females separately\n",
    "    std_grad = np.std(subject_grad, axis=0)\n",
    "    std_grad_M = np.std(subject_grad_M, axis=0)\n",
    "    std_grad_F = np.std(subject_grad_F, axis=0)\n",
    "\n",
    "\n",
    "    ### Compute the difference between males and female std (where positive scores show greater male variability)\n",
    "    std_grad_sexdiff = std_grad_M - std_grad_F\n",
    "\n",
    "    \n",
    "    ### Significance testing of the differences\n",
    "\n",
    "    # list that will contain the p values of the Levene's test for homogeneity of variance (per parcel) -> p < 0.05 mean NOT homogeneous variance, meaning that we can interpret the variability (as provided by difference of STD) as statistically significant\n",
    "    p_val_levene_grad_male_vs_female = []\n",
    "\n",
    "    # loop over 400 parcels\n",
    "    for i in range(len(subject_grad_M.T)):\n",
    "\n",
    "        # test for homogeneity of variance within this parcel (between males and females) - [1] indexes the p-value -> append p-value to list\n",
    "        p_val_levene_grad_male_vs_female.append(stats.levene(subject_grad_M.T[i], subject_grad_F.T[i])[1])\n",
    "\n",
    "    p_val_levene_grad_male_vs_female = np.array(p_val_levene_grad_male_vs_female)\n",
    "\n",
    "\n",
    "    # compute the FDR-corrected q values of G1 sex differences in variance as given from Levene's test pvalues\n",
    "    fdr_corr_p_val_levene_grad_male_vs_female = fdrcorrection(p_val_levene_grad_male_vs_female)[1]\n",
    "\n",
    "\n",
    "\n",
    "    # list that will contain difference score (M - F) of STD only for parcels who show statistical inhomogeneity of variance (i.e., Levene's test: p < 0.05) - NOT FDR corrected (just to see patterns)\n",
    "    std_grad_levene_sig_sexdiff = []\n",
    "\n",
    "    for i in range(400):\n",
    "        if p_val_levene_grad_male_vs_female[i] <= 0.05:\n",
    "            std_grad_levene_sig_sexdiff.append(std_grad_sexdiff[i])\n",
    "        else:\n",
    "            std_grad_levene_sig_sexdiff.append(float('nan'))\n",
    "\n",
    "    std_grad_levene_sig_sexdiff = np.array(std_grad_levene_sig_sexdiff)\n",
    "\n",
    "\n",
    "    print(f\"Number of parcels for which there males have a statistically significant larger variance than females: {np.sum(np.array(std_grad_levene_sig_sexdiff) > 0, axis=0)}\")\n",
    "    print(f\"Number of parcels for which there females have a statistically significant larger variance than males: {np.sum(np.array(std_grad_levene_sig_sexdiff) < 0, axis=0)}\")\n",
    "\n",
    "\n",
    "\n",
    "    # list that will contain difference score (M - F) of STD only for parcels who show statistical inhomogeneity of variance (i.e., Levene's test: p < 0.05) AFTER FDR correction (so where q < 0.05)\n",
    "    std_grad_fdr_corr_levene_sig_sexdiff = []\n",
    "\n",
    "    for i in range(400):\n",
    "        if fdr_corr_p_val_levene_grad_male_vs_female[i] <= 0.05:\n",
    "            std_grad_fdr_corr_levene_sig_sexdiff.append(std_grad_sexdiff[i])\n",
    "        else:\n",
    "            std_grad_fdr_corr_levene_sig_sexdiff.append(float('nan'))\n",
    "\n",
    "    std_grad_fdr_corr_levene_sig_sexdiff = np.array(std_grad_fdr_corr_levene_sig_sexdiff)\n",
    "\n",
    "\n",
    "    print(f\"Number of parcels for which there males have a statistically significant larger variance than females after FDR-correction: {np.sum(np.array(std_grad_fdr_corr_levene_sig_sexdiff) > 0, axis=0)}\")\n",
    "    print(f\"Number of parcels for which there females have a statistically significant larger variance than males after FDR-correction: {np.sum(np.array(std_grad_fdr_corr_levene_sig_sexdiff) < 0, axis=0)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### Find min and max std across sexes (this is for plotting the color bar in the plotted hemispheres)\n",
    "\n",
    "    if min(std_grad_M) < min(std_grad_F):\n",
    "        min_std = min(std_grad_M)\n",
    "    else:\n",
    "        min_std = min(std_grad_F)\n",
    "\n",
    "    print(f\"\\nMinimum SD: Males = {round(min(std_grad_M), 3)}; Females = {round(min(std_grad_F), 3)}\")\n",
    "\n",
    "\n",
    "    if max(std_grad_M) > max(std_grad_F):\n",
    "        max_std = max(std_grad_M)\n",
    "    else:\n",
    "        max_std = max(std_grad_F)\n",
    "\n",
    "    print(f\"Maximum SD: Males = {round(max(std_grad_M), 3)}; Females = {round(max(std_grad_F), 3)}\")\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    ### plot the standard deviations on hemispheres\n",
    "\n",
    "    # defining labeling scheme and mask\n",
    "    labeling = load_parcellation('schaefer', scale=400, join=True)\n",
    "    surf_lh, surf_rh = load_conte69()\n",
    "\n",
    "    mask = labeling != 0\n",
    "\n",
    "    # will contain the different plots\n",
    "    handles = []\n",
    "\n",
    "    std_to_labels = map_to_labels(std_grad, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    plotted_hemispheres_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=std_to_labels, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 label_text=['STD'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = save_plots,\n",
    "                                                 filename = output_dir+sample_modality+'_STD_plotted_hemispheres_across_sexes.png')\n",
    "\n",
    "    handles.append(plotted_hemispheres_std)\n",
    "\n",
    "\n",
    "\n",
    "    std_to_labels_M = map_to_labels(std_grad_M, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    plotted_hemispheres_M_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=std_to_labels_M, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 label_text=['Males'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = save_plots,\n",
    "                                                 filename = output_dir+sample_modality+'_STD_plotted_hemispheres_M.png')\n",
    "\n",
    "    handles.append(plotted_hemispheres_M_std)\n",
    "\n",
    "\n",
    "\n",
    "    std_to_labels_F = map_to_labels(std_grad_F, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    plotted_hemispheres_F_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=std_to_labels_F, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 label_text=['Females'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = save_plots,\n",
    "                                                 filename = output_dir+sample_modality+'_STD_plotted_hemispheres_F.png')\n",
    "\n",
    "    handles.append(plotted_hemispheres_F_std)\n",
    "\n",
    "\n",
    "\n",
    "    std_grad_sexdiff_to_labels = map_to_labels(std_grad_sexdiff, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    plotted_hemispheres_std_grad_sexdiff = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=std_grad_sexdiff_to_labels, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 cmap='bwr_r', \n",
    "                                                 color_bar=True,\n",
    "                                                 color_range='sym',\n",
    "                                                 label_text=['STD(M) - STD (F)'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False\n",
    "                                                )\n",
    "\n",
    "    handles.append(plotted_hemispheres_std_grad_sexdiff)\n",
    "\n",
    "\n",
    "\n",
    "    levene_pval_to_labels = map_to_labels(p_val_levene_grad_male_vs_female, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    plotted_hemispheres_levene_pval = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=levene_pval_to_labels, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 cmap='plasma_r', \n",
    "                                                 color_bar=True, \n",
    "                                                 label_text=[\"Levene's p-vals\"], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False\n",
    "                                                )\n",
    "\n",
    "    handles.append(plotted_hemispheres_levene_pval)\n",
    "\n",
    "\n",
    "\n",
    "    fdr_corr_levene_pval_to_labels = map_to_labels(fdr_corr_p_val_levene_grad_male_vs_female, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    plotted_hemispheres_fdr_corr_levene_pval = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=fdr_corr_levene_pval_to_labels, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 cmap='plasma_r', \n",
    "                                                 color_bar=True, \n",
    "                                                 label_text=[\"FDR-corrected\\nLevene's q-vals\"], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False\n",
    "                                                )\n",
    "\n",
    "    handles.append(plotted_hemispheres_fdr_corr_levene_pval)\n",
    "\n",
    "\n",
    "\n",
    "    std_grad_sig_Levene_sexdiff_to_labels = map_to_labels(std_grad_levene_sig_sexdiff, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    plotted_hemispheres_std_grad_levene_sig_sexdiff = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=std_grad_sig_Levene_sexdiff_to_labels, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 cmap='bwr_r', \n",
    "                                                 color_bar=True, \n",
    "                                                 color_range='sym',\n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['Differences STD\\nfor Levene p<.05'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False\n",
    "                                                )\n",
    "\n",
    "    handles.append(plotted_hemispheres_std_grad_levene_sig_sexdiff)\n",
    "\n",
    "\n",
    "    std_grad_sig_fdr_corr_levene_sexdiff_to_labels = map_to_labels(std_grad_fdr_corr_levene_sig_sexdiff, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    plotted_hemispheres_std_grad_fdr_corr_levene_sig_sexdiff = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=std_grad_sig_fdr_corr_levene_sexdiff_to_labels, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 cmap='bwr_r', \n",
    "                                                 color_bar=True, \n",
    "                                                 color_range='sym',\n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['Differences STD\\nfor FDR-corrected\\nLevene q<.05'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = save_plots,\n",
    "                                                 filename = output_dir+sample_modality+'_STD_plotted_hemispheres_sex_differences_fdr_corr.png')\n",
    "\n",
    "    handles.append(plotted_hemispheres_std_grad_fdr_corr_levene_sig_sexdiff)\n",
    "\n",
    "\n",
    "    display(*handles)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    ### breakdown by network\n",
    "    \n",
    "    \n",
    "    ## written breakdown\n",
    "\n",
    "    # counting number of significant parcels\n",
    "    # storing the Q values in a list (where non significant Q values are marked as 1 -> for later potential scatterplot visualization)\n",
    "    # making a dictionary that counts the number of significant parcels per yeo network\n",
    "    # making dictionaries that count the number of significant parcels per yeo network by sex\n",
    "\n",
    "    sig_Q_vals = []\n",
    "    count_sig = 0\n",
    "    count_sig_M = 0\n",
    "    count_sig_F = 0\n",
    "    count_sig_per_network = {\"visual\": 0, \"sensory motor\": 0, \"DMN\": 0, \"dorsal attention\": 0, \"ventral attention\": 0, \"limbic\": 0, \"fronto parietal\": 0}\n",
    "    count_sig_per_network_bysex = {\"visual\": [0, 0], \"sensory motor\": [0,0], \"DMN\": [0,0], \"dorsal attention\": [0,0], \"ventral attention\": [0,0], \"limbic\": [0,0], \"fronto parietal\": [0,0]} # M: [0], F: [1]\n",
    "\n",
    "    # loop over 400 parcels\n",
    "    for i in range(len(fdr_corr_p_val_levene_grad_male_vs_female)):\n",
    "\n",
    "        if fdr_corr_p_val_levene_grad_male_vs_female[i] < 0.05:\n",
    "            count_sig += 1\n",
    "            count_sig_per_network[yeo7_networks_array_labels[i]] += 1\n",
    "            sig_Q_vals.append(1)\n",
    "\n",
    "            # positive t-values mean male > female: increment the first item of the list fort given label\n",
    "            if std_grad_sexdiff[i] > 0:\n",
    "                count_sig_M += 1\n",
    "                count_sig_per_network_bysex[yeo7_networks_array_labels[i]][0] += 1\n",
    "\n",
    "            # positive t-values mean female > male: increment the second item of the list for the given label\n",
    "            else:\n",
    "                count_sig_F += 1\n",
    "                count_sig_per_network_bysex[yeo7_networks_array_labels[i]][1] += 1\n",
    "\n",
    "        else:\n",
    "            sig_Q_vals.append(0)\n",
    "\n",
    "    print(f\"Number of significant parcels: {count_sig}\\n\")\n",
    "    print(f\"Number of significant parcels for males: {count_sig_M}\")\n",
    "    print(f\"Number of significant parcels for females: {count_sig_F}\\n\")\n",
    "    print(\"Number of significant parcels in each Yeo network (across sexes):\")\n",
    "\n",
    "    # using ANSI escape sequences to underline -> bold: \\033[1m ; underline: \\033[4m ; end: \\033[0m\n",
    "    for i in range(len(count_sig_per_network)):\n",
    "        print(f\"- {list(count_sig_per_network.keys())[i]}: \\033[4m{count_sig_per_network[list(count_sig_per_network.keys())[i]]}\\033[0m out of {yeo7_networks_array_labels.tolist().count(network_names[i])} ({round(count_sig_per_network[list(count_sig_per_network.keys())[i]] / yeo7_networks_array_labels.tolist().count(network_names[i]) * 100, 2)}%) -> \\033[1m{round(count_sig_per_network[list(count_sig_per_network.keys())[i]]*100/count_sig,2)}%\\033[0m of overall significance\")\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### Nested pie chart\n",
    "\n",
    "    ## make data plottable\n",
    "    list_count_sig_per_network_bysex = []\n",
    "\n",
    "    for label in count_sig_per_network_bysex:\n",
    "        list_count_sig_per_network_bysex.append(count_sig_per_network_bysex[label])\n",
    "\n",
    "    vals = np.array(list_count_sig_per_network_bysex)\n",
    "\n",
    "    outer_colors = [\"darkorchid\",  # visual\n",
    "                    \"steelblue\",  # sensorimotor\n",
    "                    \"indianred\",  # dmn\n",
    "                    \"forestgreen\",  # dorsal attention\n",
    "                    \"orchid\",  # ventral attention\n",
    "                    \"lemonchiffon\",  # limbic\n",
    "                    \"orange\"]  # frontoparietal\n",
    "    inner_colors = ['lightblue', 'lightcoral',  # visual\n",
    "                    'lightblue', 'lightcoral',  # sensorimotor\n",
    "                    'lightblue', 'lightcoral',  # dmn\n",
    "                    'lightblue', 'lightcoral',  # dorsal attention\n",
    "                    'lightblue', 'lightcoral',  # ventral attention\n",
    "                    'lightblue', 'lightcoral',  # limbic\n",
    "                    'lightblue', 'lightcoral']  #frontoparietal\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "    size = 0.3\n",
    "\n",
    "    ## plot outer pie\n",
    "    ax.pie(vals.sum(axis=1), radius=1, labels=count_sig_per_network_bysex.keys(), colors=outer_colors, autopct='%.0f%%', pctdistance=0.85,\n",
    "           wedgeprops=dict(width=size, edgecolor='white'),  textprops={'fontsize': 20})\n",
    "\n",
    "    ## plot inner pie\n",
    "\n",
    "    # make a list (in order) containing the labels (sex - hardcoded) only for sections that have more than 1 count (otherwise label is placeholder: blank)\n",
    "\n",
    "    labels_only_show_non_null = []\n",
    "\n",
    "    for network in list_count_sig_per_network_bysex:\n",
    "\n",
    "        # males\n",
    "        if network[0] > 0:\n",
    "            labels_only_show_non_null.append('M')\n",
    "        else:\n",
    "            labels_only_show_non_null.append('')\n",
    "\n",
    "        # females\n",
    "        if network[1] > 0:\n",
    "            labels_only_show_non_null.append('F')\n",
    "        else:\n",
    "            labels_only_show_non_null.append('')\n",
    "\n",
    "    ax.pie(vals.flatten(), radius=1-size, labels=labels_only_show_non_null, colors=inner_colors,\n",
    "           wedgeprops=dict(width=size, edgecolor='white'),  textprops={'fontsize': 15},  labeldistance=0.78)\n",
    "\n",
    "    ax.set(aspect=\"equal\")\n",
    "    ax.set_title(f'Breakdown of parcels by network showing a statistically significant sex difference in gradient loadings, by sex', y=1.03, fontsize=20)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print('Number of significant parcels by sex:')\n",
    "    for network in count_sig_per_network_bysex:\n",
    "        print(f\"{network} - Male: {count_sig_per_network_bysex[network][0]}, Female: {count_sig_per_network_bysex[network][1]}\")\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    ### plot outer and inner pie (without labels)\n",
    "\n",
    "    fig, disp = plt.subplots(figsize=(15, 10))\n",
    "    size = 0.3\n",
    "\n",
    "    disp.pie(vals.sum(axis=1), radius=1, colors=outer_colors, pctdistance=0.85,\n",
    "           wedgeprops=dict(width=size, edgecolor='black'),  textprops={'fontsize': 20})\n",
    "\n",
    "    disp.pie(vals.flatten(), radius=1-size, colors=inner_colors,\n",
    "           wedgeprops=dict(width=size, edgecolor='blacK'),  textprops={'fontsize': 15},  labeldistance=0.78)\n",
    "\n",
    "    disp.set(aspect=\"equal\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    if save_plots:\n",
    "        ## save figure in directory \n",
    "        fig.savefig(output_dir+sample_modality+'_STD_pie_chart_sex_diff_netw.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4204acb9-c97f-4fa9-aa2d-3e7c545737a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variability_network_corr_to_mean_G1(mean_grad, mean_grad_M, mean_grad_F, subject_grad, subject_grad_M, subject_grad_F):\n",
    "    \n",
    "    '''\n",
    "    Function computing variability at the network level by correlating individual subject gradient loadings (HARDCODED FOR G1!!) with mean gradient loadings (-> computing deviations from the mean as quantified by correlation coefficient) by sex, shown in plots\n",
    "    CAUTION: working with data that is NOT age sorted here (different to variability_wholebrain_corr_to_mean function)\n",
    "    \n",
    "    Input variables: \n",
    "    - mean_grad: mean gradient loadings (full gradient array container -> HCP_mean_fc_grad.gradients_) - shape array: number of parcels x number of gradients computed (10)\n",
    "    - mean_grad_M: mean gradient loadings for male subsample (full gradient array container -> HCP_mean_fc_grad_M.gradients_) - shape array: number of parcels x number of gradients computed (10)\n",
    "    - mean_grad_F: mean gradient loadings for female subsample (full gradient array container -> HCP_mean_fc_grad_M.gradients_) - shape array: number of parcels x number of gradients computed (10)\n",
    "    - subject_grad: aligned gradient loadings of all subjects - shape array: number of subjects x number of parcels\n",
    "    - subject_grad_M: aligned gradient loadings of male subjects - shape array: number of subjects x number of parcels\n",
    "    - subject_grad_F: aligned gradient loadings of female subjects - shape array: number of subjects x number of parcels\n",
    "    \n",
    "    Output:\n",
    "    - box plot correlation coefficients by network (color-coded by sex)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    ### compute mean gradient loadings per networks (overall and by sex)\n",
    "\n",
    "    # lists that will contain mean gradient loadings (per network)\n",
    "    visual_mean_grad_loadings = []\n",
    "    sensorimotor_mean_grad_loadings = []\n",
    "    dorsalattention_mean_grad_loadings = []\n",
    "    ventralattention_mean_grad_loadings = []\n",
    "    limbic_mean_grad_loadings = []\n",
    "    frontoparietal_mean_grad_loadings = []\n",
    "    dmn_mean_grad_loadings = []\n",
    "\n",
    "\n",
    "    # lists that will contain mean gradient loadings (per network) by sex\n",
    "    visual_mean_grad_loadings_M = []\n",
    "    sensorimotor_mean_grad_loadings_M = []\n",
    "    dorsalattention_mean_grad_loadings_M = []\n",
    "    ventralattention_mean_grad_loadings_M = []\n",
    "    limbic_mean_grad_loadings_M = []\n",
    "    frontoparietal_mean_grad_loadings_M = []\n",
    "    dmn_mean_grad_loadings_M = []\n",
    "\n",
    "    visual_mean_grad_loadings_F = []\n",
    "    sensorimotor_mean_grad_loadings_F = []\n",
    "    dorsalattention_mean_grad_loadings_F = []\n",
    "    ventralattention_mean_grad_loadings_F = []\n",
    "    limbic_mean_grad_loadings_F = []\n",
    "    frontoparietal_mean_grad_loadings_F = []\n",
    "    dmn_mean_grad_loadings_F = []\n",
    "\n",
    "\n",
    "\n",
    "    # iterating over 400 parcels \n",
    "    # CAUTION: THIS PART IS HARCODED FOR GRADIENT 1 (index: [i,0])\n",
    "    for i in range(len(mean_grad[:,0])):\n",
    "\n",
    "        # append given parcel's mean G1 loading to the corresponding list depending on what network it belongs to \n",
    "        # doing for overall, males, and females separately (ok because we're looping over the number of parcels, which is the same for all 3 cases\n",
    "        if yeo7_networks_array_labels[i] == 'visual':\n",
    "            visual_mean_grad_loadings.append(mean_grad[i,0])\n",
    "            visual_mean_grad_loadings_M.append(mean_grad_M[i,0])\n",
    "            visual_mean_grad_loadings_F.append(mean_grad_F[i,0])\n",
    "\n",
    "        elif yeo7_networks_array_labels[i] == 'sensory motor':\n",
    "            sensorimotor_mean_grad_loadings.append(mean_grad[i,0])\n",
    "            sensorimotor_mean_grad_loadings_M.append(mean_grad_M[i,0])\n",
    "            sensorimotor_mean_grad_loadings_F.append(mean_grad_F[i,0])\n",
    "\n",
    "        elif yeo7_networks_array_labels[i] == 'dorsal attention':\n",
    "            dorsalattention_mean_grad_loadings.append(mean_grad[i,0])\n",
    "            dorsalattention_mean_grad_loadings_M.append(mean_grad_M[i,0])\n",
    "            dorsalattention_mean_grad_loadings_F.append(mean_grad_F[i,0])\n",
    "\n",
    "        elif yeo7_networks_array_labels[i] == 'ventral attention':\n",
    "            ventralattention_mean_grad_loadings.append(mean_grad[i,0])\n",
    "            ventralattention_mean_grad_loadings_M.append(mean_grad_M[i,0])\n",
    "            ventralattention_mean_grad_loadings_F.append(mean_grad_F[i,0])\n",
    "\n",
    "        elif yeo7_networks_array_labels[i] == 'limbic':\n",
    "            limbic_mean_grad_loadings.append(mean_grad[i,0])\n",
    "            limbic_mean_grad_loadings_M.append(mean_grad_M[i,0])\n",
    "            limbic_mean_grad_loadings_F.append(mean_grad_F[i,0])\n",
    "\n",
    "        elif yeo7_networks_array_labels[i] == 'fronto parietal':\n",
    "            frontoparietal_mean_grad_loadings.append(mean_grad[i,0])\n",
    "            frontoparietal_mean_grad_loadings_M.append(mean_grad_M[i,0])\n",
    "            frontoparietal_mean_grad_loadings_F.append(mean_grad_F[i,0])\n",
    "\n",
    "        elif yeo7_networks_array_labels[i] == 'DMN':\n",
    "            dmn_mean_grad_loadings.append(mean_grad[i,0])\n",
    "            dmn_mean_grad_loadings_M.append(mean_grad_M[i,0])\n",
    "            dmn_mean_grad_loadings_F.append(mean_grad_F[i,0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### compute per subject (overall)\n",
    "\n",
    "    # lists that will contain subject-level gradient loadings (per network) - length of each list is N, within each list length is parcel numbers belonging to given network\n",
    "    visual_sub_grad_loadings = []\n",
    "    sensorimotor_sub_grad_loadings = []\n",
    "    dorsalattention_sub_grad_loadings = []\n",
    "    ventralattention_sub_grad_loadings = []\n",
    "    limbic_sub_grad_loadings = []\n",
    "    frontoparietal_sub_grad_loadings = []\n",
    "    dmn_sub_grad_loadings = []\n",
    "\n",
    "\n",
    "    # for every subject in the aligned gradient array\n",
    "    for j in range(len(subject_grad)):\n",
    "\n",
    "        # lists that will contain temporary (given subject, iterated over)'s G1 gradient loadings (per network)\n",
    "        temp_visual_sub_grad_loadings = []\n",
    "        temp_sensorimotor_sub_grad_loadings = []\n",
    "        temp_dorsalattention_sub_grad_loadings = []\n",
    "        temp_ventralattention_sub_grad_loadings = []\n",
    "        temp_limbic_sub_grad_loadings = []\n",
    "        temp_frontoparietal_sub_grad_loadings = []\n",
    "        temp_dmn_sub_grad_loadings = []\n",
    "\n",
    "        # iterating over 400 parcels (of gradient loadings) for given subject\n",
    "        for i in range(len(subject_grad[j])):\n",
    "\n",
    "            # append given parcel's mean gradient loading to the corresponding list depending on what network it belongs to   \n",
    "            if yeo7_networks_array_labels[i] == 'visual':\n",
    "                temp_visual_sub_grad_loadings.append(subject_grad[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'sensory motor':\n",
    "                temp_sensorimotor_sub_grad_loadings.append(subject_grad[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'dorsal attention':\n",
    "                temp_dorsalattention_sub_grad_loadings.append(subject_grad[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'ventral attention':\n",
    "                temp_ventralattention_sub_grad_loadings.append(subject_grad[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'limbic':\n",
    "                temp_limbic_sub_grad_loadings.append(subject_grad[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'fronto parietal':\n",
    "                temp_frontoparietal_sub_grad_loadings.append(subject_grad[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'DMN':\n",
    "                temp_dmn_sub_grad_loadings.append(subject_grad[j][i])\n",
    "\n",
    "\n",
    "            # when last iteration of subject, append all the given subject's temp lists to main list\n",
    "            if i == 399:\n",
    "                visual_sub_grad_loadings.append(temp_visual_sub_grad_loadings)\n",
    "                sensorimotor_sub_grad_loadings.append(temp_sensorimotor_sub_grad_loadings)\n",
    "                dorsalattention_sub_grad_loadings.append(temp_dorsalattention_sub_grad_loadings)\n",
    "                ventralattention_sub_grad_loadings.append(temp_ventralattention_sub_grad_loadings)\n",
    "                limbic_sub_grad_loadings.append(temp_limbic_sub_grad_loadings)\n",
    "                frontoparietal_sub_grad_loadings.append(temp_frontoparietal_sub_grad_loadings)\n",
    "                dmn_sub_grad_loadings.append(temp_dmn_sub_grad_loadings)       \n",
    "\n",
    "\n",
    "\n",
    "    ### compute per subject (by sex) - need to do this separately because looping over subjects in aligned gradients per sex (aligned to that sex's mean gradient) which are of different lengths in males vs females\n",
    "\n",
    "    ## MALES\n",
    "\n",
    "    # lists that will contain subject-level G1 gradient loadings (per network) - length of each list is N males, within each list length is parcel numbers belonging to given network\n",
    "    visual_sub_grad_loadings_M = []\n",
    "    sensorimotor_sub_grad_loadings_M = []\n",
    "    dorsalattention_sub_grad_loadings_M = []\n",
    "    ventralattention_sub_grad_loadings_M = []\n",
    "    limbic_sub_grad_loadings_M = []\n",
    "    frontoparietal_sub_grad_loadings_M = []\n",
    "    dmn_sub_grad_loadings_M = []\n",
    "\n",
    "\n",
    "    # for every subject in the HCP aligned G1 array\n",
    "    for j in range(len(subject_grad_M)):\n",
    "\n",
    "        # lists that will contain temporary (given subject, iterated over)'s G1 gradient loadings (per network)\n",
    "        temp_visual_sub_grad_loadings = []\n",
    "        temp_sensorimotor_sub_grad_loadings = []\n",
    "        temp_dorsalattention_sub_grad_loadings = []\n",
    "        temp_ventralattention_sub_grad_loadings = []\n",
    "        temp_limbic_sub_grad_loadings = []\n",
    "        temp_frontoparietal_sub_grad_loadings = []\n",
    "        temp_dmn_sub_grad_loadings = []\n",
    "\n",
    "        # iterating over 400 parcels (of G1 loadings) for given subject\n",
    "        for i in range(len(subject_grad_M[j])):\n",
    "\n",
    "            # append given parcel's mean G1 loading to the corresponding list depending on what network it belongs to   \n",
    "            if yeo7_networks_array_labels[i] == 'visual':\n",
    "                temp_visual_sub_grad_loadings.append(subject_grad_M[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'sensory motor':\n",
    "                temp_sensorimotor_sub_grad_loadings.append(subject_grad_M[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'dorsal attention':\n",
    "                temp_dorsalattention_sub_grad_loadings.append(subject_grad_M[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'ventral attention':\n",
    "                temp_ventralattention_sub_grad_loadings.append(subject_grad_M[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'limbic':\n",
    "                temp_limbic_sub_grad_loadings.append(subject_grad_M[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'fronto parietal':\n",
    "                temp_frontoparietal_sub_grad_loadings.append(subject_grad_M[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'DMN':\n",
    "                temp_dmn_sub_grad_loadings.append(subject_grad_M[j][i])\n",
    "\n",
    "\n",
    "            # when last iteration of subject, append all the given subject's temp lists to main list\n",
    "            if i == 399:\n",
    "                visual_sub_grad_loadings_M.append(temp_visual_sub_grad_loadings)\n",
    "                sensorimotor_sub_grad_loadings_M.append(temp_sensorimotor_sub_grad_loadings)\n",
    "                dorsalattention_sub_grad_loadings_M.append(temp_dorsalattention_sub_grad_loadings)\n",
    "                ventralattention_sub_grad_loadings_M.append(temp_ventralattention_sub_grad_loadings)\n",
    "                limbic_sub_grad_loadings_M.append(temp_limbic_sub_grad_loadings)\n",
    "                frontoparietal_sub_grad_loadings_M.append(temp_frontoparietal_sub_grad_loadings)\n",
    "                dmn_sub_grad_loadings_M.append(temp_dmn_sub_grad_loadings)       \n",
    "\n",
    "\n",
    "    ## FEMALES\n",
    "\n",
    "    # lists that will contain subject-level G1 gradient loadings (per network) - length of each list is N females, within each list length is parcel numbers belonging to given network\n",
    "    visual_sub_grad_loadings_F = []\n",
    "    sensorimotor_sub_grad_loadings_F = []\n",
    "    dorsalattention_sub_grad_loadings_F = []\n",
    "    ventralattention_sub_grad_loadings_F = []\n",
    "    limbic_sub_grad_loadings_F = []\n",
    "    frontoparietal_sub_grad_loadings_F = []\n",
    "    dmn_sub_grad_loadings_F = []\n",
    "\n",
    "\n",
    "    # for every subject in the HCP aligned G1 array\n",
    "    for j in range(len(subject_grad_F)):\n",
    "\n",
    "        # lists that will contain temporary (given subject, iterated over)'s G1 gradient loadings (per network)\n",
    "        temp_visual_sub_grad_loadings = []\n",
    "        temp_sensorimotor_sub_grad_loadings = []\n",
    "        temp_dorsalattention_sub_grad_loadings = []\n",
    "        temp_ventralattention_sub_grad_loadings = []\n",
    "        temp_limbic_sub_grad_loadings = []\n",
    "        temp_frontoparietal_sub_grad_loadings = []\n",
    "        temp_dmn_sub_grad_loadings = []\n",
    "\n",
    "        # iterating over 400 parcels (of G1 loadings) for given subject\n",
    "        for i in range(len(subject_grad_F[j])):\n",
    "\n",
    "            # append given parcel's mean G1 loading to the corresponding list depending on what network it belongs to   \n",
    "            if yeo7_networks_array_labels[i] == 'visual':\n",
    "                temp_visual_sub_grad_loadings.append(subject_grad_F[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'sensory motor':\n",
    "                temp_sensorimotor_sub_grad_loadings.append(subject_grad_F[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'dorsal attention':\n",
    "                temp_dorsalattention_sub_grad_loadings.append(subject_grad_F[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'ventral attention':\n",
    "                temp_ventralattention_sub_grad_loadings.append(subject_grad_F[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'limbic':\n",
    "                temp_limbic_sub_grad_loadings.append(subject_grad_F[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'fronto parietal':\n",
    "                temp_frontoparietal_sub_grad_loadings.append(subject_grad_F[j][i])\n",
    "\n",
    "            elif yeo7_networks_array_labels[i] == 'DMN':\n",
    "                temp_dmn_sub_grad_loadings.append(subject_grad_F[j][i])\n",
    "\n",
    "\n",
    "            # when last iteration of subject, append all the given subject's temp lists to main list\n",
    "            if i == 399:\n",
    "                visual_sub_grad_loadings_F.append(temp_visual_sub_grad_loadings)\n",
    "                sensorimotor_sub_grad_loadings_F.append(temp_sensorimotor_sub_grad_loadings)\n",
    "                dorsalattention_sub_grad_loadings_F.append(temp_dorsalattention_sub_grad_loadings)\n",
    "                ventralattention_sub_grad_loadings_F.append(temp_ventralattention_sub_grad_loadings)\n",
    "                limbic_sub_grad_loadings_F.append(temp_limbic_sub_grad_loadings)\n",
    "                frontoparietal_sub_grad_loadings_F.append(temp_frontoparietal_sub_grad_loadings)\n",
    "                dmn_sub_grad_loadings_F.append(temp_dmn_sub_grad_loadings)       \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### computing variability in forms of correlation with mean (overall and by sex)\n",
    "\n",
    "    ### overall\n",
    "\n",
    "    # lists that will contain correlation between each subject's gradient loadings per network and mean gradient loadings per network (difference computed using correlation coefficient)\n",
    "    list_corr_coeff_HCP_visual_ind_mean_grad_loadings = []\n",
    "    list_corr_coeff_HCP_sensorimotor_ind_mean_grad_loadings = []\n",
    "    list_corr_coeff_HCP_dorsalattention_ind_mean_grad_loadings = []\n",
    "    list_corr_coeff_HCP_ventralattention_ind_mean_grad_loadings = []\n",
    "    list_corr_coeff_HCP_limbic_ind_mean_grad_loadings = []\n",
    "    list_corr_coeff_HCP_frontoparietal_ind_mean_grad_loadings = []\n",
    "    list_corr_coeff_HCP_dmn_ind_mean_grad_loadings = []\n",
    "\n",
    "    # loop over all paricipants (N)\n",
    "    for i in range(len(subject_grad)):\n",
    "\n",
    "        # computing the differences between the given subject's gradient loadings per network and mean gradient loadings per network using correlation coefficient and appending it to list \n",
    "        list_corr_coeff_HCP_visual_ind_mean_grad_loadings.append(stats.pearsonr(visual_sub_grad_loadings[i], visual_mean_grad_loadings)[0])\n",
    "        list_corr_coeff_HCP_sensorimotor_ind_mean_grad_loadings.append(stats.pearsonr(sensorimotor_sub_grad_loadings[i], sensorimotor_mean_grad_loadings)[0])\n",
    "        list_corr_coeff_HCP_dorsalattention_ind_mean_grad_loadings.append(stats.pearsonr(dorsalattention_sub_grad_loadings[i], dorsalattention_mean_grad_loadings)[0])\n",
    "        list_corr_coeff_HCP_ventralattention_ind_mean_grad_loadings.append(stats.pearsonr(ventralattention_sub_grad_loadings[i], ventralattention_mean_grad_loadings)[0])\n",
    "        list_corr_coeff_HCP_limbic_ind_mean_grad_loadings.append(stats.pearsonr(limbic_sub_grad_loadings[i], limbic_mean_grad_loadings)[0])\n",
    "        list_corr_coeff_HCP_frontoparietal_ind_mean_grad_loadings.append(stats.pearsonr(frontoparietal_sub_grad_loadings[i], frontoparietal_mean_grad_loadings)[0])\n",
    "        list_corr_coeff_HCP_dmn_ind_mean_grad_loadings.append(stats.pearsonr(dmn_sub_grad_loadings[i], dmn_mean_grad_loadings)[0])\n",
    "\n",
    "\n",
    "    ### by sex\n",
    "\n",
    "    ## MALES\n",
    "\n",
    "    # lists that will contain correlation between each subject's gradient loadings per network and mean gradient loadings per netwrok (difference computed using correlation coefficient) in males\n",
    "    list_corr_coeff_HCP_visual_ind_mean_grad_loadings_M = []\n",
    "    list_corr_coeff_HCP_sensorimotor_ind_mean_grad_loadings_M = []\n",
    "    list_corr_coeff_HCP_dorsalattention_ind_mean_grad_loadings_M = []\n",
    "    list_corr_coeff_HCP_ventralattention_ind_mean_grad_loadings_M = []\n",
    "    list_corr_coeff_HCP_limbic_ind_mean_grad_loadings_M = []\n",
    "    list_corr_coeff_HCP_frontoparietal_ind_mean_grad_loadings_M = []\n",
    "    list_corr_coeff_HCP_dmn_ind_mean_grad_loadings_M = []\n",
    "\n",
    "    # loop over all male paricipants \n",
    "    for i in range(len(subject_grad_M)):\n",
    "\n",
    "        # computing the differences between the given male subject's gradient loadings per network and mean gradient loadings per network using correlation coefficient and appending it to list \n",
    "        list_corr_coeff_HCP_visual_ind_mean_grad_loadings_M.append(stats.pearsonr(visual_sub_grad_loadings_M[i], visual_mean_grad_loadings_M)[0])\n",
    "        list_corr_coeff_HCP_sensorimotor_ind_mean_grad_loadings_M.append(stats.pearsonr(sensorimotor_sub_grad_loadings_M[i], sensorimotor_mean_grad_loadings_M)[0])\n",
    "        list_corr_coeff_HCP_dorsalattention_ind_mean_grad_loadings_M.append(stats.pearsonr(dorsalattention_sub_grad_loadings_M[i], dorsalattention_mean_grad_loadings_M)[0])\n",
    "        list_corr_coeff_HCP_ventralattention_ind_mean_grad_loadings_M.append(stats.pearsonr(ventralattention_sub_grad_loadings_M[i], ventralattention_mean_grad_loadings_M)[0])\n",
    "        list_corr_coeff_HCP_limbic_ind_mean_grad_loadings_M.append(stats.pearsonr(limbic_sub_grad_loadings_M[i], limbic_mean_grad_loadings_M)[0])\n",
    "        list_corr_coeff_HCP_frontoparietal_ind_mean_grad_loadings_M.append(stats.pearsonr(frontoparietal_sub_grad_loadings_M[i], frontoparietal_mean_grad_loadings_M)[0])\n",
    "        list_corr_coeff_HCP_dmn_ind_mean_grad_loadings_M.append(stats.pearsonr(dmn_sub_grad_loadings_M[i], dmn_mean_grad_loadings_M)[0])\n",
    "\n",
    "\n",
    "    ## FEMALES\n",
    "\n",
    "    # lists that will contain correlation between each subject's gradient loadings per network and mean gradient loadings per network (difference computed using correlation coefficient) in females\n",
    "    list_corr_coeff_HCP_visual_ind_mean_grad_loadings_F = []\n",
    "    list_corr_coeff_HCP_sensorimotor_ind_mean_grad_loadings_F = []\n",
    "    list_corr_coeff_HCP_dorsalattention_ind_mean_grad_loadings_F = []\n",
    "    list_corr_coeff_HCP_ventralattention_ind_mean_grad_loadings_F = []\n",
    "    list_corr_coeff_HCP_limbic_ind_mean_grad_loadings_F = []\n",
    "    list_corr_coeff_HCP_frontoparietal_ind_mean_grad_loadings_F = []\n",
    "    list_corr_coeff_HCP_dmn_ind_mean_grad_loadings_F = []\n",
    "\n",
    "    # loop over all female paricipants \n",
    "    for i in range(len(subject_grad_F)):\n",
    "\n",
    "        # computing the differences between the given female subject's gradient loadings per network and mean gradient loadings per network using correlation coefficient and appending it to list \n",
    "        list_corr_coeff_HCP_visual_ind_mean_grad_loadings_F.append(stats.pearsonr(visual_sub_grad_loadings_F[i], visual_mean_grad_loadings_F)[0])\n",
    "        list_corr_coeff_HCP_sensorimotor_ind_mean_grad_loadings_F.append(stats.pearsonr(sensorimotor_sub_grad_loadings_F[i], sensorimotor_mean_grad_loadings_F)[0])\n",
    "        list_corr_coeff_HCP_dorsalattention_ind_mean_grad_loadings_F.append(stats.pearsonr(dorsalattention_sub_grad_loadings_F[i], dorsalattention_mean_grad_loadings_F)[0])\n",
    "        list_corr_coeff_HCP_ventralattention_ind_mean_grad_loadings_F.append(stats.pearsonr(ventralattention_sub_grad_loadings_F[i], ventralattention_mean_grad_loadings_F)[0])\n",
    "        list_corr_coeff_HCP_limbic_ind_mean_grad_loadings_F.append(stats.pearsonr(limbic_sub_grad_loadings_F[i], limbic_mean_grad_loadings_F)[0])\n",
    "        list_corr_coeff_HCP_frontoparietal_ind_mean_grad_loadings_F.append(stats.pearsonr(frontoparietal_sub_grad_loadings_F[i], frontoparietal_mean_grad_loadings_F)[0])\n",
    "        list_corr_coeff_HCP_dmn_ind_mean_grad_loadings_F.append(stats.pearsonr(dmn_sub_grad_loadings_F[i], dmn_mean_grad_loadings_F)[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### transform / store data to make it plottable\n",
    "    dict_ind_var_network_bysex = {'sex': ['M'] * len(subject_grad_M) + ['F'] * len(subject_grad_F), 'r_visual': list_corr_coeff_HCP_visual_ind_mean_grad_loadings_M + list_corr_coeff_HCP_visual_ind_mean_grad_loadings_F, 'r_sensorimotor': list_corr_coeff_HCP_sensorimotor_ind_mean_grad_loadings_M + list_corr_coeff_HCP_sensorimotor_ind_mean_grad_loadings_F, 'r_dorsalattention': list_corr_coeff_HCP_dorsalattention_ind_mean_grad_loadings_M + list_corr_coeff_HCP_dorsalattention_ind_mean_grad_loadings_F, 'r_ventralattention': list_corr_coeff_HCP_ventralattention_ind_mean_grad_loadings_M + list_corr_coeff_HCP_ventralattention_ind_mean_grad_loadings_F, 'r_limbic' : list_corr_coeff_HCP_limbic_ind_mean_grad_loadings_M + list_corr_coeff_HCP_limbic_ind_mean_grad_loadings_F, 'r_frontoparietal': list_corr_coeff_HCP_frontoparietal_ind_mean_grad_loadings_M + list_corr_coeff_HCP_frontoparietal_ind_mean_grad_loadings_F, 'r_dmn': list_corr_coeff_HCP_dmn_ind_mean_grad_loadings_M + list_corr_coeff_HCP_dmn_ind_mean_grad_loadings_F}\n",
    "\n",
    "    df_ind_var_network_bysex = pd.DataFrame(dict_ind_var_network_bysex)\n",
    "\n",
    "    df_ind_var_network_bysex_long = pd.melt(df_ind_var_network_bysex, id_vars=['sex'], value_vars=['r_visual', 'r_sensorimotor', 'r_dorsalattention', 'r_ventralattention', 'r_limbic', 'r_frontoparietal', 'r_dmn'], var_name='network', value_name='corr_coef')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### Plot\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20,10));\n",
    "    \n",
    "    colors = {'F':'firebrick', 'M':'royalblue'}\n",
    "\n",
    "    ax = sns.boxplot(data=df_ind_var_network_bysex_long, x='network', y='corr_coef', hue = 'sex', \n",
    "                palette=colors, \n",
    "                fliersize = 2)\n",
    "\n",
    "    ax.set_xlabel('network', fontsize=25);\n",
    "    ax.set_ylabel('correlation coefficient', fontsize=25);\n",
    "    ax.tick_params(labelsize=25);\n",
    "\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"center\")\n",
    "    ax.legend(fontsize=20, bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3c28e7d-5df9-42a3-ae50-bdc1df94611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variability_network_std(subject_grad_M, subject_grad_F):\n",
    "    \n",
    "    '''\n",
    "    Function computing variability (mean standard deviation) across parcels belonging to same network\n",
    "    \n",
    "    Input variables: \n",
    "    - subject_grad_M: aligned gradient loadings of male subjects - shape array: number of subjects x number of parcels\n",
    "    - subject_grad_F: aligned gradient loadings of female subjects - shape array: number of subjects x number of parcels\n",
    "    \n",
    "    Output:\n",
    "    - bar plot of mean std by network color-coded by sex\n",
    "    \n",
    "    '''\n",
    "     \n",
    "    ### STD computation and arrangement per network\n",
    "    \n",
    "    # Compute std per parcel, across all subjects, and for males and females separately\n",
    "    std_grad_M = np.std(subject_grad_M, axis=0)\n",
    "    std_grad_F = np.std(subject_grad_F, axis=0)\n",
    "    \n",
    "    \n",
    "    # lists that will contain std per sex per network\n",
    "    visual_std_grad_M = []\n",
    "    sensorimotor_std_grad_M = []\n",
    "    dorsalattention_std_grad_M = []\n",
    "    ventralattention_std_grad_M = []\n",
    "    limbic_std_grad_M = []\n",
    "    frontoparietal_std_grad_M = []\n",
    "    dmn_std_grad_M = []\n",
    "\n",
    "    visual_std_grad_F = []\n",
    "    sensorimotor_std_grad_F = []\n",
    "    dorsalattention_std_grad_F = []\n",
    "    ventralattention_std_grad_F = []\n",
    "    limbic_std_grad_F = []\n",
    "    frontoparietal_std_grad_F = []\n",
    "    dmn_std_grad_F = []\n",
    "\n",
    "    # iterating over 400 parcels (of std) \n",
    "    for i in range(len(std_grad_M)):\n",
    "\n",
    "        # append given parcel's std gradient loading to the corresponding list depending on what network it belongs to (and by sex)\n",
    "        if yeo7_networks_array_labels[i] == 'visual':\n",
    "            visual_std_grad_M.append(std_grad_M[i])\n",
    "            visual_std_grad_F.append(std_grad_F[i])\n",
    "\n",
    "        elif yeo7_networks_array_labels[i] == 'sensory motor':\n",
    "            sensorimotor_std_grad_M.append(std_grad_M[i])\n",
    "            sensorimotor_std_grad_F.append(std_grad_F[i])\n",
    "\n",
    "        elif yeo7_networks_array_labels[i] == 'dorsal attention':\n",
    "            dorsalattention_std_grad_M.append(std_grad_M[i])\n",
    "            dorsalattention_std_grad_F.append(std_grad_F[i])\n",
    "\n",
    "        elif yeo7_networks_array_labels[i] == 'ventral attention':\n",
    "            ventralattention_std_grad_M.append(std_grad_M[i])\n",
    "            ventralattention_std_grad_F.append(std_grad_F[i])\n",
    "\n",
    "        elif yeo7_networks_array_labels[i] == 'limbic':\n",
    "            limbic_std_grad_M.append(std_grad_M[i])\n",
    "            limbic_std_grad_F.append(std_grad_F[i])\n",
    "\n",
    "        elif yeo7_networks_array_labels[i] == 'fronto parietal':\n",
    "            frontoparietal_std_grad_M.append(std_grad_M[i])\n",
    "            frontoparietal_std_grad_F.append(std_grad_F[i])\n",
    "\n",
    "        elif yeo7_networks_array_labels[i] == 'DMN':\n",
    "            dmn_std_grad_M.append(std_grad_M[i])\n",
    "            dmn_std_grad_F.append(std_grad_F[i])\n",
    "\n",
    "\n",
    "\n",
    "    ### Shape data for plotting mean std by network by sex\n",
    "\n",
    "    dict_mean_std_network_bysex = {'sex': ['M','F'], 'visual': [statistics.mean(visual_std_grad_M), statistics.mean(visual_std_grad_F)], 'sensorimotor': [statistics.mean(sensorimotor_std_grad_M), statistics.mean(sensorimotor_std_grad_F)], 'dorsal attention': [statistics.mean(dorsalattention_std_grad_M), statistics.mean(dorsalattention_std_grad_F)], 'ventral attention': [statistics.mean(ventralattention_std_grad_M), statistics.mean(ventralattention_std_grad_F)], 'limbic': [statistics.mean(limbic_std_grad_M), statistics.mean(limbic_std_grad_F)], 'fronto parietal': [statistics.mean(frontoparietal_std_grad_M), statistics.mean(frontoparietal_std_grad_F)], 'DMN': [statistics.mean(dmn_std_grad_M), statistics.mean(dmn_std_grad_F)]}\n",
    "\n",
    "    df_mean_std_network_bysex = pd.DataFrame(dict_mean_std_network_bysex)\n",
    "\n",
    "    df_mean_std_network_bysex_long = pd.melt(df_mean_std_network_bysex, id_vars=['sex'], value_vars=['visual', 'sensorimotor', 'dorsal attention', 'ventral attention', 'limbic', 'fronto parietal', 'DMN'], var_name='network', value_name='mean sd')\n",
    "\n",
    "\n",
    "\n",
    "    ### Plot \n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20,10));\n",
    "    \n",
    "    colors = {'F':'firebrick', 'M':'royalblue'}\n",
    "\n",
    "    ax = sns.barplot(data=df_mean_std_network_bysex_long, x='network', y='mean sd', hue='sex', palette=colors)\n",
    "\n",
    "\n",
    "    ax.set_xlabel('network', fontsize=25);\n",
    "    ax.set_ylabel('mean SD', fontsize=25);\n",
    "    ax.tick_params(labelsize=25);\n",
    "\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"center\")\n",
    "    ax.legend(fontsize=20, bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54cb629f-a1a5-4784-8589-5baf6892d986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variability_parcel_std_spotlight_network(subject_grad_M, subject_grad_F, output_dir = None):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Function that computes variability at the parcel level as done by function variability_parcel_std (visualizing standard deviation by parcels in both sexes separately, as well as difference scores (STD M - STD F) but displays by network (masking all but one network -> spotlight approach)\n",
    "\n",
    "    Input variables:\n",
    "    - subject_grad_M: aligned gradient loadings of male subjects - shape array: number of subjects x number of parcels\n",
    "    - subject_grad_F: aligned gradient loadings of female subjects - shape array: number of subjects x number of parcels\n",
    "    - output_dir: path to output directory (e.g. resdir_fig, i.e. '/data/p_02667/sex_diff_gradients/results/figures/')\n",
    "    \n",
    "    Output:\n",
    "    - plotted hemispheres -> spotlight approach (per network, masking parcels belonging to other networks): STD males, STD females, difference STD for q sig    \n",
    "    \n",
    "    '''\n",
    "\n",
    "    ### computing the same as function variability_parcel_std\n",
    "    \n",
    "    ## Compute std per parcel, across all subjects, and for males and females separately\n",
    "    std_grad_M = np.std(subject_grad_M, axis=0)\n",
    "    std_grad_F = np.std(subject_grad_F, axis=0)\n",
    "    \n",
    "    \n",
    "    ## Compute the difference between males and female std (where positive scores show greater male variability)\n",
    "    std_grad_sexdiff = std_grad_M - std_grad_F\n",
    "\n",
    "\n",
    "    ## Significance testing of the differences\n",
    "\n",
    "    # list that will contain the p values of the Levene's test for homogeneity of variance (per parcel) -> p < 0.05 mean NOT homogeneous variance, meaning that we can interpret the variability (as provided by difference of STD) as statistically significant\n",
    "    p_val_levene_grad_male_vs_female = []\n",
    "\n",
    "    # loop over 400 parcels\n",
    "    for i in range(len(subject_grad_M.T)):\n",
    "\n",
    "        # test for homogeneity of variance within this parcel (between males and females) - [1] indexes the p-value -> append p-value to list\n",
    "        p_val_levene_grad_male_vs_female.append(stats.levene(subject_grad_M.T[i], subject_grad_F.T[i])[1])\n",
    "\n",
    "    p_val_levene_grad_male_vs_female = np.array(p_val_levene_grad_male_vs_female)\n",
    "\n",
    "\n",
    "    ## compute the FDR-corrected q values of G1 sex differences in variance as given from Levene's test pvalues\n",
    "    fdr_corr_p_val_levene_grad_male_vs_female = fdrcorrection(p_val_levene_grad_male_vs_female)[1]\n",
    "    \n",
    "    \n",
    "    ## list that will contain difference score (M - F) of STD only for parcels who show statistical inhomogeneity of variance (i.e., Levene's test: p < 0.05) AFTER FDR correction (so where q < 0.05)\n",
    "    std_grad_fdr_corr_levene_sig_sexdiff = []\n",
    "\n",
    "    for i in range(400):\n",
    "        if fdr_corr_p_val_levene_grad_male_vs_female[i] <= 0.05:\n",
    "            std_grad_fdr_corr_levene_sig_sexdiff.append(std_grad_sexdiff[i])\n",
    "        else:\n",
    "            std_grad_fdr_corr_levene_sig_sexdiff.append(float('nan'))\n",
    "\n",
    "    std_grad_fdr_corr_levene_sig_sexdiff = np.array(std_grad_fdr_corr_levene_sig_sexdiff)\n",
    "\n",
    "    \n",
    "    \n",
    "    ## Find min and max std across sexes (this is for plotting the color bar in the plotted hemispheres)\n",
    "\n",
    "    if min(std_grad_M) < min(std_grad_F):\n",
    "        min_std = min(std_grad_M)\n",
    "    else:\n",
    "        min_std = min(std_grad_F)\n",
    "\n",
    "    print(f\"\\nMinimum SD: Males = {round(min(std_grad_M), 3)}; Females = {round(min(std_grad_F), 3)}\")\n",
    "\n",
    "\n",
    "    if max(std_grad_M) > max(std_grad_F):\n",
    "        max_std = max(std_grad_M)\n",
    "    else:\n",
    "        max_std = max(std_grad_F)\n",
    "\n",
    "    print(f\"Maximum SD: Males = {round(max(std_grad_M), 3)}; Females = {round(max(std_grad_F), 3)}\")\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    ### Making lists by network\n",
    "    \n",
    "    # lists that will contain the std gradient per sex values for a given network and nans in parcels that do not belong to that network\n",
    "    visual_std_grad_to_plot_M = []\n",
    "    sensorimotor_std_grad_to_plot_M = []\n",
    "    dorsalattention_std_grad_to_plot_M = []\n",
    "    ventralattention_std_grad_to_plot_M = []\n",
    "    limbic_std_grad_to_plot_M = []\n",
    "    frontoparietal_std_grad_to_plot_M = []\n",
    "    dmn_std_grad_to_plot_M = []\n",
    "\n",
    "    visual_std_grad_to_plot_F = []\n",
    "    sensorimotor_std_grad_to_plot_F = []\n",
    "    dorsalattention_std_grad_to_plot_F = []\n",
    "    ventralattention_std_grad_to_plot_F = []\n",
    "    limbic_std_grad_to_plot_F = []\n",
    "    frontoparietal_std_grad_to_plot_F = []\n",
    "    dmn_std_grad_to_plot_F = []\n",
    "\n",
    "    # lists that will contain the difference score (M - F) of STD only for parcels who show statistical inhomogeneity of variance (i.e., Levene's test: p < 0.05)\n",
    "    visual_std_grad_fdr_corr_levene_sig_sexdiff_to_plot = []\n",
    "    sensorimotor_std_grad_fdr_corr_levene_sig_sexdiff_to_plot = []\n",
    "    dorsalattention_std_grad_fdr_corr_levene_sig_sexdiff_to_plot = []\n",
    "    ventralattention_std_grad_fdr_corr_levene_sig_sexdiff_to_plot = []\n",
    "    limbic_std_grad_fdr_corr_levene_sig_sexdiff_to_plot = []\n",
    "    frontoparietal_std_grad_fdr_corr_levene_sig_sexdiff_to_plot = []\n",
    "    dmn_std_grad_fdr_corr_levene_sig_sexdiff_to_plot = []\n",
    "\n",
    "\n",
    "\n",
    "    # loop over 400 parcels and each time if parcel corresponds to a given yeo network, append the std value of that parcel for males and females, else append nan\n",
    "\n",
    "    for i in range(len(yeo7_networks_array_labels)):\n",
    "        if yeo7_networks_array_labels[i] == 'visual':\n",
    "            visual_std_grad_to_plot_M.append(std_grad_M[i])\n",
    "            visual_std_grad_to_plot_F.append(std_grad_F[i])\n",
    "            visual_std_grad_fdr_corr_levene_sig_sexdiff_to_plot.append(std_grad_fdr_corr_levene_sig_sexdiff[i])\n",
    "        else:\n",
    "            visual_std_grad_to_plot_M.append(float('nan'))\n",
    "            visual_std_grad_to_plot_F.append(float('nan'))\n",
    "            visual_std_grad_fdr_corr_levene_sig_sexdiff_to_plot.append(float('nan'))\n",
    "\n",
    "    for i in range(len(yeo7_networks_array_labels)):\n",
    "        if yeo7_networks_array_labels[i] == 'sensory motor':\n",
    "            sensorimotor_std_grad_to_plot_M.append(std_grad_M[i])\n",
    "            sensorimotor_std_grad_to_plot_F.append(std_grad_F[i])\n",
    "            sensorimotor_std_grad_fdr_corr_levene_sig_sexdiff_to_plot.append(std_grad_fdr_corr_levene_sig_sexdiff[i])\n",
    "        else:\n",
    "            sensorimotor_std_grad_to_plot_M.append(float('nan'))\n",
    "            sensorimotor_std_grad_to_plot_F.append(float('nan'))\n",
    "            sensorimotor_std_grad_fdr_corr_levene_sig_sexdiff_to_plot.append(float('nan'))\n",
    "\n",
    "    for i in range(len(yeo7_networks_array_labels)):\n",
    "        if yeo7_networks_array_labels[i] == 'dorsal attention':\n",
    "\n",
    "            dorsalattention_std_grad_to_plot_M.append(std_grad_M[i])\n",
    "            dorsalattention_std_grad_to_plot_F.append(std_grad_F[i])\n",
    "            dorsalattention_std_grad_fdr_corr_levene_sig_sexdiff_to_plot.append(std_grad_fdr_corr_levene_sig_sexdiff[i])\n",
    "        else:\n",
    "            dorsalattention_std_grad_to_plot_M.append(float('nan'))\n",
    "            dorsalattention_std_grad_to_plot_F.append(float('nan'))\n",
    "            dorsalattention_std_grad_fdr_corr_levene_sig_sexdiff_to_plot.append(float('nan'))\n",
    "\n",
    "    for i in range(len(yeo7_networks_array_labels)):\n",
    "        if yeo7_networks_array_labels[i] == 'ventral attention':\n",
    "            ventralattention_std_grad_to_plot_M.append(std_grad_M[i])\n",
    "            ventralattention_std_grad_to_plot_F.append(std_grad_F[i])\n",
    "            ventralattention_std_grad_fdr_corr_levene_sig_sexdiff_to_plot.append(std_grad_fdr_corr_levene_sig_sexdiff[i])\n",
    "        else:\n",
    "            ventralattention_std_grad_to_plot_M.append(float('nan'))\n",
    "            ventralattention_std_grad_to_plot_F.append(float('nan'))\n",
    "            ventralattention_std_grad_fdr_corr_levene_sig_sexdiff_to_plot.append(float('nan'))\n",
    "\n",
    "    for i in range(len(yeo7_networks_array_labels)):\n",
    "        if yeo7_networks_array_labels[i] == 'limbic':\n",
    "            limbic_std_grad_to_plot_M.append(std_grad_M[i])\n",
    "            limbic_std_grad_to_plot_F.append(std_grad_F[i])\n",
    "            limbic_std_grad_fdr_corr_levene_sig_sexdiff_to_plot.append(std_grad_fdr_corr_levene_sig_sexdiff[i])\n",
    "        else:\n",
    "            limbic_std_grad_to_plot_M.append(float('nan'))\n",
    "            limbic_std_grad_to_plot_F.append(float('nan'))\n",
    "            limbic_std_grad_fdr_corr_levene_sig_sexdiff_to_plot.append(float('nan'))\n",
    "\n",
    "    for i in range(len(yeo7_networks_array_labels)):\n",
    "        if yeo7_networks_array_labels[i] == 'fronto parietal':\n",
    "            frontoparietal_std_grad_to_plot_M.append(std_grad_M[i])\n",
    "            frontoparietal_std_grad_to_plot_F.append(std_grad_F[i])\n",
    "            frontoparietal_std_grad_fdr_corr_levene_sig_sexdiff_to_plot.append(std_grad_fdr_corr_levene_sig_sexdiff[i])\n",
    "        else:\n",
    "            frontoparietal_std_grad_to_plot_M.append(float('nan'))\n",
    "            frontoparietal_std_grad_to_plot_F.append(float('nan'))\n",
    "            frontoparietal_std_grad_fdr_corr_levene_sig_sexdiff_to_plot.append(float('nan'))\n",
    "\n",
    "    for i in range(len(yeo7_networks_array_labels)):\n",
    "        if yeo7_networks_array_labels[i] == 'DMN':\n",
    "            dmn_std_grad_to_plot_M.append(std_grad_M[i])\n",
    "            dmn_std_grad_to_plot_F.append(std_grad_F[i])\n",
    "            dmn_std_grad_fdr_corr_levene_sig_sexdiff_to_plot.append(std_grad_fdr_corr_levene_sig_sexdiff[i])\n",
    "        else:\n",
    "            dmn_std_grad_to_plot_M.append(float('nan'))\n",
    "            dmn_std_grad_to_plot_F.append(float('nan'))\n",
    "            dmn_std_grad_fdr_corr_levene_sig_sexdiff_to_plot.append(float('nan'))\n",
    "\n",
    "\n",
    "    # make lists as array (required for plotting hemispheres)\n",
    "    visual_std_grad_to_plot_M = np.array(visual_std_grad_to_plot_M)\n",
    "    sensorimotor_std_grad_to_plot_M = np.array(sensorimotor_std_grad_to_plot_M)\n",
    "    dorsalattention_std_grad_to_plot_M = np.array(dorsalattention_std_grad_to_plot_M)\n",
    "    ventralattention_std_grad_to_plot_M = np.array(ventralattention_std_grad_to_plot_M)\n",
    "    limbic_std_grad_to_plot_M = np.array(limbic_std_grad_to_plot_M)\n",
    "    frontoparietal_std_grad_to_plot_M = np.array(frontoparietal_std_grad_to_plot_M)\n",
    "    dmn_std_grad_to_plot_M = np.array(dmn_std_grad_to_plot_M)\n",
    "\n",
    "    visual_std_grad_to_plot_F = np.array(visual_std_grad_to_plot_F)\n",
    "    sensorimotor_std_grad_to_plot_F = np.array(sensorimotor_std_grad_to_plot_F)\n",
    "    dorsalattention_std_grad_to_plot_F = np.array(dorsalattention_std_grad_to_plot_F)\n",
    "    ventralattention_std_grad_to_plot_F = np.array(ventralattention_std_grad_to_plot_F)\n",
    "    limbic_std_grad_to_plot_F = np.array(limbic_std_grad_to_plot_F)\n",
    "    frontoparietal_std_grad_to_plot_F = np.array(frontoparietal_std_grad_to_plot_F)\n",
    "    dmn_std_grad_to_plot_F = np.array(dmn_std_grad_to_plot_F)\n",
    "\n",
    "    visual_std_grad_fdr_corr_levene_sig_sexdiff_to_plot = np.array(visual_std_grad_fdr_corr_levene_sig_sexdiff_to_plot)\n",
    "    sensorimotor_std_grad_fdr_corr_levene_sig_sexdiff_to_plot = np.array(sensorimotor_std_grad_fdr_corr_levene_sig_sexdiff_to_plot)\n",
    "    dorsalattention_std_grad_fdr_corr_levene_sig_sexdiff_to_plot = np.array(dorsalattention_std_grad_fdr_corr_levene_sig_sexdiff_to_plot)\n",
    "    ventralattention_std_grad_fdr_corr_levene_sig_sexdiff_to_plot = np.array(ventralattention_std_grad_fdr_corr_levene_sig_sexdiff_to_plot)\n",
    "    limbic_std_grad_fdr_corr_levene_sig_sexdiff_to_plot = np.array(limbic_std_grad_fdr_corr_levene_sig_sexdiff_to_plot)\n",
    "    frontoparietal_std_grad_fdr_corr_levene_sig_sexdiff_to_plot = np.array(frontoparietal_std_grad_fdr_corr_levene_sig_sexdiff_to_plot)\n",
    "    dmn_std_grad_fdr_corr_levene_sig_sexdiff_to_plot = np.array(dmn_std_grad_fdr_corr_levene_sig_sexdiff_to_plot)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### plot the standard deviations by network on hemispheres\n",
    "\n",
    "    # defining labeling scheme and mask\n",
    "    labeling = load_parcellation('schaefer', scale=400, join=True)\n",
    "    surf_lh, surf_rh = load_conte69()\n",
    "\n",
    "    mask = labeling != 0\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    ### MALES\n",
    "\n",
    "    # will contain the different plots for males\n",
    "    handles_M = []\n",
    "\n",
    "    # visual\n",
    "    visual_std_to_labels_M = map_to_labels(visual_std_grad_to_plot_M, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    visual_plotted_hemispheres_M_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=visual_std_to_labels_M, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['visual'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = output_dir+'HCP_fc'+'_plotted_hemispheres_std_visual_M.png')\n",
    "\n",
    "    handles_M.append(visual_plotted_hemispheres_M_std)\n",
    "\n",
    "\n",
    "    # sensorimotor\n",
    "    sensorimotor_std_to_labels_M = map_to_labels(sensorimotor_std_grad_to_plot_M, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    sensorimotor_plotted_hemispheres_M_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=sensorimotor_std_to_labels_M, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['sensorimotor'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = output_dir+'HCP_fc'+'_plotted_hemispheres_std_sensorimotor_M.png')\n",
    "\n",
    "    handles_M.append(sensorimotor_plotted_hemispheres_M_std)\n",
    "\n",
    "\n",
    "    # dorsal attention\n",
    "    dorsalattention_std_to_labels_M = map_to_labels(dorsalattention_std_grad_to_plot_M, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    dorsalattention_plotted_hemispheres_M_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=dorsalattention_std_to_labels_M, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['dorsal attention'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = output_dir+'HCP_fc'+'_plotted_hemispheres_std_dorsalattention_M.png')\n",
    "\n",
    "    handles_M.append(dorsalattention_plotted_hemispheres_M_std)\n",
    "\n",
    "\n",
    "    # ventral attention\n",
    "    ventralattention_std_to_labels_M = map_to_labels(ventralattention_std_grad_to_plot_M, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    ventralattention_plotted_hemispheres_M_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=ventralattention_std_to_labels_M, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['ventral attention'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = output_dir+'HCP_fc'+'_plotted_hemispheres_std_ventralattention_M.png')\n",
    "\n",
    "    handles_M.append(ventralattention_plotted_hemispheres_M_std)\n",
    "\n",
    "\n",
    "    # limbic\n",
    "    limbic_std_to_labels_M = map_to_labels(limbic_std_grad_to_plot_M, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    limbic_plotted_hemispheres_M_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=limbic_std_to_labels_M, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['limbic'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = output_dir+'HCP_fc'+'_plotted_hemispheres_std_limbic_M.png')\n",
    "\n",
    "    handles_M.append(limbic_plotted_hemispheres_M_std)\n",
    "\n",
    "\n",
    "    # fronto parietal\n",
    "    frontoparietal_std_to_labels_M = map_to_labels(frontoparietal_std_grad_to_plot_M, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    frontoparietal_plotted_hemispheres_M_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=frontoparietal_std_to_labels_M, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['frontoparietal'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = output_dir+'HCP_fc'+'_plotted_hemispheres_std_frontoparietal_M.png')\n",
    "\n",
    "    handles_M.append(frontoparietal_plotted_hemispheres_M_std)\n",
    "\n",
    "\n",
    "    # DMN\n",
    "    dmn_std_to_labels_M = map_to_labels(dmn_std_grad_to_plot_M, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    dmn_plotted_hemispheres_M_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=dmn_std_to_labels_M, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['DMN'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = output_dir+'HCP_fc'+'_plotted_hemispheres_std_dmn_M.png')\n",
    "\n",
    "    handles_M.append(dmn_plotted_hemispheres_M_std)\n",
    "\n",
    "\n",
    "    print('Males')\n",
    "    display(*handles_M)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    ### FEMALES\n",
    "\n",
    "    # will contain the different plots for females\n",
    "    handles_F = []\n",
    "\n",
    "    # visual\n",
    "    visual_std_to_labels_F = map_to_labels(visual_std_grad_to_plot_F, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    visual_plotted_hemispheres_F_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=visual_std_to_labels_F, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['visual'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = output_dir+'HCP_fc'+'_plotted_hemispheres_std_visual_F.png')\n",
    "\n",
    "    handles_F.append(visual_plotted_hemispheres_F_std)\n",
    "\n",
    "\n",
    "    # sensorimotor\n",
    "    sensorimotor_std_to_labels_F = map_to_labels(sensorimotor_std_grad_to_plot_F, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    sensorimotor_plotted_hemispheres_F_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=sensorimotor_std_to_labels_F, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['sensorimotor'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = output_dir+'HCP_fc'+'_plotted_hemispheres_std_sensorimotor_F.png')\n",
    "\n",
    "    handles_F.append(sensorimotor_plotted_hemispheres_F_std)\n",
    "\n",
    "\n",
    "    # dorsal attention\n",
    "    dorsalattention_std_to_labels_F = map_to_labels(dorsalattention_std_grad_to_plot_F, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    dorsalattention_plotted_hemispheres_F_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=dorsalattention_std_to_labels_F, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['dorsal attention'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = output_dir+'HCP_fc'+'_plotted_hemispheres_std_dorsalattention_F.png')\n",
    "\n",
    "    handles_F.append(dorsalattention_plotted_hemispheres_F_std)\n",
    "\n",
    "\n",
    "    # ventral attention\n",
    "    ventralattention_std_to_labels_F = map_to_labels(ventralattention_std_grad_to_plot_F, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    ventralattention_plotted_hemispheres_F_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=ventralattention_std_to_labels_F, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['ventral attention'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = output_dir+'HCP_fc'+'_plotted_hemispheres_std_ventralattention_F.png')\n",
    "\n",
    "    handles_F.append(ventralattention_plotted_hemispheres_F_std)\n",
    "\n",
    "\n",
    "    # limbic\n",
    "    limbic_std_to_labels_F = map_to_labels(limbic_std_grad_to_plot_F, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    limbic_plotted_hemispheres_F_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=limbic_std_to_labels_F, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['limbic'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = output_dir+'HCP_fc'+'_plotted_hemispheres_std_limbic_F.png')\n",
    "\n",
    "    handles_F.append(limbic_plotted_hemispheres_F_std)\n",
    "\n",
    "\n",
    "    # fronto parietal\n",
    "    frontoparietal_std_to_labels_F = map_to_labels(frontoparietal_std_grad_to_plot_F, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    frontoparietal_plotted_hemispheres_F_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=frontoparietal_std_to_labels_F, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['frontoparietal'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = output_dir+'HCP_fc'+'_plotted_hemispheres_std_frontoparietal_F.png')\n",
    "\n",
    "    handles_F.append(frontoparietal_plotted_hemispheres_F_std)\n",
    "\n",
    "\n",
    "    # DMN\n",
    "    dmn_std_to_labels_F = map_to_labels(dmn_std_grad_to_plot_F, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    dmn_plotted_hemispheres_F_std = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=dmn_std_to_labels_F, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 color_range = (min_std, max_std),\n",
    "                                                 cmap='YlGn', \n",
    "                                                 color_bar=True, \n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['DMN'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = output_dir+'HCP_fc'+'_plotted_hemispheres_std_dmn_F.png')\n",
    "\n",
    "    handles_F.append(dmn_plotted_hemispheres_F_std)\n",
    "\n",
    "\n",
    "    print('Females')\n",
    "    display(*handles_F)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    ### DIFFERENCE SCORE (M - F) of STD only for parcels who show statistical inhomogeneity of variance (i.e., Levene's test: p < 0.05)\n",
    "\n",
    "    # will contain the different plots \n",
    "    handles = []\n",
    "\n",
    "    # visual\n",
    "    visual_std_grad_fdr_corr_levene_sig_sexdiff_to_labels = map_to_labels(visual_std_grad_fdr_corr_levene_sig_sexdiff_to_plot, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    visual_std_grad_fdr_corr_levene_sig_sexdiff_plotted_hemispheres = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=visual_std_grad_fdr_corr_levene_sig_sexdiff_to_labels, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 cmap='bwr_r', \n",
    "                                                 color_bar=True, \n",
    "                                                 color_range='sym',\n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['visual'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = output_dir+'HCP_fc'+'_plotted_hemispheres_std_visual_F.png')\n",
    "\n",
    "    handles.append(visual_std_grad_fdr_corr_levene_sig_sexdiff_plotted_hemispheres)\n",
    "\n",
    "\n",
    "    # sensorimotor\n",
    "    sensorimotor_std_grad_fdr_corr_levene_sig_sexdiff_to_labels = map_to_labels(sensorimotor_std_grad_fdr_corr_levene_sig_sexdiff_to_plot, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    sensorimotor_std_grad_fdr_corr_levene_sig_sexdiff_plotted_hemispheres = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=sensorimotor_std_grad_fdr_corr_levene_sig_sexdiff_to_labels, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 cmap='bwr_r', \n",
    "                                                 color_bar=True, \n",
    "                                                 color_range='sym',\n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['sensorimotor'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = output_dir+'HCP_fc'+'_plotted_hemispheres_std_sensorimotor_F.png')\n",
    "\n",
    "    handles.append(sensorimotor_std_grad_fdr_corr_levene_sig_sexdiff_plotted_hemispheres)\n",
    "\n",
    "\n",
    "    # dorsal attention\n",
    "    dorsalattention_std_grad_fdr_corr_levene_sig_sexdiff_to_labels = map_to_labels(dorsalattention_std_grad_fdr_corr_levene_sig_sexdiff_to_plot, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    dorsalattention_std_grad_fdr_corr_levene_sig_sexdiff_plotted_hemispheres = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=dorsalattention_std_grad_fdr_corr_levene_sig_sexdiff_to_labels, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 cmap='bwr_r', \n",
    "                                                 color_bar=True,\n",
    "                                                 color_range='sym',\n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['dorsal attention'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = output_dir+'HCP_fc'+'_plotted_hemispheres_std_dorsalattention_F.png')\n",
    "\n",
    "    handles.append(dorsalattention_std_grad_fdr_corr_levene_sig_sexdiff_plotted_hemispheres)\n",
    "\n",
    "\n",
    "    # ventral attention\n",
    "    ventralattention_std_grad_fdr_corr_levene_sig_sexdiff_to_labels = map_to_labels(ventralattention_std_grad_fdr_corr_levene_sig_sexdiff_to_plot, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    ventralattention_std_grad_fdr_corr_levene_sig_sexdiff_plotted_hemispheres = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=ventralattention_std_grad_fdr_corr_levene_sig_sexdiff_to_labels, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 cmap='bwr_r', \n",
    "                                                 color_bar=True,\n",
    "                                                 color_range='sym',\n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['ventral attention'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = output_dir+'HCP_fc'+'_plotted_hemispheres_std_ventralattention_F.png')\n",
    "\n",
    "    handles.append(ventralattention_std_grad_fdr_corr_levene_sig_sexdiff_plotted_hemispheres)\n",
    "\n",
    "\n",
    "    # limbic\n",
    "    limbic_std_grad_fdr_corr_levene_sig_sexdiff_to_labels = map_to_labels(limbic_std_grad_fdr_corr_levene_sig_sexdiff_to_plot, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    limbic_std_grad_fdr_corr_levene_sig_sexdiff_plotted_hemispheres = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=limbic_std_grad_fdr_corr_levene_sig_sexdiff_to_labels, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 cmap='bwr_r', \n",
    "                                                 color_bar=True, \n",
    "                                                 color_range='sym',\n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['limbic'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = output_dir+'HCP_fc'+'_plotted_hemispheres_std_limbic_F.png')\n",
    "\n",
    "    handles.append(limbic_std_grad_fdr_corr_levene_sig_sexdiff_plotted_hemispheres)\n",
    "\n",
    "\n",
    "    # fronto parietal\n",
    "    frontoparietal_std_grad_fdr_corr_levene_sig_sexdiff_to_labels = map_to_labels(frontoparietal_std_grad_fdr_corr_levene_sig_sexdiff_to_plot, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    frontoparietal_std_grad_fdr_corr_levene_sig_sexdiff_plotted_hemispheres = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=frontoparietal_std_grad_fdr_corr_levene_sig_sexdiff_to_labels, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 cmap='bwr_r', \n",
    "                                                 color_bar=True, \n",
    "                                                 color_range='sym',\n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['frontoparietal'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = output_dir+'HCP_fc'+'_plotted_hemispheres_std_frontoparietal_F.png')\n",
    "\n",
    "    handles.append(frontoparietal_std_grad_fdr_corr_levene_sig_sexdiff_plotted_hemispheres)\n",
    "\n",
    "\n",
    "    # DMN\n",
    "    dmn_std_grad_fdr_corr_levene_sig_sexdiff_to_labels = map_to_labels(dmn_std_grad_fdr_corr_levene_sig_sexdiff_to_plot, labeling, mask=mask, fill=np.nan)  \n",
    "\n",
    "    dmn_std_grad_fdr_corr_levene_sig_sexdiff_plotted_hemispheres = plot_hemispheres(surf_lh, \n",
    "                                                 surf_rh, \n",
    "                                                 array_name=dmn_std_grad_fdr_corr_levene_sig_sexdiff_to_labels, \n",
    "                                                 embed_nb = True, \n",
    "                                                 size=(1200, 200), \n",
    "                                                 cmap='bwr_r', \n",
    "                                                 color_bar=True, \n",
    "                                                 color_range='sym',\n",
    "                                                 nan_color = (0.7, 0.7, 0.7, 1),\n",
    "                                                 label_text=['DMN'], \n",
    "                                                 zoom=1.55,\n",
    "                                                 screenshot = False,\n",
    "                                                 filename = output_dir+'HCP_fc'+'_plotted_hemispheres_std_dmn_F.png')\n",
    "\n",
    "    handles.append(dmn_std_grad_fdr_corr_levene_sig_sexdiff_plotted_hemispheres)\n",
    "\n",
    "\n",
    "    print(\"difference score (M - F) of STD only for parcels who show statistical inhomogeneity of variance (i.e., Levene's test: p < 0.05)\")\n",
    "    display(*handles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0256814-2346-4faf-8eee-32e5ffb7d247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def schaefer400_to_fs5(schaefer400_data, seven_networks=True):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Function that transforms data in Schaefer 400 (7 or 17 networks) space to fsaverage5 space\n",
    "    \n",
    "    Input:\n",
    "    - data in Schaefer 400 space\n",
    "    - seven_networks (True (7 networks) or False (17 networks)\n",
    "    \n",
    "    Output:\n",
    "    - data in fsaverage5 space\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # fetch the fsaverage parcellation labeling each of fsaverage5's 20484 vertices with its corresponding Schaefer parcel - seven_networks=False means 17 yeo networks\n",
    "    from brainstat.datasets import fetch_parcellation\n",
    "    \n",
    "    schaefer_400_fs5 = fetch_parcellation(\"fsaverage5\", \"schaefer\", 400, seven_networks=seven_networks)\n",
    "    \n",
    "    \n",
    "    # list that will contain the fs5 data\n",
    "    fs5_data = []\n",
    "    \n",
    "\n",
    "    # iterate over the 20484 vertices in fsaverage5\n",
    "    for i in range(len(schaefer_400_fs5)):\n",
    "\n",
    "        if schaefer_400_fs5[i] == 0:  # corresponds to the midline\n",
    "            # append to the lists of fs5_tvals: 0\n",
    "            fs5_data.append(0)\n",
    "\n",
    "        else:\n",
    "            # append to the lists of fs5_tvals: the value of the corresponding Schaefer parcel (here parcel value [i] - 1 because parcel numbers go from 1-400 instead of 0-399 as required for indexing)\n",
    "            fs5_data.append(schaefer400_data[schaefer_400_fs5[i]-1])\n",
    "\n",
    "\n",
    "    # transform list into array\n",
    "    fs5_data = np.asarray(fs5_data)\n",
    "\n",
    "    # change the zeros into nan (couldn't nan directly because then it made the array content strings)\n",
    "    fs5_data[fs5_data == 0] = np.nan\n",
    "\n",
    "\n",
    "    return fs5_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b15b59d-9c14-4bb9-b62f-a61dd9bcb1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BN_dispersion_heatmap_matrix(BN_dispersion_contrast_res, contrast_type, save_plot = False, output_dir = None):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Function that plots a heatmap matrix for the pairwise comparison results of effects on BN dispersion \n",
    "    \n",
    "    Input variables:\n",
    "    - BN_dispersion_contrast_res: pd dataframe IN CORRECT ORDER (i.e., yielded by my code) containing pairwise comparisons of all possible combinations of 7 Yeo networks and t-values (dataframe also contains p-val, spin p-val and Bonferroni sig (but it is not used here)\n",
    "    - contrast_type: string that will go in name of the plot to save (e.g., \"sex\")\n",
    "    - save_plots: True/False if want to save screenshots of plotted hemispheres and network breakdown of significant differences\n",
    "    - output_dir: path to output directory (e.g. resdir_fig, i.e. '/data/p_02667/sex_diff_gradients/results/figures/')\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    ### Arrange data in triangle format\n",
    "    \n",
    "    triangle = []\n",
    "    \n",
    "    triangle.append([1]+BN_dispersion_contrast_res.iloc[:6,0].tolist())\n",
    "    triangle.append(2*[1]+BN_dispersion_contrast_res.iloc[6:11,0].tolist())\n",
    "    triangle.append(3*[1]+BN_dispersion_contrast_res.iloc[11:15,0].tolist())\n",
    "    triangle.append(4*[1]+BN_dispersion_contrast_res.iloc[15:18,0].tolist())\n",
    "    triangle.append(5*[1]+BN_dispersion_contrast_res.iloc[18:20,0].tolist())\n",
    "    triangle.append(6*[1]+BN_dispersion_contrast_res.iloc[20:21,0].tolist())\n",
    "    triangle.append(7*[1])\n",
    "    \n",
    "    triangle = np.array(triangle)\n",
    "    \n",
    "    # Create a mask for the upper triangle\n",
    "    mask = np.triu(np.ones(triangle.shape, dtype=bool), k=1)\n",
    "    \n",
    "    # Set values in the lower triangle to NaN or 0\n",
    "    triangle[np.logical_not(mask)] = np.nan  # Use np.nan to leave the lower triangle empty\n",
    "    \n",
    "    \n",
    "    ### Plot\n",
    "    \n",
    "    plt.figure(figsize=(20, 18))\n",
    "    \n",
    "    plt.imshow(triangle, cmap='bwr_r', interpolation='none')\n",
    "    \n",
    "    colorbar = plt.colorbar()\n",
    "    colorbar.ax.tick_params(labelsize=40)  # Set the font size for the color bar ticks\n",
    "    colorbar.set_label('t-values', fontsize=40)  # Set the font size for the color bar label\n",
    "    #plt.title(‘t-vales sex effects on pairwise BN dispersion’, fontsize=30)\n",
    "    plt.xticks(ticks=range(triangle.shape[0]), labels=np.array(['V', 'SM', 'DA', 'VA', 'L', 'FP', 'DMN']), rotation=0,  fontsize=40)\n",
    "    plt.yticks(ticks=range(triangle.shape[0]), labels=np.array(['V', 'SM', 'DA', 'VA', 'L', 'FP', 'DMN']), rotation=0,  fontsize=40)\n",
    "    \n",
    "    # Add labels to the values in the upper triangle\n",
    "    for i in range(triangle.shape[0]):\n",
    "        for j in range(i + 1, triangle.shape[1]):\n",
    "            value = triangle[i, j]\n",
    "            if not np.isnan(value):\n",
    "                plt.annotate(f'{value:.2f}', xy=(j, i), color='black', ha='center', va='center', fontsize=40)\n",
    "      \n",
    "    \n",
    "    # Save the plot \n",
    "    if save_plot:\n",
    "        \n",
    "        plt.savefig(output_dir+'BN_dispersion_heatmap_matrix_tvals_'+contrast_type+'_contrast.png', dpi=300,  bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abc78104-e352-4d6c-977b-9236c3894e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for running chord_diagram() (for sex differences in connectivity profiles) because importing (from mpl_chord_diagram import chord_diagram) it yields errors\n",
    "\n",
    "https://blog.finxter.com/how-to-plot-a-chord-diagram-using-python/\n",
    "\n",
    "https://github.com/tfardet/mpl_chord_diagram/tree/main\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Tools to draw a chord diagram in python\n",
    "\"\"\"\n",
    "\n",
    "from collections.abc import Sequence\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from matplotlib.colors import ColorConverter\n",
    "from matplotlib.path import Path\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as ssp\n",
    "\n",
    "#from .gradient import gradient\n",
    "\"\"\"\n",
    "Create linear color gradients\n",
    "\"\"\"\n",
    "\n",
    "from matplotlib.colors import ColorConverter, LinearSegmentedColormap\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def gradient(start, end, min_angle, color1, color2, meshgrid, mask, ax,\n",
    "             alpha):\n",
    "    '''\n",
    "    Create a linear gradient from `start` to `end`, which is translationally\n",
    "    invarient in the orthogonal direction.\n",
    "    The gradient is then cliped by the mask.\n",
    "    '''\n",
    "    xs, ys = start\n",
    "    xe, ye = end\n",
    "\n",
    "    X, Y = meshgrid\n",
    "\n",
    "    # get the distance to each point\n",
    "    d2start = (X - xs)*(X - xs) + (Y - ys)*(Y - ys)\n",
    "    d2end   = (X - xe)*(X - xe) + (Y - ye)*(Y - ye)\n",
    "\n",
    "    dmax = (xs - xe)*(xs - xe) + (ys - ye)*(ys - ye)\n",
    "\n",
    "    # blur\n",
    "    smin = 0.015*len(X)\n",
    "    smax = max(smin, 0.1*len(X)*min(min_angle/120, 1))\n",
    "\n",
    "    sigma = np.clip(dmax*len(X), smin, smax)\n",
    "\n",
    "    Z = gaussian_filter((d2end < d2start).astype(float), sigma=sigma)\n",
    "\n",
    "    # generate the colormap\n",
    "    n_bin = 100\n",
    "\n",
    "    color_list = linear_gradient(color1, color2, n_bin)\n",
    "\n",
    "    cmap = LinearSegmentedColormap.from_list(\"gradient\", color_list, N=n_bin)\n",
    "\n",
    "    im = ax.imshow(Z, interpolation='bilinear', cmap=cmap,\n",
    "                   origin='lower', extent=[-1, 1, -1, 1], alpha=alpha)\n",
    "\n",
    "    im.set_clip_path(mask)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#from .utilities import _get_normed_line, compute_positions, dist, polar2xy\n",
    "\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def dist(points):\n",
    "    '''\n",
    "    Compute the distance between two points.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    points : array of length 4\n",
    "        The coordinates of the two points, P1 = (x1, y1) and P2 = (x2, y2)\n",
    "        in the order [x1, y1, x2, y2].\n",
    "    '''\n",
    "    x1, y1 = points[0]\n",
    "    x2, y2 = points[1]\n",
    "\n",
    "    return np.sqrt((x2 - x1)*(x2 - x1) + (y2 - y1)*(y2 - y1))\n",
    "\n",
    "\n",
    "def polar2xy(r, theta):\n",
    "    '''\n",
    "    Convert the coordinates of a point P from polar (r, theta) to cartesian\n",
    "    (x, y).\n",
    "    '''\n",
    "    return np.array([r*np.cos(theta), r*np.sin(theta)])\n",
    "\n",
    "\n",
    "def compute_positions(mat, deg, in_deg, out_deg, start_at, is_sparse, kwargs,\n",
    "                      directed, extent, pad, arc, rotation, nodePos, pos):\n",
    "    '''\n",
    "    Compute all arcs and chords start/end positions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mat : matrix\n",
    "        Original matrix.\n",
    "    deg : array\n",
    "        Out (if undirected) or total (if directed) degree to compute the\n",
    "        starting positions.\n",
    "    in_deg : array\n",
    "        In-degree to compute the end positions (if directed).\n",
    "    out_deg : array\n",
    "        Out-degree to compute the end positions (if directed).\n",
    "    y : array\n",
    "        Used to compute the arcs' ends.\n",
    "    start_at : float\n",
    "        Start of the first arc.\n",
    "    is_sparse : bool\n",
    "        Whether the matrix is sparse.\n",
    "    kwargs : dict\n",
    "        Keyword arguments.\n",
    "    directed : bool\n",
    "        Whether the chords are directed.\n",
    "    extent : float in ]0, 360]\n",
    "        Angular aperture of the diagram.\n",
    "    pad : float\n",
    "        Gap between entries.\n",
    "    arc : list\n",
    "        Used to store the arcs start and endpoints.\n",
    "    rotation : list\n",
    "        Store the rotation booleans for the names.\n",
    "    nodePos : list\n",
    "        Store the name positions.\n",
    "    pos : dict\n",
    "        Store the start and end positions for each arc under the form:\n",
    "        (start1, end1, start2, end2), where (start1, end1) are the limits of the\n",
    "        chords starting point, and (start2, end2) are the limits of the chord's\n",
    "        end point.\n",
    "    '''\n",
    "    num_nodes = len(deg)\n",
    "\n",
    "    # find position for each start and end\n",
    "    y = deg / np.sum(deg).astype(float) * (extent - pad * num_nodes)\n",
    "\n",
    "    if directed:\n",
    "        y_out = out_deg / np.sum(deg).astype(float) * (extent - pad * num_nodes)\n",
    "\n",
    "    starts = [start_at] + (\n",
    "        start_at + np.cumsum(y + pad*np.ones(num_nodes))).tolist()\n",
    "\n",
    "    out_ends = [s + d for s, d in zip(starts, (y_out if directed else y))]\n",
    "\n",
    "\n",
    "    # relative positions within an arc\n",
    "    zmat = [\n",
    "        _get_normed_line(mat, i, out_deg if directed else deg, starts[i],\n",
    "                         out_ends[i], is_sparse)\n",
    "        for i in range(num_nodes)\n",
    "    ]\n",
    "\n",
    "    zin_mat = zmat\n",
    "\n",
    "    if directed:\n",
    "        zin_mat = [\n",
    "            _get_normed_line(mat.T, i, in_deg, out_ends[i], starts[i + 1] - pad,\n",
    "                             is_sparse)\n",
    "            for i in range(num_nodes)\n",
    "        ]\n",
    "\n",
    "    # sort\n",
    "    sort = kwargs.get(\"sort\", \"size\")\n",
    "\n",
    "    mat_ids = _get_sorted_ids(sort, zmat, num_nodes, directed)\n",
    "\n",
    "    # compute positions\n",
    "    for i in range(num_nodes):\n",
    "        # arcs\n",
    "        start = starts[i]\n",
    "        end = start + y[i]\n",
    "        arc.append((start, end))\n",
    "        angle = 0.5*(start + end)\n",
    "\n",
    "        if -30 <= (angle % 360) <= 180:\n",
    "            angle -= 90\n",
    "            rotation.append(False)\n",
    "        else:\n",
    "            angle -= 270\n",
    "            rotation.append(True)\n",
    "\n",
    "        nodePos.append(\n",
    "            tuple(polar2xy(1.05, 0.5*(start + end)*np.pi/180.)) + (angle,))\n",
    "\n",
    "        # sort chords\n",
    "        z = zmat[i]\n",
    "        z0 = start\n",
    "\n",
    "        for j in mat_ids[i]:\n",
    "            # compute the arrival points\n",
    "            zj = zin_mat[j]\n",
    "            startj = out_ends[j] if directed else starts[j]\n",
    "\n",
    "            jids = mat_ids[j]\n",
    "\n",
    "            distsort = (sort == \"distance\")\n",
    "\n",
    "            if directed and not distsort:\n",
    "                jids = jids[::-1]\n",
    "\n",
    "            stop = np.where(np.equal(jids, i))[0][0]\n",
    "\n",
    "            startji = startj + zj[jids[:stop]].sum()\n",
    "\n",
    "            if distsort and directed:\n",
    "                # we want j first for target positions\n",
    "                startji += zj[j]\n",
    "\n",
    "            if distsort and directed and i == j:\n",
    "                pos[(i, j)] = (z0, z0 + z[j], startj, startj + zj[j])\n",
    "            else:\n",
    "                pos[(i, j)] = (z0, z0 + z[j], startji, startji + zj[jids[stop]])\n",
    "\n",
    "            z0 += z[j]\n",
    "\n",
    "\n",
    "# In-file functions\n",
    "\n",
    "def _get_normed_line(mat, i, x, start, end, is_sparse):\n",
    "    if is_sparse:\n",
    "        row = mat.getrow(i).todense().A1\n",
    "        return (row / x[i]) * (end - start)\n",
    "\n",
    "    return (mat[i, :] / x[i]) * (end - start)\n",
    "\n",
    "\n",
    "def _get_sorted_ids(sort, zmat, num_nodes, directed):\n",
    "    mat_ids = defaultdict(lambda: list(range(num_nodes)))\n",
    "\n",
    "    if sort == \"size\":\n",
    "        mat_ids = [np.argsort(z) for z in zmat]\n",
    "    elif sort == \"distance\":\n",
    "        mat_ids = []\n",
    "        for i in range(num_nodes):\n",
    "            remainder = 0 if num_nodes % 2 else -1\n",
    "\n",
    "            ids  = list(range(i - int(0.5*num_nodes), i))[::-1]\n",
    "\n",
    "            if not directed:\n",
    "                ids += [i]\n",
    "\n",
    "            ids += list(range(i + int(0.5*num_nodes) + remainder, i, -1))\n",
    "\n",
    "            if directed:\n",
    "                ids += [i]\n",
    "\n",
    "            # put them back into [0, num_nodes[\n",
    "            ids = np.array(ids)\n",
    "            ids[ids < 0] += num_nodes\n",
    "            ids[ids >= num_nodes] -= num_nodes\n",
    "\n",
    "            mat_ids.append(ids)\n",
    "    elif sort is not None:\n",
    "        raise ValueError(\"Invalid `sort`: '{}'\".format(sort))\n",
    "\n",
    "    return mat_ids\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "LW = 0.3\n",
    "\n",
    "\n",
    "def chord_diagram(mat, names=None, order=None, width=0.1, pad=2., gap=0.03,\n",
    "                  chordwidth=0.7, ax=None, colors=None, cmap=None, alpha=0.7,\n",
    "                  use_gradient=False, chord_colors=None, start_at=0, extent=360,\n",
    "                  directed=False, show=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Plot a chord diagram.\n",
    "\n",
    "    Draws a representation of many-to-many interactions between elements, given\n",
    "    by an interaction matrix.\n",
    "    The elements are represented by arcs proportional to their degree and the\n",
    "    interactions (or fluxes) are drawn as chords joining two arcs:\n",
    "\n",
    "    * for undirected chords, the size of the arc is proportional to its\n",
    "      out-degree (or simply its degree if the matrix is fully symmetrical), i.e.\n",
    "      the sum of the element's row.\n",
    "    * for directed chords, the size is proportional to the total-degree, i.e.\n",
    "      the sum of the element's row and column.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mat : square matrix\n",
    "        Flux data, ``mat[i, j]`` is the flux from i to j.\n",
    "    names : list of str, optional (default: no names)\n",
    "        Names of the nodes that will be displayed (must be ordered as the\n",
    "        matrix entries).\n",
    "    order : list, optional (default: order of the matrix entries)\n",
    "        Order in which the arcs should be placed around the trigonometric\n",
    "        circle.\n",
    "    width : float, optional (default: 0.1)\n",
    "        Width/thickness of the ideogram arc.\n",
    "    pad : float, optional (default: 2)\n",
    "        Distance between two neighboring ideogram arcs. Unit: degree.\n",
    "    gap : float, optional (default: 0)\n",
    "        Distance between the arc and the beginning of the cord.\n",
    "    chordwidth : float, optional (default: 0.7)\n",
    "        Position of the control points for the chords, controlling their shape.\n",
    "    ax : matplotlib axis, optional (default: new axis)\n",
    "        Matplotlib axis where the plot should be drawn.\n",
    "    colors : list, optional (default: from `cmap`)\n",
    "        List of user defined colors or floats.\n",
    "    cmap : str or colormap object (default: viridis)\n",
    "        Colormap that will be used to color the arcs and chords by default.\n",
    "        See `chord_colors` to use different colors for chords.\n",
    "    alpha : float in [0, 1], optional (default: 0.7)\n",
    "        Opacity of the chord diagram.\n",
    "    use_gradient : bool, optional (default: False)\n",
    "        Whether a gradient should be use so that chord extremities have the\n",
    "        same color as the arc they belong to.\n",
    "    chord_colors : str, or list of colors, optional (default: None)\n",
    "        Specify color(s) to fill the chords differently from the arcs.\n",
    "        When the keyword is not used, chord colors default to the colomap given\n",
    "        by `colors`.\n",
    "        Possible values for `chord_colors` are:\n",
    "\n",
    "        * a single color (do not use an RGB tuple, use hex format instead),\n",
    "          e.g. \"red\" or \"#ff0000\"; all chords will have this color\n",
    "        * a list of colors, e.g. ``[\"red\", \"green\", \"blue\"]``, one per node\n",
    "          (in this case, RGB tuples are accepted as entries to the list).\n",
    "          Each chord will get its color from its associated source node, or\n",
    "          from both nodes if `use_gradient` is True.\n",
    "    start_at : float, optional (default : 0)\n",
    "        Location, in degrees, where the diagram should start on the unit circle.\n",
    "        Default is to start at 0 degrees, i.e. (x, y) = (1, 0) or 3 o'clock),\n",
    "        and move counter-clockwise\n",
    "    extent : float, optional (default : 360)\n",
    "        The angular aperture, in degrees, of the diagram.\n",
    "        Default is to use the whole circle, i.e. 360 degrees, but in some cases\n",
    "        it can be useful to use only a part of it.\n",
    "    directed : bool, optional (default: False)\n",
    "        Whether the chords should be directed, like edges in a graph, with one\n",
    "        part of each arc dedicated to outgoing chords and the other to incoming\n",
    "        ones.\n",
    "    show : bool, optional (default: False)\n",
    "        Whether the plot should be displayed immediately via an automatic call\n",
    "        to `plt.show()`.\n",
    "    **kwargs : keyword arguments\n",
    "        Available kwargs are:\n",
    "\n",
    "        ================  ==================  ==================================\n",
    "              Name               Type            Purpose and possible values\n",
    "        ================  ==================  ==================================\n",
    "        fontcolor         str or list         Color of the names (default: \"k\")\n",
    "        ----------------  ------------------  ----------------------------------\n",
    "        fontsize          int                 Size of the font for names\n",
    "        ----------------  ------------------  ----------------------------------\n",
    "        rotate_names      (list of) bool(s)   Rotate names by 90°\n",
    "        ----------------  ------------------  ----------------------------------\n",
    "        sort              str                 Either None, \"size\", or \"distance\"\n",
    "                                              (default is \"size\")\n",
    "        ----------------  ------------------  ----------------------------------\n",
    "                                              Minimal chord width to replace\n",
    "        min_chord_width   float               small entries and zero reciprocals\n",
    "                                              in the matrix (default: 0)\n",
    "        ================  ==================  ==================================\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "\n",
    "    # copy matrix\n",
    "    is_sparse = ssp.issparse(mat)\n",
    "\n",
    "    if is_sparse:\n",
    "        mat = mat.tocsr(copy=True)\n",
    "    else:\n",
    "        mat = np.array(mat, copy=True)\n",
    "\n",
    "    num_nodes = mat.shape[0]\n",
    "\n",
    "    # don't use gradient with directed chords\n",
    "    use_gradient *= not directed\n",
    "\n",
    "    # set min entry size for small entries and zero reciprocals\n",
    "    # mat[i, j]:  i -> j\n",
    "    min_deg = kwargs.get(\"min_chord_width\", 0)\n",
    "\n",
    "    if is_sparse and min_deg:\n",
    "        nnz = mat.nonzero()\n",
    "\n",
    "        mat.data[mat.data < min_deg] = min_deg\n",
    "\n",
    "        # check zero reciprocals\n",
    "        for i, j in zip(*nnz):\n",
    "            if mat[j, i] < min_deg:\n",
    "                mat[j, i] = min_deg\n",
    "    else:\n",
    "        nnz = mat > 0\n",
    "\n",
    "        mat[nnz] = np.maximum(mat[nnz], min_deg)\n",
    "\n",
    "        # check zero reciprocals\n",
    "        for i, j in zip(*np.where(~nnz)):\n",
    "            if mat[j, i]:\n",
    "                mat[i, j] = min_deg\n",
    "\n",
    "    # check name rotations\n",
    "    rotate_names = kwargs.get(\"rotate_names\", False)\n",
    "\n",
    "    if isinstance(rotate_names, Sequence):\n",
    "        assert len(rotate_names) == num_nodes, \\\n",
    "            \"Wrong number of entries in 'rotate_names'.\"\n",
    "    else:\n",
    "        rotate_names = [rotate_names]*num_nodes\n",
    "\n",
    "    # check order\n",
    "    if order is not None:\n",
    "        mat = mat[order][:, order]\n",
    "\n",
    "        rotate_names = [rotate_names[i] for i in order]\n",
    "\n",
    "        if names is not None:\n",
    "            names = [names[i] for i in order]\n",
    "\n",
    "        if colors is not None:\n",
    "            colors = [colors[i] for i in order]\n",
    "\n",
    "    # configure colors\n",
    "    if colors is None:\n",
    "        colors = np.linspace(0, 1, num_nodes)\n",
    "\n",
    "    fontcolor = kwargs.get(\"fontcolor\", \"k\")\n",
    "\n",
    "    if isinstance(fontcolor, str):\n",
    "        fontcolor = [fontcolor]*num_nodes\n",
    "    else:\n",
    "        assert len(fontcolor) == num_nodes, \\\n",
    "            \"One fontcolor per node is required.\"\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = \"viridis\"\n",
    "\n",
    "    if isinstance(colors, (list, tuple, np.ndarray)):\n",
    "        assert len(colors) == num_nodes, \"One color per node is required.\"\n",
    "\n",
    "        # check color type\n",
    "        first_color = colors[0]\n",
    "\n",
    "        if isinstance(first_color, (int, float, np.integer)):\n",
    "            cm = plt.get_cmap(cmap)\n",
    "            colors = cm(colors)[:, :3]\n",
    "        else:\n",
    "            colors = [ColorConverter.to_rgb(c) for c in colors]\n",
    "    else:\n",
    "        raise ValueError(\"`colors` should be a list.\")\n",
    "\n",
    "    if chord_colors is None:\n",
    "       chord_colors = colors\n",
    "    else:\n",
    "        try:\n",
    "            chord_colors = [ColorConverter.to_rgb(chord_colors)] * num_nodes\n",
    "        except ValueError:\n",
    "            assert len(chord_colors) == num_nodes, \\\n",
    "                \"If `chord_colors` is a list of colors, it should include \" \\\n",
    "                \"one color per node (here {} colors).\".format(num_nodes)\n",
    "\n",
    "    # sum over rows\n",
    "    out_deg = mat.sum(axis=1).A1 if is_sparse else mat.sum(axis=1)\n",
    "    in_deg = None\n",
    "    degree = out_deg.copy()\n",
    "\n",
    "    if directed:\n",
    "        # also sum over columns\n",
    "        in_deg = mat.sum(axis=0).A1 if is_sparse else mat.sum(axis=0)\n",
    "        degree += in_deg\n",
    "\n",
    "    pos = {}\n",
    "    pos_dir = {}\n",
    "    arc = []\n",
    "    nodePos = []\n",
    "    rotation = []\n",
    "\n",
    "    # compute all values and optionally apply sort\n",
    "    compute_positions(mat, degree, in_deg, out_deg, start_at, is_sparse, kwargs,\n",
    "                      directed, extent, pad, arc, rotation, nodePos, pos)\n",
    "\n",
    "    # plot\n",
    "    for i in range(num_nodes):\n",
    "        color = colors[i]\n",
    "\n",
    "        # plot the arcs\n",
    "        start_at, end = arc[i]\n",
    "\n",
    "        ideogram_arc(start=start_at, end=end, radius=1.0, color=color,\n",
    "                     width=width, alpha=alpha, ax=ax)\n",
    "\n",
    "        chord_color = chord_colors[i]\n",
    "\n",
    "        # plot self-chords if directed is False\n",
    "        if not directed and mat[i, i]:\n",
    "            start1, end1, _, _ = pos[(i, i)]\n",
    "            self_chord_arc(start1, end1, radius=1 - width - gap,\n",
    "                           chordwidth=0.7*chordwidth, color=chord_color,\n",
    "                           alpha=alpha, ax=ax)\n",
    "\n",
    "        # plot all other chords\n",
    "        targets = range(num_nodes) if directed else range(i)\n",
    "\n",
    "        for j in targets:\n",
    "            cend = chord_colors[j]\n",
    "\n",
    "            start1, end1, start2, end2 = pos[(i, j)]\n",
    "\n",
    "            if mat[i, j] > 0 or (not directed and mat[j, i] > 0):\n",
    "                chord_arc(\n",
    "                    start1, end1, start2, end2, radius=1 - width - gap, gap=gap,\n",
    "                    chordwidth=chordwidth, color=chord_color, cend=cend,\n",
    "                    alpha=alpha, ax=ax, use_gradient=use_gradient,\n",
    "                    extent=extent, directed=directed)\n",
    "\n",
    "    # add names if necessary\n",
    "    if names is not None:\n",
    "        assert len(names) == num_nodes, \"One name per node is required.\"\n",
    "\n",
    "        prop = {\n",
    "            \"fontsize\": kwargs.get(\"fontsize\", 16*0.8),\n",
    "            \"ha\": \"center\",\n",
    "            \"va\": \"center\",\n",
    "            \"rotation_mode\": \"anchor\"\n",
    "        }\n",
    "\n",
    "        for i, (pos, name, r) in enumerate(zip(nodePos, names, rotation)):\n",
    "            rotate = rotate_names[i]\n",
    "            pp = prop.copy()\n",
    "            pp[\"color\"] = fontcolor[i]\n",
    "\n",
    "            if rotate:\n",
    "                angle  = np.average(arc[i])\n",
    "                rotate = 90\n",
    "\n",
    "                if 90 < angle < 180 or 270 < angle:\n",
    "                    rotate = -90\n",
    "\n",
    "                if 90 < angle < 270:\n",
    "                    pp[\"ha\"] = \"right\"\n",
    "                else:\n",
    "                    pp[\"ha\"] = \"left\"\n",
    "            elif r:\n",
    "                pp[\"va\"] = \"top\"\n",
    "            else:\n",
    "                pp[\"va\"] = \"bottom\"\n",
    "\n",
    "            ax.text(pos[0], pos[1], name, rotation=pos[2] + rotate, **pp)\n",
    "\n",
    "    # configure axis\n",
    "    ax.set_xlim(-1.1, 1.1)\n",
    "    ax.set_ylim(-1.1, 1.1)\n",
    "\n",
    "    ax.set_aspect(1)\n",
    "    ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "    return nodePos\n",
    "\n",
    "\n",
    "# ------------ #\n",
    "# Subfunctions #\n",
    "# ------------ #\n",
    "\n",
    "def initial_path(start, end, radius, width, factor=4/3):\n",
    "    ''' First 16 vertices and 15 instructions are the same for everyone '''\n",
    "    if start > end:\n",
    "        start, end = end, start\n",
    "\n",
    "    start *= np.pi/180.\n",
    "    end   *= np.pi/180.\n",
    "\n",
    "    # optimal distance to the control points\n",
    "    # https://stackoverflow.com/questions/1734745/\n",
    "    # how-to-create-circle-with-b%C3%A9zier-curves\n",
    "    # use 16-vertex curves (4 quadratic Beziers which accounts for worst case\n",
    "    # scenario of 360 degrees)\n",
    "    inner = radius*(1-width)\n",
    "    opt   = factor * np.tan((end-start)/ 16.) * radius\n",
    "    inter1 = start*(3./4.)+end*(1./4.)\n",
    "    inter2 = start*(2./4.)+end*(2./4.)\n",
    "    inter3 = start*(1./4.)+end*(3./4.)\n",
    "\n",
    "    verts = [\n",
    "        polar2xy(radius, start),\n",
    "        polar2xy(radius, start) + polar2xy(opt, start+0.5*np.pi),\n",
    "        polar2xy(radius, inter1) + polar2xy(opt, inter1-0.5*np.pi),\n",
    "        polar2xy(radius, inter1),\n",
    "        polar2xy(radius, inter1),\n",
    "        polar2xy(radius, inter1) + polar2xy(opt, inter1+0.5*np.pi),\n",
    "        polar2xy(radius, inter2) + polar2xy(opt, inter2-0.5*np.pi),\n",
    "        polar2xy(radius, inter2),\n",
    "        polar2xy(radius, inter2),\n",
    "        polar2xy(radius, inter2) + polar2xy(opt, inter2+0.5*np.pi),\n",
    "        polar2xy(radius, inter3) + polar2xy(opt, inter3-0.5*np.pi),\n",
    "        polar2xy(radius, inter3),\n",
    "        polar2xy(radius, inter3),\n",
    "        polar2xy(radius, inter3) + polar2xy(opt, inter3+0.5*np.pi),\n",
    "        polar2xy(radius, end) + polar2xy(opt, end-0.5*np.pi),\n",
    "        polar2xy(radius, end)\n",
    "    ]\n",
    "\n",
    "    codes = [\n",
    "        Path.MOVETO,\n",
    "        Path.CURVE4,\n",
    "        Path.CURVE4,\n",
    "        Path.CURVE4,\n",
    "        Path.LINETO,\n",
    "        Path.CURVE4,\n",
    "        Path.CURVE4,\n",
    "        Path.CURVE4,\n",
    "        Path.LINETO,\n",
    "        Path.CURVE4,\n",
    "        Path.CURVE4,\n",
    "        Path.CURVE4,\n",
    "        Path.LINETO,\n",
    "        Path.CURVE4,\n",
    "        Path.CURVE4,\n",
    "        Path.CURVE4,\n",
    "    ]\n",
    "\n",
    "    return start, end, verts, codes\n",
    "\n",
    "\n",
    "def ideogram_arc(start, end, radius=1., width=0.2, color=\"r\", alpha=0.7,\n",
    "                 ax=None):\n",
    "    '''\n",
    "    Draw an arc symbolizing a region of the chord diagram.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    start : float (degree in 0, 360)\n",
    "        Starting degree.\n",
    "    end : float (degree in 0, 360)\n",
    "        Final degree.\n",
    "    radius : float, optional (default: 1)\n",
    "        External radius of the arc.\n",
    "    width : float, optional (default: 0.2)\n",
    "        Width of the arc.\n",
    "    ax : matplotlib axis, optional (default: not plotted)\n",
    "        Axis on which the arc should be plotted.\n",
    "    color : valid matplotlib color, optional (default: \"r\")\n",
    "        Color of the arc.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    verts, codes : lists\n",
    "        Vertices and path instructions to draw the shape.\n",
    "    '''\n",
    "    start, end, verts, codes = initial_path(start, end, radius, width)\n",
    "\n",
    "    opt    = 4./3. * np.tan((end-start)/ 16.) * radius\n",
    "    inner  = radius*(1-width)\n",
    "    inter1 = start*(3./4.) + end*(1./4.)\n",
    "    inter2 = start*(2./4.) + end*(2./4.)\n",
    "    inter3 = start*(1./4.) + end*(3./4.)\n",
    "\n",
    "    verts += [\n",
    "        polar2xy(inner, end),\n",
    "        polar2xy(inner, end) + polar2xy(opt*(1-width), end-0.5*np.pi),\n",
    "        polar2xy(inner, inter3) + polar2xy(opt*(1-width), inter3+0.5*np.pi),\n",
    "        polar2xy(inner, inter3),\n",
    "        polar2xy(inner, inter3),\n",
    "        polar2xy(inner, inter3) + polar2xy(opt*(1-width), inter3-0.5*np.pi),\n",
    "        polar2xy(inner, inter2) + polar2xy(opt*(1-width), inter2+0.5*np.pi),\n",
    "        polar2xy(inner, inter2),\n",
    "        polar2xy(inner, inter2),\n",
    "        polar2xy(inner, inter2) + polar2xy(opt*(1-width), inter2-0.5*np.pi),\n",
    "        polar2xy(inner, inter1) + polar2xy(opt*(1-width), inter1+0.5*np.pi),\n",
    "        polar2xy(inner, inter1),\n",
    "        polar2xy(inner, inter1),\n",
    "        polar2xy(inner, inter1) + polar2xy(opt*(1-width), inter1-0.5*np.pi),\n",
    "        polar2xy(inner, start) + polar2xy(opt*(1-width), start+0.5*np.pi),\n",
    "        polar2xy(inner, start),\n",
    "        polar2xy(radius, start),\n",
    "    ]\n",
    "\n",
    "    codes += [\n",
    "        Path.LINETO,\n",
    "        Path.CURVE4,\n",
    "        Path.CURVE4,\n",
    "        Path.CURVE4,\n",
    "        Path.LINETO,\n",
    "        Path.CURVE4,\n",
    "        Path.CURVE4,\n",
    "        Path.CURVE4,\n",
    "        Path.LINETO,\n",
    "        Path.CURVE4,\n",
    "        Path.CURVE4,\n",
    "        Path.CURVE4,\n",
    "        Path.LINETO,\n",
    "        Path.CURVE4,\n",
    "        Path.CURVE4,\n",
    "        Path.CURVE4,\n",
    "        Path.CLOSEPOLY,\n",
    "    ]\n",
    "\n",
    "    if ax is not None:\n",
    "        path  = Path(verts, codes)\n",
    "        patch = patches.PathPatch(path, facecolor=color, alpha=alpha,\n",
    "                                  edgecolor=color, lw=LW)\n",
    "        ax.add_patch(patch)\n",
    "\n",
    "    return verts, codes\n",
    "\n",
    "\n",
    "def chord_arc(start1, end1, start2, end2, radius=1.0, gap=0.03, pad=2,\n",
    "              chordwidth=0.7, ax=None, color=\"r\", cend=\"r\", alpha=0.7,\n",
    "              use_gradient=False, extent=360, directed=False):\n",
    "    '''\n",
    "    Draw a chord between two regions (arcs) of the chord diagram.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    start1 : float (degree in 0, 360)\n",
    "        Starting degree.\n",
    "    end1 : float (degree in 0, 360)\n",
    "        Final degree.\n",
    "    start2 : float (degree in 0, 360)\n",
    "        Starting degree.\n",
    "    end2 : float (degree in 0, 360)\n",
    "        Final degree.\n",
    "    radius : float, optional (default: 1)\n",
    "        External radius of the arc.\n",
    "    gap : float, optional (default: 0)\n",
    "        Distance between the arc and the beginning of the cord.\n",
    "    chordwidth : float, optional (default: 0.2)\n",
    "        Width of the chord.\n",
    "    ax : matplotlib axis, optional (default: not plotted)\n",
    "        Axis on which the chord should be plotted.\n",
    "    color : valid matplotlib color, optional (default: \"r\")\n",
    "        Color of the chord or of its beginning if `use_gradient` is True.\n",
    "    cend : valid matplotlib color, optional (default: \"r\")\n",
    "        Color of the end of the chord if `use_gradient` is True.\n",
    "    alpha : float, optional (default: 0.7)\n",
    "        Opacity of the chord.\n",
    "    use_gradient : bool, optional (default: False)\n",
    "        Whether a gradient should be use so that chord extremities have the\n",
    "        same color as the arc they belong to.\n",
    "    extent : float, optional (default : 360)\n",
    "        The angular aperture, in degrees, of the diagram.\n",
    "        Default is to use the whole circle, i.e. 360 degrees, but in some cases\n",
    "        it can be useful to use only a part of it.\n",
    "    directed : bool, optional (default: False)\n",
    "        Whether the chords should be directed, ending in an arrow.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    verts, codes : lists\n",
    "        Vertices and path instructions to draw the shape.\n",
    "    '''\n",
    "    chordwidth2 = chordwidth\n",
    "\n",
    "    dtheta1 = min((start1 - end2) % extent, (end2 - start1) % extent)\n",
    "    dtheta2 = min((end1 - start2) % extent, (start2 - end1) % extent)\n",
    "\n",
    "    start1, end1, verts, codes = initial_path(start1, end1, radius, chordwidth)\n",
    "\n",
    "    if directed:\n",
    "        if start2 > end2:\n",
    "            start2, end2 = end2, start2\n",
    "\n",
    "        start2 *= np.pi/180.\n",
    "        end2   *= np.pi/180.\n",
    "\n",
    "        tip = 0.5*(start2 + end2)\n",
    "        asize = max(gap, 0.02)\n",
    "\n",
    "        verts2 = [\n",
    "            polar2xy(radius - asize, start2),\n",
    "            polar2xy(radius, tip),\n",
    "            polar2xy(radius - asize, end2)\n",
    "        ]\n",
    "    else:\n",
    "        start2, end2, verts2, _ = initial_path(start2, end2, radius, chordwidth)\n",
    "\n",
    "    chordwidth2 *= np.clip(0.4 + (dtheta1 - 2*pad) / (15*pad), 0.2, 1)\n",
    "\n",
    "    chordwidth *= np.clip(0.4 + (dtheta2 - 2*pad) / (15*pad), 0.2, 1)\n",
    "\n",
    "    rchord  = radius * (1-chordwidth)\n",
    "    rchord2 = radius * (1-chordwidth2)\n",
    "\n",
    "    verts += [polar2xy(rchord, end1), polar2xy(rchord, start2)] + verts2\n",
    "\n",
    "    verts += [\n",
    "        polar2xy(rchord2, end2),\n",
    "        polar2xy(rchord2, start1),\n",
    "        polar2xy(radius, start1),\n",
    "    ]\n",
    "\n",
    "    # update codes\n",
    "\n",
    "    codes += [\n",
    "        Path.CURVE4,\n",
    "        Path.CURVE4,\n",
    "    ]\n",
    "\n",
    "    if directed:\n",
    "        codes += [\n",
    "            Path.CURVE4,\n",
    "            Path.LINETO,\n",
    "            Path.LINETO,\n",
    "        ]\n",
    "    else:\n",
    "        codes += [\n",
    "            Path.CURVE4,\n",
    "            Path.CURVE4,\n",
    "            Path.CURVE4,\n",
    "            Path.CURVE4,\n",
    "            Path.LINETO,\n",
    "            Path.CURVE4,\n",
    "            Path.CURVE4,\n",
    "            Path.CURVE4,\n",
    "            Path.LINETO,\n",
    "            Path.CURVE4,\n",
    "            Path.CURVE4,\n",
    "            Path.CURVE4,\n",
    "            Path.LINETO,\n",
    "            Path.CURVE4,\n",
    "            Path.CURVE4,\n",
    "            Path.CURVE4,\n",
    "        ]\n",
    "\n",
    "    codes += [\n",
    "        Path.CURVE4,\n",
    "        Path.CURVE4,\n",
    "        Path.CURVE4,\n",
    "    ]\n",
    "\n",
    "    if ax is not None:\n",
    "        path = Path(verts, codes)\n",
    "\n",
    "        if use_gradient:\n",
    "            # find the start and end points of the gradient\n",
    "            points, min_angle = None, None\n",
    "\n",
    "            if dtheta1 < dtheta2:\n",
    "                points = [\n",
    "                    polar2xy(radius, start1),\n",
    "                    polar2xy(radius, end2),\n",
    "                ]\n",
    "\n",
    "                min_angle = dtheta1\n",
    "            else:\n",
    "                points = [\n",
    "                    polar2xy(radius, end1),\n",
    "                    polar2xy(radius, start2),\n",
    "                ]\n",
    "\n",
    "                min_angle = dtheta1\n",
    "\n",
    "            # make the patch\n",
    "            patch = patches.PathPatch(path, facecolor=\"none\",\n",
    "                                      edgecolor=\"none\", lw=LW)\n",
    "            ax.add_patch(patch)  # this is required to clip the gradient\n",
    "\n",
    "            # make the grid\n",
    "            x = y = np.linspace(-1, 1, 100)\n",
    "            meshgrid = np.meshgrid(x, y)\n",
    "\n",
    "            gradient(points[0], points[1], min_angle, color, cend, meshgrid,\n",
    "                     patch, ax, alpha)\n",
    "        else:\n",
    "            patch = patches.PathPatch(path, facecolor=color, alpha=alpha,\n",
    "                                      edgecolor=color, lw=LW)\n",
    "\n",
    "            idx = 16\n",
    "\n",
    "            ax.add_patch(patch)\n",
    "\n",
    "    return verts, codes\n",
    "\n",
    "\n",
    "def self_chord_arc(start, end, radius=1.0, chordwidth=0.7, ax=None,\n",
    "                   color=(1,0,0), alpha=0.7):\n",
    "    start, end, verts, codes = initial_path(start, end, radius, chordwidth)\n",
    "\n",
    "    rchord = radius * (1 - chordwidth)\n",
    "\n",
    "    verts += [\n",
    "        polar2xy(rchord, end),\n",
    "        polar2xy(rchord, start),\n",
    "        polar2xy(radius, start),\n",
    "    ]\n",
    "\n",
    "    codes += [\n",
    "        Path.CURVE4,\n",
    "        Path.CURVE4,\n",
    "        Path.CURVE4,\n",
    "    ]\n",
    "\n",
    "    if ax is not None:\n",
    "        path  = Path(verts, codes)\n",
    "        patch = patches.PathPatch(path, facecolor=color, alpha=alpha,\n",
    "                                  edgecolor=color, lw=LW)\n",
    "        ax.add_patch(patch)\n",
    "\n",
    "    return verts, codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a19ba7-88ee-4ff6-9795-e125d85f12be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
